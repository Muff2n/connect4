{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.manual_seed(999)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = 2\n",
    "filters = 64\n",
    "\n",
    "n_epocs = 20\n",
    "batch_size = 511\n",
    "test_size = 0.2\n",
    "learning_rate = 0.002 * (batch_size / 1024.0)\n",
    "momentum = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Connect4Dataset(data.Dataset):\n",
    "    def __init__(self, boards, values):\n",
    "        assert len(boards) == len(values)\n",
    "        self.boards = boards\n",
    "        self.values = values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.boards)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.boards[idx], self.values[idx]\n",
    "\n",
    "boards = torch.load('/home/richard/Downloads/connect4_boards.pth').numpy()\n",
    "values = torch.load('/home/richard/Downloads/connect4_values.pth').numpy()\n",
    "\n",
    "# Here we don't want to have the player to move channel\n",
    "boards = boards[:, 3 - channels:]\n",
    "\n",
    "board_train, board_test, value_train, value_test = train_test_split(boards, values, test_size=test_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # augment data\n",
    "v_wins = value_train[value_train == 1.0]\n",
    "v_draws = value_train[value_train == 0.5]\n",
    "v_losses = value_train[value_train == 0.0]\n",
    "b_wins = board_train[value_train == 1.0]\n",
    "b_draws = board_train[value_train == 0.5]\n",
    "b_losses = board_train[value_train == 0.0]\n",
    "\n",
    "n_wins = len(v_wins)\n",
    "n_draws = len(v_draws)\n",
    "n_losses = len(v_losses)\n",
    "\n",
    "v_augmented_draws = np.repeat(v_draws, n_wins/n_draws)\n",
    "v_augmented_losses = np.repeat(v_losses, n_wins/n_losses)\n",
    "b_augmented_draws = np.repeat(b_draws, n_wins/n_draws, axis=0)\n",
    "b_augmented_losses = np.repeat(b_losses, n_wins/n_losses, axis=0)\n",
    "\n",
    "extra_draw_idx = np.random.choice(range(len(v_draws)), n_wins - len(v_augmented_draws), replace=False)\n",
    "extra_losses_idx = np.random.choice(range(len(v_losses)), n_wins - len(v_augmented_losses), replace=False)\n",
    "\n",
    "v_augmented_draws = np.hstack([v_augmented_draws, v_draws[extra_draw_idx]])\n",
    "v_augmented_losses = np.hstack([v_augmented_losses, v_losses[extra_losses_idx]])\n",
    "b_augmented_draws = np.concatenate([b_augmented_draws, b_draws[extra_draw_idx]], axis=0)\n",
    "b_augmented_losses = np.concatenate([b_augmented_losses, b_losses[extra_losses_idx]], axis=0)\n",
    "\n",
    "value_train = np.hstack([v_wins, v_augmented_draws, v_augmented_losses])\n",
    "board_train = np.concatenate([b_wins, b_augmented_draws, b_augmented_losses], axis=0)\n",
    "\n",
    "train = Connect4Dataset(torch.from_numpy(board_train), torch.from_numpy(value_train))\n",
    "test = Connect4Dataset(torch.from_numpy(board_test), torch.from_numpy(value_test))\n",
    "\n",
    "train_gen = data.DataLoader(train, batch_size, shuffle=True)\n",
    "test_gen = data.DataLoader(test, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.connect4.neural import value_net as net\n",
    "\n",
    "def init_normal(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.normal_(m.weight, std=0.0000001)\n",
    "    elif type(m) == nn.Conv2d:\n",
    "        nn.init.normal_(m.weight, std=0.0000001)\n",
    "    elif type(m) == nn.BatchNorm2d:\n",
    "        nn.init.normal_(m.weight, std=0.0000001)\n",
    "#         nn.init.constant_(m.bias, 0)\n",
    "\n",
    "# net.apply(init_normal)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = nn.MSELoss()\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=momentum)\n",
    "# optimizer = optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorise_predictions(preds):\n",
    "    preds = preds * 3.0\n",
    "    torch.floor_(preds)\n",
    "    preds = preds / 2.0\n",
    "    return preds\n",
    "\n",
    "class Stats():\n",
    "    def __init__(self):\n",
    "        self.n = 0\n",
    "        self.average_value = 0.0\n",
    "        self.total_loss = 0.0\n",
    "        self.smallest = 1.0\n",
    "        self.largest = 0.0\n",
    "        self.correct = {i : 0 for i in [0.0, 0.5, 1.0]}\n",
    "        self.total = {i : 0 for i in [0.0, 0.5, 1.0]}\n",
    "    \n",
    "    @property\n",
    "    def loss(self):\n",
    "        return self.total_loss / self.n\n",
    "    \n",
    "    @property\n",
    "    def accuracy(self):\n",
    "        return float(sum(self.correct.values())) / self.n\n",
    "        \n",
    "    def __repr__(self):\n",
    "        x = \"Average loss:  \" + \"{:.5f}\".format(self.loss) + \\\n",
    "            \",  Accuracy:  \" + \"{:.5f}\".format(self.accuracy) + \\\n",
    "            \",  Smallest:  \" + \"{:.5f}\".format(self.smallest) + \\\n",
    "            \",  Largest:  \" + \"{:.5f}\".format(self.largest) + \\\n",
    "            \",  Average:  \" + \"{:.5f}\".format(self.average_value / self.n)\n",
    "        \n",
    "        for k in self.correct:\n",
    "            x += \"\\nCategory, # Members, # Correct Predictions:  {}, {}, {}\".format(\n",
    "                k,\n",
    "                self.total[k],\n",
    "                self.correct[k])\n",
    "        return x\n",
    "    \n",
    "    def update(self, outputs, values, loss):\n",
    "        self.n += len(values)\n",
    "        self.average_value += outputs.sum().item()\n",
    "        self.total_loss += loss.item() * len(values)\n",
    "        self.smallest = min(self.smallest, torch.min(outputs).item())\n",
    "        self.largest = max(self.largest, torch.max(outputs).item())\n",
    "\n",
    "        categories = categorise_predictions(outputs)\n",
    "        values = values.view(-1)\n",
    "        categories = categories.view(-1)\n",
    "\n",
    "        for k in self.correct:\n",
    "            idx = (values == k).nonzero()\n",
    "            self.total[k] += len(idx)\n",
    "            self.correct[k] += len(torch.eq(categories[idx], values[idx]).nonzero()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from laplotter import LossAccPlotter\n",
    "\n",
    "plotter = LossAccPlotter()\n",
    "\n",
    "for epoch in range(n_epocs):\n",
    "    \n",
    "    net = net.train()\n",
    "    train_stats = Stats()\n",
    "    test_stats = Stats()\n",
    "    \n",
    "    for board, value in train_gen:\n",
    "        board, value = board.to(device), value.to(device)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        output = net(board)\n",
    "        loss = criterion(output, value)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_stats.update(output, value, loss)\n",
    "\n",
    "    # validate\n",
    "    with torch.set_grad_enabled(False):\n",
    "        net = net.eval()\n",
    "        for board, value in test_gen:\n",
    "            board, value = board.to(device), value.to(device)\n",
    "\n",
    "            output = net(board)\n",
    "            loss = criterion(output, value)\n",
    "            \n",
    "            test_stats.update(output, value, loss)\n",
    "            \n",
    "    print(\"Epoch:  \", epoch, \"  Train:\\n\", train_stats, \"\\nTest:\\n\", test_stats)\n",
    "    plotter.add_values(epoch,\n",
    "                       loss_train=train_stats.loss, acc_train=train_stats.accuracy,\n",
    "                       loss_val=test_stats.loss, acc_val=test_stats.accuracy)\n",
    "            \n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch:   2   Train:\n",
    " Average loss:  0.19129,  Accuracy:  0.48539,  Smallest:  0.00000,  Largest:  1.00000,  Average:  0.49355\n",
    "Category, # Predictions, # Correct:  0.0, 35539, 22758\n",
    "Category, # Predictions, # Correct:  0.5, 35539, 23891\n",
    "Category, # Predictions, # Correct:  1.0, 35539, 5102 \n",
    "Test:\n",
    " Average loss:  0.17624,  Accuracy:  0.27805,  Smallest:  0.00000,  Largest:  1.00000,  Average:  0.67491\n",
    "Category, # Predictions, # Correct:  0.0, 3300, 1932\n",
    "Category, # Predictions, # Correct:  0.5, 1278, 786\n",
    "Category, # Predictions, # Correct:  1.0, 8934, 1039\n",
    "((8934-1039)*0.33 + (3300 - 1932) * 0.33 + (1278 - 786) * 0.16) / (3300+1278+8934) = 0.23\n",
    "So explain to me how the test set had an average loss of 0.18!?\n",
    "Still large for epoch 3\n",
    "((8934-2201)*0.33 + (3300 - 2108) * 0.33 + (1278 - 909) * 0.16) / (3300+1278+8934) = 0.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter.fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate\n",
    "with torch.set_grad_enabled(False):\n",
    "    net = net.eval()\n",
    "    correct = {i : 0 for i in [0, 0.5, 1]}\n",
    "    total = {i : 0 for i in [0, 0.5, 1]}\n",
    "    for board, value in test_gen:\n",
    "        board, value = board.to(device), value.to(device)\n",
    "\n",
    "        outputs = net(board)\n",
    "        categories = categorise_predictions(outputs)\n",
    "\n",
    "        for k in correct:\n",
    "            idx = (categories == k).nonzero()\n",
    "            total[k] += len(idx)\n",
    "            correct[k] += (categories[idx] == value[idx]).nonzero().sum().item()\n",
    "    for k in correct:\n",
    "        print('Category, # Predictions, Accuracy of the network on the test%s: %d %d %%' % (\n",
    "            k,\n",
    "            total[k],\n",
    "            (100 * float(correct[k]) / float(total[k])) if total[k] != 0 else 0.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(False)\n",
    "# save that crap\n",
    "torch.save({\n",
    "    'net_state_dict': net.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': loss},\n",
    "    '/home/richard/Downloads/nn.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternatively load it\n",
    "assert(False)\n",
    "checkpoint = torch.load('/home/richard/Downloads/nn.pth')\n",
    "net.load_state_dict(checkpoint['net_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "loss = checkpoint['loss']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
