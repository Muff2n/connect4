{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from connect4.neural.nn_pytorch import evaluate\n",
    "from connect4.neural.stats import CombinedStats\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from visdom import Visdom\n",
    "\n",
    "from laplotter import LossAccPlotter\n",
    "\n",
    "\n",
    "# https://discuss.pytorch.org/t/output-of-resnet34-network-depends-on-the-batch-size/21647\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.manual_seed(999)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epocs = 10000\n",
    "epochs_per_stats = 1\n",
    "batch_size = 4096\n",
    "test_size = 0.2\n",
    "# learning_rate = 0.002 * (batch_size / 1024.0)\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "\n",
    "WORKING_DIR = '/home/richard/Downloads/nn/PSU_back/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/richard/data/connect4/7ply_boards.pkl', 'rb') as f:\n",
    "    boards = pickle.load(f)\n",
    "with open ('/home/richard/data/connect4/7ply_values.pkl', 'rb') as f:\n",
    "    values = pickle.load(f)\n",
    "with open('/home/richard/data/connect4/7ply_priors.pkl', 'rb') as f:\n",
    "    priors = pickle.load(f)\n",
    "\n",
    "priors = list(map(lambda x: x / np.sum(x) if np.sum(x) > 0.0 else np.zeros((7,)), priors))\n",
    "\n",
    "board_train, board_test, value_train, value_test, prior_train, prior_test = train_test_split(boards, values, priors, test_size=test_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset with 22391 positions\n",
      "Creating dataset with 5598 positions\n"
     ]
    }
   ],
   "source": [
    "from connect4.neural.nn_pytorch import Connect4Dataset\n",
    "\n",
    "train = Connect4Dataset(board_train, value_train, prior_train)\n",
    "test = Connect4Dataset(board_test, value_test, prior_test)\n",
    "\n",
    "train_gen = data.DataLoader(train, batch_size, shuffle=True)\n",
    "test_gen = data.DataLoader(train, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (body): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): ResidualLayer(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batch_norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (batch_norm2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "      (1): ResidualLayer(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batch_norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (batch_norm2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "      (2): ResidualLayer(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batch_norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (batch_norm2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (value_head): ValueHead(\n",
       "    (conv1): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (batch_norm): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): LeakyReLU(negative_slope=0.01)\n",
       "    (fcN): Sequential(\n",
       "      (0): Linear(in_features=42, out_features=42, bias=True)\n",
       "      (1): Linear(in_features=42, out_features=42, bias=True)\n",
       "      (2): Linear(in_features=42, out_features=42, bias=True)\n",
       "      (3): Linear(in_features=42, out_features=42, bias=True)\n",
       "    )\n",
       "    (fc1): Linear(in_features=42, out_features=1, bias=True)\n",
       "    (tanh): Tanh()\n",
       "  )\n",
       "  (policy_head): PolicyHead(\n",
       "    (conv1): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (batch_norm): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): LeakyReLU(negative_slope=0.01)\n",
       "    (fc1): Linear(in_features=84, out_features=7, bias=True)\n",
       "    (softmax): Softmax()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from connect4.neural.nn_pytorch import Net\n",
    "\n",
    "net = Net()\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_criterion = nn.MSELoss()\n",
    "prior_criterion = nn.BCELoss()\n",
    "\n",
    "# optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=momentum)\n",
    "optimizer = optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "Average loss:  0.21271  Accuracy:  0.11697  Smallest:  0.37858  Largest:  0.57237  Average:  0.49557\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 0)  (0.5, 2619, 2619)  (1.0, 9869, 0)\n",
      "Average loss:  0.40620  Accuracy:  0.79894\n",
      "Average loss:  0.21995  Accuracy:  0.11826  Smallest:  0.50177  Largest:  0.51380  Average:  0.50666\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 0)  (0.5, 226, 226)  (1.0, 856, 0)\n",
      "Average loss:  0.40768  Accuracy:  0.80377\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1728x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1728x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "Average loss:  0.17229  Accuracy:  0.19432  Smallest:  0.12522  Largest:  0.73170  Average:  0.47555\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 1613)  (0.5, 2619, 2587)  (1.0, 9869, 151)\n",
      "Average loss:  0.40416  Accuracy:  0.80836\n",
      "Average loss:  0.21860  Accuracy:  0.11826  Smallest:  0.49873  Largest:  0.53955  Average:  0.51571\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 0)  (0.5, 226, 226)  (1.0, 856, 0)\n",
      "Average loss:  0.40753  Accuracy:  0.80377\n",
      "epoch: 2\n",
      "Average loss:  0.11472  Accuracy:  0.59551  Smallest:  0.02135  Largest:  0.94494  Average:  0.46561\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 6707)  (0.5, 2619, 1867)  (1.0, 9869, 4760)\n",
      "Average loss:  0.40309  Accuracy:  0.80729\n",
      "Average loss:  0.21351  Accuracy:  0.11826  Smallest:  0.47252  Largest:  0.60157  Average:  0.52753\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 0)  (0.5, 226, 226)  (1.0, 856, 0)\n",
      "Average loss:  0.40734  Accuracy:  0.80377\n",
      "epoch: 3\n",
      "Average loss:  0.07957  Accuracy:  0.75955  Smallest:  0.00173  Largest:  0.99238  Average:  0.47856\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 8137)  (0.5, 2619, 999)  (1.0, 9869, 7871)\n",
      "Average loss:  0.40231  Accuracy:  0.80867\n",
      "Average loss:  0.20636  Accuracy:  0.14652  Smallest:  0.41942  Largest:  0.73219  Average:  0.57153\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 0)  (0.5, 226, 224)  (1.0, 856, 56)\n",
      "Average loss:  0.40688  Accuracy:  0.80115\n",
      "epoch: 4\n",
      "Average loss:  0.06590  Accuracy:  0.79724  Smallest:  0.00039  Largest:  0.99909  Average:  0.49344\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 8552)  (0.5, 2619, 707)  (1.0, 9869, 8592)\n",
      "Average loss:  0.40154  Accuracy:  0.80903\n",
      "Average loss:  0.20990  Accuracy:  0.39979  Smallest:  0.32937  Largest:  0.87491  Average:  0.66756\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 1)  (0.5, 226, 108)  (1.0, 856, 655)\n",
      "Average loss:  0.40612  Accuracy:  0.80272\n",
      "epoch: 5\n",
      "Average loss:  0.06084  Accuracy:  0.81417  Smallest:  0.00007  Largest:  0.99982  Average:  0.49675\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 8777)  (0.5, 2619, 694)  (1.0, 9869, 8759)\n",
      "Average loss:  0.40085  Accuracy:  0.80912\n",
      "Average loss:  0.23735  Accuracy:  0.45840  Smallest:  0.23152  Largest:  0.97135  Average:  0.78035\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 15)  (0.5, 226, 23)  (1.0, 856, 838)\n",
      "Average loss:  0.40511  Accuracy:  0.80638\n",
      "epoch: 6\n",
      "Average loss:  0.06053  Accuracy:  0.81104  Smallest:  0.00005  Largest:  0.99992  Average:  0.50058\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 8725)  (0.5, 2619, 663)  (1.0, 9869, 8772)\n",
      "Average loss:  0.40013  Accuracy:  0.81564\n",
      "Average loss:  0.11701  Accuracy:  0.64521  Smallest:  0.02345  Largest:  0.99257  Average:  0.65983\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 349)  (0.5, 226, 63)  (1.0, 856, 821)\n",
      "Average loss:  0.40301  Accuracy:  0.81109\n",
      "epoch: 7\n",
      "Average loss:  0.05435  Accuracy:  0.82538  Smallest:  0.00004  Largest:  0.99987  Average:  0.49352\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 8943)  (0.5, 2619, 708)  (1.0, 9869, 8830)\n",
      "Average loss:  0.39939  Accuracy:  0.82350\n",
      "Average loss:  0.10804  Accuracy:  0.69702  Smallest:  0.00644  Largest:  0.99889  Average:  0.66245\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 453)  (0.5, 226, 42)  (1.0, 856, 837)\n",
      "Average loss:  0.40093  Accuracy:  0.82575\n",
      "epoch: 8\n",
      "Average loss:  0.04966  Accuracy:  0.83328  Smallest:  0.00007  Largest:  0.99986  Average:  0.50110\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 8916)  (0.5, 2619, 763)  (1.0, 9869, 8979)\n",
      "Average loss:  0.39855  Accuracy:  0.83409\n",
      "Average loss:  0.09482  Accuracy:  0.71900  Smallest:  0.00368  Largest:  0.99898  Average:  0.64399\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 494)  (0.5, 226, 41)  (1.0, 856, 839)\n",
      "Average loss:  0.39967  Accuracy:  0.84301\n",
      "epoch: 9\n",
      "Average loss:  0.04660  Accuracy:  0.84034  Smallest:  0.00008  Largest:  0.99990  Average:  0.50230\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 8956)  (0.5, 2619, 823)  (1.0, 9869, 9037)\n",
      "Average loss:  0.39763  Accuracy:  0.84208\n",
      "Average loss:  0.06240  Accuracy:  0.79696  Smallest:  0.00163  Largest:  0.99937  Average:  0.57939\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 624)  (0.5, 226, 73)  (1.0, 856, 826)\n",
      "Average loss:  0.39793  Accuracy:  0.85243\n",
      "epoch: 10\n",
      "Average loss:  0.04279  Accuracy:  0.85222  Smallest:  0.00005  Largest:  0.99983  Average:  0.49480\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9154)  (0.5, 2619, 863)  (1.0, 9869, 9065)\n",
      "Average loss:  0.39664  Accuracy:  0.84463\n",
      "Average loss:  0.04964  Accuracy:  0.83150  Smallest:  0.00044  Largest:  0.99982  Average:  0.54721\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 697)  (0.5, 226, 72)  (1.0, 856, 820)\n",
      "Average loss:  0.39578  Accuracy:  0.86028\n",
      "epoch: 11\n",
      "Average loss:  0.04049  Accuracy:  0.85753  Smallest:  0.00004  Largest:  0.99991  Average:  0.50110\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9160)  (0.5, 2619, 849)  (1.0, 9869, 9192)\n",
      "Average loss:  0.39556  Accuracy:  0.84565\n",
      "Average loss:  0.04371  Accuracy:  0.85034  Smallest:  0.00028  Largest:  0.99982  Average:  0.52685\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 732)  (0.5, 226, 85)  (1.0, 856, 808)\n",
      "Average loss:  0.39415  Accuracy:  0.86185\n",
      "epoch: 12\n",
      "Average loss:  0.03829  Accuracy:  0.86258  Smallest:  0.00003  Largest:  0.99991  Average:  0.49660\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9286)  (0.5, 2619, 844)  (1.0, 9869, 9184)\n",
      "Average loss:  0.39435  Accuracy:  0.84748\n",
      "Average loss:  0.04227  Accuracy:  0.84720  Smallest:  0.00022  Largest:  0.99983  Average:  0.53643\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 726)  (0.5, 226, 77)  (1.0, 856, 816)\n",
      "Average loss:  0.39274  Accuracy:  0.86499\n",
      "epoch: 13\n",
      "Average loss:  0.03624  Accuracy:  0.86767  Smallest:  0.00001  Largest:  0.99996  Average:  0.50177\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9274)  (0.5, 2619, 867)  (1.0, 9869, 9287)\n",
      "Average loss:  0.39314  Accuracy:  0.85083\n",
      "Average loss:  0.03946  Accuracy:  0.85662  Smallest:  0.00019  Largest:  0.99990  Average:  0.52648\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 739)  (0.5, 226, 86)  (1.0, 856, 812)\n",
      "Average loss:  0.39101  Accuracy:  0.86238\n",
      "epoch: 14\n",
      "Average loss:  0.03438  Accuracy:  0.87062  Smallest:  0.00001  Largest:  0.99997  Average:  0.49763\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9345)  (0.5, 2619, 850)  (1.0, 9869, 9299)\n",
      "Average loss:  0.39190  Accuracy:  0.85021\n",
      "Average loss:  0.03757  Accuracy:  0.86604  Smallest:  0.00009  Largest:  0.99994  Average:  0.53624\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 747)  (0.5, 226, 81)  (1.0, 856, 827)\n",
      "Average loss:  0.39012  Accuracy:  0.86342\n",
      "epoch: 15\n",
      "Average loss:  0.03170  Accuracy:  0.87982  Smallest:  0.00000  Largest:  0.99999  Average:  0.49911\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9415)  (0.5, 2619, 888)  (1.0, 9869, 9397)\n",
      "Average loss:  0.39067  Accuracy:  0.85324\n",
      "Average loss:  0.03545  Accuracy:  0.87075  Smallest:  0.00006  Largest:  0.99998  Average:  0.52651\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 762)  (0.5, 226, 75)  (1.0, 856, 827)\n",
      "Average loss:  0.38849  Accuracy:  0.86447\n",
      "epoch: 16\n",
      "Average loss:  0.03002  Accuracy:  0.88509  Smallest:  0.00000  Largest:  0.99998  Average:  0.49878\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9509)  (0.5, 2619, 886)  (1.0, 9869, 9423)\n",
      "Average loss:  0.38961  Accuracy:  0.85597\n",
      "Average loss:  0.03471  Accuracy:  0.87546  Smallest:  0.00003  Largest:  0.99998  Average:  0.53559\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 755)  (0.5, 226, 82)  (1.0, 856, 836)\n",
      "Average loss:  0.38724  Accuracy:  0.86813\n",
      "epoch: 17\n",
      "Average loss:  0.02830  Accuracy:  0.88732  Smallest:  0.00000  Largest:  0.99999  Average:  0.50072\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9493)  (0.5, 2619, 861)  (1.0, 9869, 9514)\n",
      "Average loss:  0.38864  Accuracy:  0.85869\n",
      "Average loss:  0.03645  Accuracy:  0.85924  Smallest:  0.00003  Largest:  0.99998  Average:  0.55252\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 736)  (0.5, 226, 67)  (1.0, 856, 839)\n",
      "Average loss:  0.38658  Accuracy:  0.87232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18\n",
      "Average loss:  0.02653  Accuracy:  0.89366  Smallest:  0.00000  Largest:  0.99999  Average:  0.50151\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9559)  (0.5, 2619, 899)  (1.0, 9869, 9552)\n",
      "Average loss:  0.38777  Accuracy:  0.86075\n",
      "Average loss:  0.02953  Accuracy:  0.88226  Smallest:  0.00002  Largest:  0.99998  Average:  0.53034\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 775)  (0.5, 226, 76)  (1.0, 856, 835)\n",
      "Average loss:  0.38509  Accuracy:  0.87703\n",
      "epoch: 19\n",
      "Average loss:  0.02553  Accuracy:  0.89540  Smallest:  0.00000  Largest:  0.99999  Average:  0.50204\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9589)  (0.5, 2619, 871)  (1.0, 9869, 9589)\n",
      "Average loss:  0.38695  Accuracy:  0.86584\n",
      "Average loss:  0.02896  Accuracy:  0.88121  Smallest:  0.00001  Largest:  0.99999  Average:  0.47780\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 815)  (0.5, 226, 59)  (1.0, 856, 810)\n",
      "Average loss:  0.38443  Accuracy:  0.87598\n",
      "epoch: 20\n",
      "Average loss:  0.02670  Accuracy:  0.88754  Smallest:  0.00000  Largest:  0.99999  Average:  0.49881\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9557)  (0.5, 2619, 809)  (1.0, 9869, 9507)\n",
      "Average loss:  0.38624  Accuracy:  0.86856\n",
      "Average loss:  0.03328  Accuracy:  0.86761  Smallest:  0.00001  Largest:  0.99999  Average:  0.54682\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 758)  (0.5, 226, 57)  (1.0, 856, 843)\n",
      "Average loss:  0.38368  Accuracy:  0.88121\n",
      "epoch: 21\n",
      "Average loss:  0.02652  Accuracy:  0.88924  Smallest:  0.00000  Largest:  0.99999  Average:  0.49987\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9564)  (0.5, 2619, 771)  (1.0, 9869, 9576)\n",
      "Average loss:  0.38564  Accuracy:  0.87173\n",
      "Average loss:  0.02396  Accuracy:  0.89744  Smallest:  0.00000  Largest:  0.99998  Average:  0.50903\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 807)  (0.5, 226, 71)  (1.0, 856, 837)\n",
      "Average loss:  0.38299  Accuracy:  0.87807\n",
      "epoch: 22\n",
      "Average loss:  0.02694  Accuracy:  0.88594  Smallest:  0.00000  Largest:  1.00000  Average:  0.49864\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9578)  (0.5, 2619, 748)  (1.0, 9869, 9511)\n",
      "Average loss:  0.38502  Accuracy:  0.87419\n",
      "Average loss:  0.03013  Accuracy:  0.86761  Smallest:  0.00000  Largest:  0.99999  Average:  0.54124\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 762)  (0.5, 226, 46)  (1.0, 856, 850)\n",
      "Average loss:  0.38234  Accuracy:  0.87912\n",
      "epoch: 23\n",
      "Average loss:  0.02460  Accuracy:  0.89348  Smallest:  0.00000  Largest:  1.00000  Average:  0.50360\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9577)  (0.5, 2619, 795)  (1.0, 9869, 9634)\n",
      "Average loss:  0.38441  Accuracy:  0.87647\n",
      "Average loss:  0.02449  Accuracy:  0.90058  Smallest:  0.00000  Largest:  0.99999  Average:  0.49737\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 810)  (0.5, 226, 80)  (1.0, 856, 831)\n",
      "Average loss:  0.38186  Accuracy:  0.88802\n",
      "epoch: 24\n",
      "Average loss:  0.02101  Accuracy:  0.90795  Smallest:  0.00000  Largest:  0.99999  Average:  0.50075\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9681)  (0.5, 2619, 952)  (1.0, 9869, 9697)\n",
      "Average loss:  0.38376  Accuracy:  0.87951\n",
      "Average loss:  0.02157  Accuracy:  0.91104  Smallest:  0.00000  Largest:  0.99998  Average:  0.51191\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 808)  (0.5, 226, 90)  (1.0, 856, 843)\n",
      "Average loss:  0.38085  Accuracy:  0.89325\n",
      "epoch: 25\n",
      "Average loss:  0.01932  Accuracy:  0.91456  Smallest:  0.00000  Largest:  0.99999  Average:  0.49786\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9752)  (0.5, 2619, 1032)  (1.0, 9869, 9694)\n",
      "Average loss:  0.38311  Accuracy:  0.88464\n",
      "Average loss:  0.02248  Accuracy:  0.90947  Smallest:  0.00000  Largest:  0.99998  Average:  0.53061\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 800)  (0.5, 226, 88)  (1.0, 856, 850)\n",
      "Average loss:  0.38055  Accuracy:  0.89848\n",
      "epoch: 26\n",
      "Average loss:  0.01946  Accuracy:  0.91215  Smallest:  0.00000  Largest:  0.99999  Average:  0.49857\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9735)  (0.5, 2619, 978)  (1.0, 9869, 9711)\n",
      "Average loss:  0.38256  Accuracy:  0.88536\n",
      "Average loss:  0.02017  Accuracy:  0.91837  Smallest:  0.00000  Largest:  0.99998  Average:  0.51414\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 809)  (0.5, 226, 99)  (1.0, 856, 847)\n",
      "Average loss:  0.38014  Accuracy:  0.90529\n",
      "epoch: 27\n",
      "Average loss:  0.01747  Accuracy:  0.91979  Smallest:  0.00000  Largest:  1.00000  Average:  0.49812\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9798)  (0.5, 2619, 1051)  (1.0, 9869, 9746)\n",
      "Average loss:  0.38195  Accuracy:  0.88920\n",
      "Average loss:  0.02295  Accuracy:  0.89901  Smallest:  0.00000  Largest:  0.99999  Average:  0.53890\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 789)  (0.5, 226, 79)  (1.0, 856, 850)\n",
      "Average loss:  0.37929  Accuracy:  0.90686\n",
      "epoch: 28\n",
      "Average loss:  0.01752  Accuracy:  0.91814  Smallest:  0.00000  Largest:  1.00000  Average:  0.49789\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9770)  (0.5, 2619, 1051)  (1.0, 9869, 9737)\n",
      "Average loss:  0.38131  Accuracy:  0.89116\n",
      "Average loss:  0.02439  Accuracy:  0.88278  Smallest:  0.00000  Largest:  0.99998  Average:  0.46510\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 823)  (0.5, 226, 47)  (1.0, 856, 817)\n",
      "Average loss:  0.37839  Accuracy:  0.90738\n",
      "epoch: 29\n",
      "Average loss:  0.01729  Accuracy:  0.91756  Smallest:  0.00000  Largest:  0.99999  Average:  0.49584\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9792)  (0.5, 2619, 1029)  (1.0, 9869, 9724)\n",
      "Average loss:  0.38079  Accuracy:  0.89380\n",
      "Average loss:  0.01856  Accuracy:  0.91837  Smallest:  0.00000  Largest:  0.99999  Average:  0.51587\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 812)  (0.5, 226, 94)  (1.0, 856, 849)\n",
      "Average loss:  0.37779  Accuracy:  0.90999\n",
      "epoch: 30\n",
      "Average loss:  0.02127  Accuracy:  0.89965  Smallest:  0.00000  Largest:  1.00000  Average:  0.49931\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9692)  (0.5, 2619, 829)  (1.0, 9869, 9623)\n",
      "Average loss:  0.38027  Accuracy:  0.89576\n",
      "Average loss:  0.01999  Accuracy:  0.91470  Smallest:  0.00000  Largest:  0.99998  Average:  0.51781\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 802)  (0.5, 226, 100)  (1.0, 856, 846)\n",
      "Average loss:  0.37737  Accuracy:  0.91052\n",
      "epoch: 31\n",
      "Average loss:  0.01784  Accuracy:  0.91211  Smallest:  0.00000  Largest:  1.00000  Average:  0.50472\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9717)  (0.5, 2619, 943)  (1.0, 9869, 9763)\n",
      "Average loss:  0.37980  Accuracy:  0.89674\n",
      "Average loss:  0.02582  Accuracy:  0.88069  Smallest:  0.00000  Largest:  0.99996  Average:  0.45962\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 824)  (0.5, 226, 58)  (1.0, 856, 801)\n",
      "Average loss:  0.37684  Accuracy:  0.91575\n",
      "epoch: 32\n",
      "Average loss:  0.01961  Accuracy:  0.90443  Smallest:  0.00000  Largest:  1.00000  Average:  0.49702\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9717)  (0.5, 2619, 892)  (1.0, 9869, 9642)\n",
      "Average loss:  0.37927  Accuracy:  0.89987\n",
      "Average loss:  0.02037  Accuracy:  0.90476  Smallest:  0.00000  Largest:  0.99998  Average:  0.47706\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 821)  (0.5, 226, 78)  (1.0, 856, 830)\n",
      "Average loss:  0.37621  Accuracy:  0.91052\n",
      "epoch: 33\n",
      "Average loss:  0.01913  Accuracy:  0.90514  Smallest:  0.00000  Largest:  1.00000  Average:  0.48958\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9757)  (0.5, 2619, 881)  (1.0, 9869, 9629)\n",
      "Average loss:  0.37880  Accuracy:  0.90215\n",
      "Average loss:  0.03584  Accuracy:  0.85139  Smallest:  0.00000  Largest:  0.99999  Average:  0.57433\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 733)  (0.5, 226, 41)  (1.0, 856, 853)\n",
      "Average loss:  0.37608  Accuracy:  0.91732\n",
      "epoch: 34\n",
      "Average loss:  0.01680  Accuracy:  0.91832  Smallest:  0.00000  Largest:  0.99999  Average:  0.50349\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9722)  (0.5, 2619, 1086)  (1.0, 9869, 9754)\n",
      "Average loss:  0.37826  Accuracy:  0.90438\n",
      "Average loss:  0.01789  Accuracy:  0.91627  Smallest:  0.00000  Largest:  0.99997  Average:  0.47918\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 823)  (0.5, 226, 89)  (1.0, 856, 839)\n",
      "Average loss:  0.37525  Accuracy:  0.92046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 35\n",
      "Average loss:  0.01774  Accuracy:  0.91255  Smallest:  0.00000  Largest:  1.00000  Average:  0.49623\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9741)  (0.5, 2619, 998)  (1.0, 9869, 9694)\n",
      "Average loss:  0.37771  Accuracy:  0.90536\n",
      "Average loss:  0.01655  Accuracy:  0.92308  Smallest:  0.00000  Largest:  0.99998  Average:  0.51948\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 811)  (0.5, 226, 102)  (1.0, 856, 851)\n",
      "Average loss:  0.37483  Accuracy:  0.91941\n",
      "epoch: 36\n",
      "Average loss:  0.01690  Accuracy:  0.91439  Smallest:  0.00000  Largest:  1.00000  Average:  0.49512\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9746)  (0.5, 2619, 1011)  (1.0, 9869, 9717)\n",
      "Average loss:  0.37732  Accuracy:  0.90782\n",
      "Average loss:  0.02349  Accuracy:  0.88854  Smallest:  0.00000  Largest:  0.99998  Average:  0.54722\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 772)  (0.5, 226, 75)  (1.0, 856, 851)\n",
      "Average loss:  0.37493  Accuracy:  0.92203\n",
      "epoch: 37\n",
      "Average loss:  0.01581  Accuracy:  0.92158  Smallest:  0.00000  Largest:  1.00000  Average:  0.50100\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9764)  (0.5, 2619, 1103)  (1.0, 9869, 9768)\n",
      "Average loss:  0.37684  Accuracy:  0.91014\n",
      "Average loss:  0.01592  Accuracy:  0.92151  Smallest:  0.00000  Largest:  0.99999  Average:  0.50285\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 819)  (0.5, 226, 97)  (1.0, 856, 845)\n",
      "Average loss:  0.37351  Accuracy:  0.92674\n",
      "epoch: 38\n",
      "Average loss:  0.01499  Accuracy:  0.92457  Smallest:  0.00000  Largest:  1.00000  Average:  0.49581\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9813)  (0.5, 2619, 1148)  (1.0, 9869, 9741)\n",
      "Average loss:  0.37631  Accuracy:  0.91023\n",
      "Average loss:  0.01871  Accuracy:  0.90372  Smallest:  0.00000  Largest:  0.99999  Average:  0.53783\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 801)  (0.5, 226, 73)  (1.0, 856, 853)\n",
      "Average loss:  0.37357  Accuracy:  0.92569\n",
      "epoch: 39\n",
      "Average loss:  0.01380  Accuracy:  0.93261  Smallest:  0.00000  Largest:  1.00000  Average:  0.50156\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9805)  (0.5, 2619, 1277)  (1.0, 9869, 9800)\n",
      "Average loss:  0.37567  Accuracy:  0.91233\n",
      "Average loss:  0.01979  Accuracy:  0.89796  Smallest:  0.00000  Largest:  0.99997  Average:  0.46747\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 825)  (0.5, 226, 64)  (1.0, 856, 827)\n",
      "Average loss:  0.37293  Accuracy:  0.92151\n",
      "epoch: 40\n",
      "Average loss:  0.01316  Accuracy:  0.93238  Smallest:  0.00000  Largest:  1.00000  Average:  0.49344\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9843)  (0.5, 2619, 1254)  (1.0, 9869, 9780)\n",
      "Average loss:  0.37512  Accuracy:  0.91447\n",
      "Average loss:  0.01836  Accuracy:  0.91156  Smallest:  0.00000  Largest:  1.00000  Average:  0.53658\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 804)  (0.5, 226, 85)  (1.0, 856, 853)\n",
      "Average loss:  0.37246  Accuracy:  0.92569\n",
      "epoch: 41\n",
      "Average loss:  0.01281  Accuracy:  0.93573  Smallest:  0.00000  Largest:  1.00000  Average:  0.50078\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9825)  (0.5, 2619, 1318)  (1.0, 9869, 9809)\n",
      "Average loss:  0.37464  Accuracy:  0.91747\n",
      "Average loss:  0.01717  Accuracy:  0.90895  Smallest:  0.00000  Largest:  0.99999  Average:  0.47683\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 825)  (0.5, 226, 73)  (1.0, 856, 839)\n",
      "Average loss:  0.37149  Accuracy:  0.93093\n",
      "epoch: 42\n",
      "Average loss:  0.01220  Accuracy:  0.93886  Smallest:  0.00000  Largest:  1.00000  Average:  0.49694\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9849)  (0.5, 2619, 1365)  (1.0, 9869, 9808)\n",
      "Average loss:  0.37399  Accuracy:  0.91907\n",
      "Average loss:  0.01174  Accuracy:  0.95133  Smallest:  0.00000  Largest:  0.99999  Average:  0.51176\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 823)  (0.5, 226, 142)  (1.0, 856, 853)\n",
      "Average loss:  0.37095  Accuracy:  0.92936\n",
      "epoch: 43\n",
      "Average loss:  0.01135  Accuracy:  0.94453  Smallest:  0.00000  Largest:  1.00000  Average:  0.49662\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9856)  (0.5, 2619, 1487)  (1.0, 9869, 9806)\n",
      "Average loss:  0.37336  Accuracy:  0.92010\n",
      "Average loss:  0.01376  Accuracy:  0.93668  Smallest:  0.00000  Largest:  1.00000  Average:  0.52256\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 817)  (0.5, 226, 120)  (1.0, 856, 853)\n",
      "Average loss:  0.37049  Accuracy:  0.93250\n",
      "epoch: 44\n",
      "Average loss:  0.01081  Accuracy:  0.94784  Smallest:  0.00000  Largest:  1.00000  Average:  0.50030\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9865)  (0.5, 2619, 1534)  (1.0, 9869, 9824)\n",
      "Average loss:  0.37285  Accuracy:  0.92077\n",
      "Average loss:  0.01133  Accuracy:  0.94819  Smallest:  0.00000  Largest:  1.00000  Average:  0.51368\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 822)  (0.5, 226, 137)  (1.0, 856, 853)\n",
      "Average loss:  0.37009  Accuracy:  0.93511\n",
      "epoch: 45\n",
      "Average loss:  0.00978  Accuracy:  0.95574  Smallest:  0.00000  Largest:  1.00000  Average:  0.49778\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9873)  (0.5, 2619, 1700)  (1.0, 9869, 9827)\n",
      "Average loss:  0.37228  Accuracy:  0.92434\n",
      "Average loss:  0.01033  Accuracy:  0.95029  Smallest:  0.00000  Largest:  0.99999  Average:  0.49847\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 825)  (0.5, 226, 138)  (1.0, 856, 853)\n",
      "Average loss:  0.36934  Accuracy:  0.93302\n",
      "epoch: 46\n",
      "Average loss:  0.01022  Accuracy:  0.94918  Smallest:  0.00000  Largest:  1.00000  Average:  0.49734\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9868)  (0.5, 2619, 1557)  (1.0, 9869, 9828)\n",
      "Average loss:  0.37183  Accuracy:  0.92493\n",
      "Average loss:  0.01130  Accuracy:  0.94349  Smallest:  0.00000  Largest:  1.00000  Average:  0.48936\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 826)  (0.5, 226, 125)  (1.0, 856, 852)\n",
      "Average loss:  0.36862  Accuracy:  0.93407\n",
      "epoch: 47\n",
      "Average loss:  0.00963  Accuracy:  0.95351  Smallest:  0.00000  Largest:  1.00000  Average:  0.49778\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9868)  (0.5, 2619, 1655)  (1.0, 9869, 9827)\n",
      "Average loss:  0.37121  Accuracy:  0.92707\n",
      "Average loss:  0.01234  Accuracy:  0.93354  Smallest:  0.00000  Largest:  1.00000  Average:  0.48697\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 826)  (0.5, 226, 111)  (1.0, 856, 847)\n",
      "Average loss:  0.36817  Accuracy:  0.93616\n",
      "epoch: 48\n",
      "Average loss:  0.01054  Accuracy:  0.94734  Smallest:  0.00000  Largest:  1.00000  Average:  0.49737\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9862)  (0.5, 2619, 1541)  (1.0, 9869, 9809)\n",
      "Average loss:  0.37069  Accuracy:  0.92961\n",
      "Average loss:  0.01437  Accuracy:  0.91994  Smallest:  0.00000  Largest:  1.00000  Average:  0.47367\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 826)  (0.5, 226, 87)  (1.0, 856, 845)\n",
      "Average loss:  0.36794  Accuracy:  0.93825\n",
      "epoch: 49\n",
      "Average loss:  0.01203  Accuracy:  0.93404  Smallest:  0.00000  Largest:  1.00000  Average:  0.49370\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9840)  (0.5, 2619, 1287)  (1.0, 9869, 9787)\n",
      "Average loss:  0.37039  Accuracy:  0.93060\n",
      "Average loss:  0.01298  Accuracy:  0.93040  Smallest:  0.00000  Largest:  1.00000  Average:  0.48598\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 826)  (0.5, 226, 104)  (1.0, 856, 848)\n",
      "Average loss:  0.36789  Accuracy:  0.93773\n",
      "epoch: 50\n",
      "Average loss:  0.01203  Accuracy:  0.93471  Smallest:  0.00000  Largest:  1.00000  Average:  0.49342\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9851)  (0.5, 2619, 1311)  (1.0, 9869, 9767)\n",
      "Average loss:  0.37001  Accuracy:  0.93069\n",
      "Average loss:  0.01743  Accuracy:  0.91470  Smallest:  0.00000  Largest:  1.00000  Average:  0.53999\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 802)  (0.5, 226, 92)  (1.0, 856, 854)\n",
      "Average loss:  0.36753  Accuracy:  0.94192\n",
      "epoch: 51\n",
      "Average loss:  0.01061  Accuracy:  0.94404  Smallest:  0.00000  Largest:  1.00000  Average:  0.49977\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9845)  (0.5, 2619, 1469)  (1.0, 9869, 9824)\n",
      "Average loss:  0.36962  Accuracy:  0.93127\n",
      "Average loss:  0.01623  Accuracy:  0.91209  Smallest:  0.00000  Largest:  1.00000  Average:  0.54247\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 808)  (0.5, 226, 81)  (1.0, 856, 854)\n",
      "Average loss:  0.36706  Accuracy:  0.94296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 52\n",
      "Average loss:  0.01011  Accuracy:  0.94873  Smallest:  0.00000  Largest:  1.00000  Average:  0.50129\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9849)  (0.5, 2619, 1571)  (1.0, 9869, 9823)\n",
      "Average loss:  0.36893  Accuracy:  0.93466\n",
      "Average loss:  0.01101  Accuracy:  0.94244  Smallest:  0.00000  Largest:  1.00000  Average:  0.48878\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 826)  (0.5, 226, 124)  (1.0, 856, 851)\n",
      "Average loss:  0.36599  Accuracy:  0.94349\n",
      "epoch: 53\n",
      "Average loss:  0.01032  Accuracy:  0.94489  Smallest:  0.00000  Largest:  1.00000  Average:  0.49913\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9862)  (0.5, 2619, 1482)  (1.0, 9869, 9813)\n",
      "Average loss:  0.36839  Accuracy:  0.93618\n",
      "Average loss:  0.01334  Accuracy:  0.92831  Smallest:  0.00000  Largest:  1.00000  Average:  0.48030\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 827)  (0.5, 226, 105)  (1.0, 856, 842)\n",
      "Average loss:  0.36560  Accuracy:  0.94505\n",
      "epoch: 54\n",
      "Average loss:  0.00981  Accuracy:  0.94989  Smallest:  0.00000  Largest:  1.00000  Average:  0.49503\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9871)  (0.5, 2619, 1579)  (1.0, 9869, 9819)\n",
      "Average loss:  0.36796  Accuracy:  0.93587\n",
      "Average loss:  0.00969  Accuracy:  0.94610  Smallest:  0.00000  Largest:  1.00000  Average:  0.50909\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 825)  (0.5, 226, 129)  (1.0, 856, 854)\n",
      "Average loss:  0.36514  Accuracy:  0.94767\n",
      "epoch: 55\n",
      "Average loss:  0.01020  Accuracy:  0.94592  Smallest:  0.00000  Largest:  1.00000  Average:  0.49766\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9858)  (0.5, 2619, 1518)  (1.0, 9869, 9804)\n",
      "Average loss:  0.36740  Accuracy:  0.93779\n",
      "Average loss:  0.01106  Accuracy:  0.94035  Smallest:  0.00000  Largest:  1.00000  Average:  0.52264\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 821)  (0.5, 226, 122)  (1.0, 856, 854)\n",
      "Average loss:  0.36487  Accuracy:  0.94453\n",
      "epoch: 56\n",
      "Average loss:  0.01233  Accuracy:  0.93225  Smallest:  0.00000  Largest:  1.00000  Average:  0.50448\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9826)  (0.5, 2619, 1269)  (1.0, 9869, 9779)\n",
      "Average loss:  0.36713  Accuracy:  0.93904\n",
      "Average loss:  0.01961  Accuracy:  0.88435  Smallest:  0.00000  Largest:  1.00000  Average:  0.45643\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 828)  (0.5, 226, 46)  (1.0, 856, 816)\n",
      "Average loss:  0.36466  Accuracy:  0.94139\n",
      "epoch: 57\n",
      "Average loss:  0.01253  Accuracy:  0.93198  Smallest:  0.00000  Largest:  1.00000  Average:  0.49567\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9814)  (0.5, 2619, 1298)  (1.0, 9869, 9756)\n",
      "Average loss:  0.36662  Accuracy:  0.93971\n",
      "Average loss:  0.01017  Accuracy:  0.94715  Smallest:  0.00000  Largest:  1.00000  Average:  0.49458\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 828)  (0.5, 226, 132)  (1.0, 856, 850)\n",
      "Average loss:  0.36426  Accuracy:  0.94924\n",
      "epoch: 58\n",
      "Average loss:  0.01243  Accuracy:  0.93158  Smallest:  0.00000  Largest:  1.00000  Average:  0.49321\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9841)  (0.5, 2619, 1277)  (1.0, 9869, 9741)\n",
      "Average loss:  0.36628  Accuracy:  0.94069\n",
      "Average loss:  0.02281  Accuracy:  0.88697  Smallest:  0.00000  Largest:  1.00000  Average:  0.55948\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 773)  (0.5, 226, 68)  (1.0, 856, 854)\n",
      "Average loss:  0.36436  Accuracy:  0.94976\n",
      "epoch: 59\n",
      "Average loss:  0.01129  Accuracy:  0.93926  Smallest:  0.00000  Largest:  1.00000  Average:  0.50313\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9804)  (0.5, 2619, 1423)  (1.0, 9869, 9804)\n",
      "Average loss:  0.36594  Accuracy:  0.94207\n",
      "Average loss:  0.01186  Accuracy:  0.93302  Smallest:  0.00000  Largest:  1.00000  Average:  0.52894\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 815)  (0.5, 226, 114)  (1.0, 856, 854)\n",
      "Average loss:  0.36371  Accuracy:  0.95290\n",
      "epoch: 60\n",
      "Average loss:  0.00881  Accuracy:  0.95529  Smallest:  0.00000  Largest:  1.00000  Average:  0.49830\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9876)  (0.5, 2619, 1687)  (1.0, 9869, 9827)\n",
      "Average loss:  0.36540  Accuracy:  0.94212\n",
      "Average loss:  0.00885  Accuracy:  0.95238  Smallest:  0.00000  Largest:  1.00000  Average:  0.51203\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 823)  (0.5, 226, 143)  (1.0, 856, 854)\n",
      "Average loss:  0.36256  Accuracy:  0.95133\n",
      "epoch: 61\n",
      "Average loss:  0.00856  Accuracy:  0.95699  Smallest:  0.00000  Largest:  1.00000  Average:  0.50055\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9866)  (0.5, 2619, 1730)  (1.0, 9869, 9832)\n",
      "Average loss:  0.36462  Accuracy:  0.94458\n",
      "Average loss:  0.00959  Accuracy:  0.95081  Smallest:  0.00000  Largest:  1.00000  Average:  0.48562\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 829)  (0.5, 226, 138)  (1.0, 856, 850)\n",
      "Average loss:  0.36283  Accuracy:  0.95029\n",
      "epoch: 62\n",
      "Average loss:  0.01003  Accuracy:  0.94382  Smallest:  0.00000  Largest:  1.00000  Average:  0.49550\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9868)  (0.5, 2619, 1456)  (1.0, 9869, 9809)\n",
      "Average loss:  0.36421  Accuracy:  0.94650\n",
      "Average loss:  0.01122  Accuracy:  0.93145  Smallest:  0.00000  Largest:  1.00000  Average:  0.48077\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 828)  (0.5, 226, 110)  (1.0, 856, 842)\n",
      "Average loss:  0.36263  Accuracy:  0.95186\n",
      "epoch: 63\n",
      "Average loss:  0.00961  Accuracy:  0.94721  Smallest:  0.00000  Largest:  1.00000  Average:  0.49576\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9872)  (0.5, 2619, 1534)  (1.0, 9869, 9803)\n",
      "Average loss:  0.36391  Accuracy:  0.94694\n",
      "Average loss:  0.01108  Accuracy:  0.93930  Smallest:  0.00000  Largest:  1.00000  Average:  0.53049\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 820)  (0.5, 226, 121)  (1.0, 856, 854)\n",
      "Average loss:  0.36152  Accuracy:  0.95552\n",
      "epoch: 64\n",
      "Average loss:  0.00943  Accuracy:  0.94824  Smallest:  0.00000  Largest:  1.00000  Average:  0.50294\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9849)  (0.5, 2619, 1562)  (1.0, 9869, 9821)\n",
      "Average loss:  0.36344  Accuracy:  0.94815\n",
      "Average loss:  0.00837  Accuracy:  0.95657  Smallest:  0.00000  Largest:  1.00000  Average:  0.50638\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 826)  (0.5, 226, 148)  (1.0, 856, 854)\n",
      "Average loss:  0.36166  Accuracy:  0.95447\n",
      "epoch: 65\n",
      "Average loss:  0.00854  Accuracy:  0.95431  Smallest:  0.00000  Largest:  1.00000  Average:  0.49756\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9872)  (0.5, 2619, 1665)  (1.0, 9869, 9831)\n",
      "Average loss:  0.36289  Accuracy:  0.95145\n",
      "Average loss:  0.00845  Accuracy:  0.95133  Smallest:  0.00000  Largest:  1.00000  Average:  0.49325\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 828)  (0.5, 226, 140)  (1.0, 856, 850)\n",
      "Average loss:  0.35997  Accuracy:  0.95029\n",
      "epoch: 66\n",
      "Average loss:  0.00865  Accuracy:  0.95387  Smallest:  0.00000  Largest:  1.00000  Average:  0.49532\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9877)  (0.5, 2619, 1668)  (1.0, 9869, 9813)\n",
      "Average loss:  0.36228  Accuracy:  0.95092\n",
      "Average loss:  0.02466  Accuracy:  0.86185  Smallest:  0.00000  Largest:  1.00000  Average:  0.56879\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 761)  (0.5, 226, 32)  (1.0, 856, 854)\n",
      "Average loss:  0.36061  Accuracy:  0.95500\n",
      "epoch: 67\n",
      "Average loss:  0.01103  Accuracy:  0.93752  Smallest:  0.00000  Largest:  1.00000  Average:  0.50473\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9838)  (0.5, 2619, 1365)  (1.0, 9869, 9789)\n",
      "Average loss:  0.36187  Accuracy:  0.95226\n",
      "Average loss:  0.00911  Accuracy:  0.94872  Smallest:  0.00000  Largest:  1.00000  Average:  0.48473\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 828)  (0.5, 226, 134)  (1.0, 856, 851)\n",
      "Average loss:  0.35926  Accuracy:  0.95290\n",
      "epoch: 68\n",
      "Average loss:  0.00803  Accuracy:  0.95766  Smallest:  0.00000  Largest:  1.00000  Average:  0.49725\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9880)  (0.5, 2619, 1730)  (1.0, 9869, 9833)\n",
      "Average loss:  0.36159  Accuracy:  0.95293\n",
      "Average loss:  0.00786  Accuracy:  0.96180  Smallest:  0.00000  Largest:  1.00000  Average:  0.51782\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 828)  (0.5, 226, 156)  (1.0, 856, 854)\n",
      "Average loss:  0.35936  Accuracy:  0.95709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 69\n",
      "Average loss:  0.00693  Accuracy:  0.96722  Smallest:  0.00000  Largest:  1.00000  Average:  0.49838\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9892)  (0.5, 2619, 1928)  (1.0, 9869, 9837)\n",
      "Average loss:  0.36088  Accuracy:  0.95561\n",
      "Average loss:  0.00690  Accuracy:  0.96860  Smallest:  0.00000  Largest:  1.00000  Average:  0.49988\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 829)  (0.5, 226, 168)  (1.0, 856, 854)\n",
      "Average loss:  0.35804  Accuracy:  0.95971\n",
      "epoch: 70\n",
      "Average loss:  0.00805  Accuracy:  0.95806  Smallest:  0.00000  Largest:  1.00000  Average:  0.49956\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9874)  (0.5, 2619, 1745)  (1.0, 9869, 9833)\n",
      "Average loss:  0.36040  Accuracy:  0.95574\n",
      "Average loss:  0.01098  Accuracy:  0.93616  Smallest:  0.00000  Largest:  1.00000  Average:  0.47487\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 829)  (0.5, 226, 116)  (1.0, 856, 844)\n",
      "Average loss:  0.35762  Accuracy:  0.95918\n",
      "epoch: 71\n",
      "Average loss:  0.00977  Accuracy:  0.94172  Smallest:  0.00000  Largest:  1.00000  Average:  0.49222\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9873)  (0.5, 2619, 1424)  (1.0, 9869, 9789)\n",
      "Average loss:  0.36011  Accuracy:  0.95695\n",
      "Average loss:  0.00905  Accuracy:  0.94401  Smallest:  0.00000  Largest:  1.00000  Average:  0.51328\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 822)  (0.5, 226, 131)  (1.0, 856, 851)\n",
      "Average loss:  0.35737  Accuracy:  0.96023\n",
      "epoch: 72\n",
      "Average loss:  0.00857  Accuracy:  0.95270  Smallest:  0.00000  Largest:  1.00000  Average:  0.50109\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9861)  (0.5, 2619, 1644)  (1.0, 9869, 9827)\n",
      "Average loss:  0.35969  Accuracy:  0.95900\n",
      "Average loss:  0.01346  Accuracy:  0.92360  Smallest:  0.00000  Largest:  1.00000  Average:  0.54021\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 808)  (0.5, 226, 103)  (1.0, 856, 854)\n",
      "Average loss:  0.36007  Accuracy:  0.96023\n",
      "epoch: 73\n",
      "Average loss:  0.00750  Accuracy:  0.96280  Smallest:  0.00000  Largest:  1.00000  Average:  0.49951\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9883)  (0.5, 2619, 1844)  (1.0, 9869, 9831)\n",
      "Average loss:  0.35937  Accuracy:  0.95891\n",
      "Average loss:  0.00736  Accuracy:  0.96232  Smallest:  0.00000  Largest:  1.00000  Average:  0.49300\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 829)  (0.5, 226, 158)  (1.0, 856, 852)\n",
      "Average loss:  0.35680  Accuracy:  0.96023\n",
      "epoch: 74\n",
      "Average loss:  0.00743  Accuracy:  0.96289  Smallest:  0.00000  Largest:  1.00000  Average:  0.49949\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9878)  (0.5, 2619, 1852)  (1.0, 9869, 9830)\n",
      "Average loss:  0.35868  Accuracy:  0.96101\n",
      "Average loss:  0.01528  Accuracy:  0.90529  Smallest:  0.00000  Largest:  1.00000  Average:  0.46330\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 829)  (0.5, 226, 74)  (1.0, 856, 827)\n",
      "Average loss:  0.35678  Accuracy:  0.96232\n",
      "epoch: 75\n",
      "Average loss:  0.00838  Accuracy:  0.95583  Smallest:  0.00000  Largest:  1.00000  Average:  0.49483\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9873)  (0.5, 2619, 1721)  (1.0, 9869, 9808)\n",
      "Average loss:  0.35825  Accuracy:  0.96123\n",
      "Average loss:  0.01658  Accuracy:  0.90110  Smallest:  0.00000  Largest:  1.00000  Average:  0.54929\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 796)  (0.5, 226, 72)  (1.0, 856, 854)\n",
      "Average loss:  0.35705  Accuracy:  0.96285\n",
      "epoch: 76\n",
      "Average loss:  0.00747  Accuracy:  0.96048  Smallest:  0.00000  Largest:  1.00000  Average:  0.49928\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9884)  (0.5, 2619, 1793)  (1.0, 9869, 9829)\n",
      "Average loss:  0.35780  Accuracy:  0.96204\n",
      "Average loss:  0.00721  Accuracy:  0.96860  Smallest:  0.00000  Largest:  1.00000  Average:  0.51627\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 827)  (0.5, 226, 170)  (1.0, 856, 854)\n",
      "Average loss:  0.35473  Accuracy:  0.96599\n",
      "epoch: 77\n",
      "Average loss:  0.00723  Accuracy:  0.96222  Smallest:  0.00000  Largest:  1.00000  Average:  0.49749\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9889)  (0.5, 2619, 1829)  (1.0, 9869, 9827)\n",
      "Average loss:  0.35733  Accuracy:  0.96248\n",
      "Average loss:  0.00715  Accuracy:  0.96023  Smallest:  0.00000  Largest:  1.00000  Average:  0.51665\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 828)  (0.5, 226, 154)  (1.0, 856, 853)\n",
      "Average loss:  0.35533  Accuracy:  0.96599\n",
      "epoch: 78\n",
      "Average loss:  0.00973  Accuracy:  0.94453  Smallest:  0.00000  Largest:  1.00000  Average:  0.49800\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9840)  (0.5, 2619, 1514)  (1.0, 9869, 9795)\n",
      "Average loss:  0.35718  Accuracy:  0.96342\n",
      "Average loss:  0.00769  Accuracy:  0.96023  Smallest:  0.00000  Largest:  1.00000  Average:  0.51289\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 826)  (0.5, 226, 156)  (1.0, 856, 853)\n",
      "Average loss:  0.35525  Accuracy:  0.96442\n",
      "epoch: 79\n",
      "Average loss:  0.00777  Accuracy:  0.95847  Smallest:  0.00000  Largest:  1.00000  Average:  0.50152\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9874)  (0.5, 2619, 1765)  (1.0, 9869, 9822)\n",
      "Average loss:  0.35701  Accuracy:  0.96423\n",
      "Average loss:  0.01068  Accuracy:  0.94558  Smallest:  0.00000  Largest:  1.00000  Average:  0.53153\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 816)  (0.5, 226, 137)  (1.0, 856, 854)\n",
      "Average loss:  0.35486  Accuracy:  0.96808\n",
      "epoch: 80\n",
      "Average loss:  0.00713  Accuracy:  0.96441  Smallest:  0.00000  Largest:  1.00000  Average:  0.50061\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9884)  (0.5, 2619, 1878)  (1.0, 9869, 9832)\n",
      "Average loss:  0.35622  Accuracy:  0.96449\n",
      "Average loss:  0.00986  Accuracy:  0.93721  Smallest:  0.00000  Largest:  1.00000  Average:  0.47835\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 829)  (0.5, 226, 113)  (1.0, 856, 849)\n",
      "Average loss:  0.35369  Accuracy:  0.96913\n",
      "epoch: 81\n",
      "Average loss:  0.00870  Accuracy:  0.94967  Smallest:  0.00000  Largest:  1.00000  Average:  0.49636\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9870)  (0.5, 2619, 1588)  (1.0, 9869, 9806)\n",
      "Average loss:  0.35554  Accuracy:  0.96686\n",
      "Average loss:  0.01373  Accuracy:  0.92203  Smallest:  0.00000  Largest:  1.00000  Average:  0.46925\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 829)  (0.5, 226, 104)  (1.0, 856, 829)\n",
      "Average loss:  0.35608  Accuracy:  0.96389\n",
      "epoch: 82\n",
      "Average loss:  0.00717  Accuracy:  0.96329  Smallest:  0.00000  Largest:  1.00000  Average:  0.49550\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9884)  (0.5, 2619, 1863)  (1.0, 9869, 9822)\n",
      "Average loss:  0.35543  Accuracy:  0.96601\n",
      "Average loss:  0.01021  Accuracy:  0.94244  Smallest:  0.00000  Largest:  1.00000  Average:  0.48022\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 829)  (0.5, 226, 131)  (1.0, 856, 841)\n",
      "Average loss:  0.35507  Accuracy:  0.97017\n",
      "epoch: 83\n",
      "Average loss:  0.00662  Accuracy:  0.96722  Smallest:  0.00000  Largest:  1.00000  Average:  0.49892\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9884)  (0.5, 2619, 1939)  (1.0, 9869, 9834)\n",
      "Average loss:  0.35498  Accuracy:  0.96753\n",
      "Average loss:  0.00647  Accuracy:  0.96651  Smallest:  0.00000  Largest:  1.00000  Average:  0.49653\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 829)  (0.5, 226, 166)  (1.0, 856, 852)\n",
      "Average loss:  0.35271  Accuracy:  0.96389\n",
      "epoch: 84\n",
      "Average loss:  0.00684  Accuracy:  0.96619  Smallest:  0.00000  Largest:  1.00000  Average:  0.50058\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9886)  (0.5, 2619, 1927)  (1.0, 9869, 9821)\n",
      "Average loss:  0.35468  Accuracy:  0.96784\n",
      "Average loss:  0.00649  Accuracy:  0.96913  Smallest:  0.00000  Largest:  1.00000  Average:  0.49657\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 829)  (0.5, 226, 170)  (1.0, 856, 853)\n",
      "Average loss:  0.35229  Accuracy:  0.97070\n",
      "epoch: 85\n",
      "Average loss:  0.00635  Accuracy:  0.96749  Smallest:  0.00000  Largest:  1.00000  Average:  0.49742\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9887)  (0.5, 2619, 1968)  (1.0, 9869, 9808)\n",
      "Average loss:  0.35393  Accuracy:  0.96936\n",
      "Average loss:  0.00589  Accuracy:  0.97122  Smallest:  0.00000  Largest:  1.00000  Average:  0.50744\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 829)  (0.5, 226, 174)  (1.0, 856, 853)\n",
      "Average loss:  0.35114  Accuracy:  0.97174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 86\n",
      "Average loss:  0.00592  Accuracy:  0.97182  Smallest:  0.00000  Largest:  1.00000  Average:  0.49891\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9889)  (0.5, 2619, 2059)  (1.0, 9869, 9812)\n",
      "Average loss:  0.35322  Accuracy:  0.96994\n",
      "Average loss:  0.00552  Accuracy:  0.97698  Smallest:  0.00000  Largest:  1.00000  Average:  0.50550\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 829)  (0.5, 226, 187)  (1.0, 856, 851)\n",
      "Average loss:  0.35079  Accuracy:  0.97122\n",
      "epoch: 87\n",
      "Average loss:  0.00582  Accuracy:  0.97244  Smallest:  0.00000  Largest:  1.00000  Average:  0.49821\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9894)  (0.5, 2619, 2075)  (1.0, 9869, 9805)\n",
      "Average loss:  0.35256  Accuracy:  0.97124\n",
      "Average loss:  0.01162  Accuracy:  0.92726  Smallest:  0.00000  Largest:  1.00000  Average:  0.53870\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 813)  (0.5, 226, 112)  (1.0, 856, 847)\n",
      "Average loss:  0.35093  Accuracy:  0.97227\n",
      "epoch: 88\n",
      "Average loss:  0.00674  Accuracy:  0.96382  Smallest:  0.00000  Largest:  1.00000  Average:  0.50181\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9887)  (0.5, 2619, 1902)  (1.0, 9869, 9792)\n",
      "Average loss:  0.35200  Accuracy:  0.97258\n",
      "Average loss:  0.00641  Accuracy:  0.96808  Smallest:  0.00000  Largest:  1.00000  Average:  0.49459\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 829)  (0.5, 226, 170)  (1.0, 856, 851)\n",
      "Average loss:  0.34996  Accuracy:  0.97645\n",
      "epoch: 89\n",
      "Average loss:  0.00636  Accuracy:  0.96646  Smallest:  0.00000  Largest:  1.00000  Average:  0.49765\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9888)  (0.5, 2619, 1968)  (1.0, 9869, 9784)\n",
      "Average loss:  0.35203  Accuracy:  0.97267\n",
      "Average loss:  0.00867  Accuracy:  0.93930  Smallest:  0.00000  Largest:  1.00000  Average:  0.52631\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 817)  (0.5, 226, 133)  (1.0, 856, 845)\n",
      "Average loss:  0.34991  Accuracy:  0.96913\n",
      "epoch: 90\n",
      "Average loss:  0.00597  Accuracy:  0.97213  Smallest:  0.00000  Largest:  1.00000  Average:  0.49930\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9890)  (0.5, 2619, 2076)  (1.0, 9869, 9801)\n",
      "Average loss:  0.35137  Accuracy:  0.97356\n",
      "Average loss:  0.00725  Accuracy:  0.95709  Smallest:  0.00000  Largest:  1.00000  Average:  0.52084\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 827)  (0.5, 226, 156)  (1.0, 856, 846)\n",
      "Average loss:  0.34942  Accuracy:  0.97541\n",
      "epoch: 91\n",
      "Average loss:  0.00553  Accuracy:  0.97481  Smallest:  0.00000  Largest:  1.00000  Average:  0.49974\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9894)  (0.5, 2619, 2149)  (1.0, 9869, 9784)\n",
      "Average loss:  0.35084  Accuracy:  0.97499\n",
      "Average loss:  0.00545  Accuracy:  0.96913  Smallest:  0.00000  Largest:  1.00000  Average:  0.49784\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 829)  (0.5, 226, 175)  (1.0, 856, 848)\n",
      "Average loss:  0.34986  Accuracy:  0.97645\n",
      "epoch: 92\n",
      "Average loss:  0.00563  Accuracy:  0.97240  Smallest:  0.00000  Largest:  1.00000  Average:  0.49846\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9892)  (0.5, 2619, 2106)  (1.0, 9869, 9775)\n",
      "Average loss:  0.35077  Accuracy:  0.97401\n",
      "Average loss:  0.01404  Accuracy:  0.91104  Smallest:  0.00000  Largest:  1.00000  Average:  0.46319\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 829)  (0.5, 226, 80)  (1.0, 856, 832)\n",
      "Average loss:  0.34943  Accuracy:  0.97436\n",
      "epoch: 93\n",
      "Average loss:  0.00647  Accuracy:  0.96382  Smallest:  0.00000  Largest:  1.00000  Average:  0.49576\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9887)  (0.5, 2619, 1939)  (1.0, 9869, 9755)\n",
      "Average loss:  0.35018  Accuracy:  0.97687\n",
      "Average loss:  0.01353  Accuracy:  0.92255  Smallest:  0.00000  Largest:  1.00000  Average:  0.54391\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 807)  (0.5, 226, 107)  (1.0, 856, 849)\n",
      "Average loss:  0.34916  Accuracy:  0.97698\n",
      "epoch: 94\n",
      "Average loss:  0.00696  Accuracy:  0.96079  Smallest:  0.00000  Largest:  1.00000  Average:  0.49966\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9874)  (0.5, 2619, 1889)  (1.0, 9869, 9750)\n",
      "Average loss:  0.34985  Accuracy:  0.97678\n",
      "Average loss:  0.01134  Accuracy:  0.92569  Smallest:  0.00000  Largest:  1.00000  Average:  0.47756\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 829)  (0.5, 226, 113)  (1.0, 856, 827)\n",
      "Average loss:  0.35143  Accuracy:  0.96913\n",
      "epoch: 95\n",
      "Average loss:  0.00888  Accuracy:  0.94583  Smallest:  0.00000  Largest:  1.00000  Average:  0.50112\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9860)  (0.5, 2619, 1618)  (1.0, 9869, 9700)\n",
      "Average loss:  0.34957  Accuracy:  0.97642\n",
      "Average loss:  0.00803  Accuracy:  0.95866  Smallest:  0.00000  Largest:  1.00000  Average:  0.51835\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 824)  (0.5, 226, 160)  (1.0, 856, 848)\n",
      "Average loss:  0.34851  Accuracy:  0.97541\n",
      "epoch: 96\n",
      "Average loss:  0.00662  Accuracy:  0.96579  Smallest:  0.00000  Largest:  1.00000  Average:  0.49762\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9882)  (0.5, 2619, 2000)  (1.0, 9869, 9743)\n",
      "Average loss:  0.34965  Accuracy:  0.97566\n",
      "Average loss:  0.00731  Accuracy:  0.95500  Smallest:  0.00000  Largest:  1.00000  Average:  0.51816\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 824)  (0.5, 226, 161)  (1.0, 856, 840)\n",
      "Average loss:  0.34957  Accuracy:  0.97174\n",
      "epoch: 97\n",
      "Average loss:  0.00725  Accuracy:  0.96079  Smallest:  0.00000  Largest:  1.00000  Average:  0.50080\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9866)  (0.5, 2619, 1913)  (1.0, 9869, 9734)\n",
      "Average loss:  0.34914  Accuracy:  0.97727\n",
      "Average loss:  0.00612  Accuracy:  0.97017  Smallest:  0.00000  Largest:  1.00000  Average:  0.50660\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 829)  (0.5, 226, 176)  (1.0, 856, 849)\n",
      "Average loss:  0.34869  Accuracy:  0.97855\n",
      "epoch: 98\n",
      "Average loss:  0.00615  Accuracy:  0.96878  Smallest:  0.00000  Largest:  1.00000  Average:  0.49992\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9888)  (0.5, 2619, 2064)  (1.0, 9869, 9740)\n",
      "Average loss:  0.34903  Accuracy:  0.97740\n",
      "Average loss:  0.00511  Accuracy:  0.97907  Smallest:  0.00000  Largest:  1.00000  Average:  0.49808\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 829)  (0.5, 226, 193)  (1.0, 856, 849)\n",
      "Average loss:  0.34730  Accuracy:  0.97488\n",
      "epoch: 99\n",
      "Average loss:  0.00609  Accuracy:  0.96700  Smallest:  0.00000  Largest:  1.00000  Average:  0.49877\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9887)  (0.5, 2619, 2014)  (1.0, 9869, 9751)\n",
      "Average loss:  0.34818  Accuracy:  0.97785\n",
      "Average loss:  0.00845  Accuracy:  0.95133  Smallest:  0.00000  Largest:  1.00000  Average:  0.48034\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 829)  (0.5, 226, 148)  (1.0, 856, 841)\n",
      "Average loss:  0.34669  Accuracy:  0.97645\n",
      "epoch: 100\n",
      "Average loss:  0.00725  Accuracy:  0.95632  Smallest:  0.00000  Largest:  1.00000  Average:  0.49424\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9884)  (0.5, 2619, 1819)  (1.0, 9869, 9710)\n",
      "Average loss:  0.34763  Accuracy:  0.97838\n",
      "Average loss:  0.00830  Accuracy:  0.94244  Smallest:  0.00000  Largest:  1.00000  Average:  0.52844\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 824)  (0.5, 226, 141)  (1.0, 856, 836)\n",
      "Average loss:  0.34622  Accuracy:  0.97802\n",
      "epoch: 101\n",
      "Average loss:  0.00668  Accuracy:  0.96088  Smallest:  0.00000  Largest:  1.00000  Average:  0.49938\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9885)  (0.5, 2619, 1957)  (1.0, 9869, 9673)\n",
      "Average loss:  0.34760  Accuracy:  0.97910\n",
      "Average loss:  0.00535  Accuracy:  0.97331  Smallest:  0.00000  Largest:  1.00000  Average:  0.50885\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 828)  (0.5, 226, 185)  (1.0, 856, 847)\n",
      "Average loss:  0.34538  Accuracy:  0.98168\n",
      "epoch: 102\n",
      "Average loss:  0.00845  Accuracy:  0.95061  Smallest:  0.00000  Largest:  1.00000  Average:  0.50144\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9839)  (0.5, 2619, 1765)  (1.0, 9869, 9681)\n",
      "Average loss:  0.34760  Accuracy:  0.98080\n",
      "Average loss:  0.00641  Accuracy:  0.96546  Smallest:  0.00000  Largest:  1.00000  Average:  0.49157\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 829)  (0.5, 226, 170)  (1.0, 856, 846)\n",
      "Average loss:  0.34599  Accuracy:  0.97959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 103\n",
      "Average loss:  0.00852  Accuracy:  0.95087  Smallest:  0.00000  Largest:  1.00000  Average:  0.49272\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9858)  (0.5, 2619, 1766)  (1.0, 9869, 9667)\n",
      "Average loss:  0.34748  Accuracy:  0.97941\n",
      "Average loss:  0.00749  Accuracy:  0.94558  Smallest:  0.00000  Largest:  1.00000  Average:  0.51251\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 827)  (0.5, 226, 155)  (1.0, 856, 825)\n",
      "Average loss:  0.34626  Accuracy:  0.97698\n",
      "epoch: 104\n",
      "Average loss:  0.00777  Accuracy:  0.95395  Smallest:  0.00000  Largest:  1.00000  Average:  0.50303\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9854)  (0.5, 2619, 1855)  (1.0, 9869, 9651)\n",
      "Average loss:  0.34715  Accuracy:  0.97932\n",
      "Average loss:  0.00802  Accuracy:  0.95971  Smallest:  0.00000  Largest:  1.00000  Average:  0.49134\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 828)  (0.5, 226, 163)  (1.0, 856, 843)\n",
      "Average loss:  0.34546  Accuracy:  0.98064\n",
      "epoch: 105\n",
      "Average loss:  0.00704  Accuracy:  0.95860  Smallest:  0.00000  Largest:  1.00000  Average:  0.49493\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9876)  (0.5, 2619, 1942)  (1.0, 9869, 9646)\n",
      "Average loss:  0.34687  Accuracy:  0.98008\n",
      "Average loss:  0.01211  Accuracy:  0.91418  Smallest:  0.00000  Largest:  1.00000  Average:  0.53897\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 810)  (0.5, 226, 116)  (1.0, 856, 821)\n",
      "Average loss:  0.34535  Accuracy:  0.98221\n",
      "epoch: 106\n",
      "Average loss:  0.00683  Accuracy:  0.95864  Smallest:  0.00000  Largest:  1.00000  Average:  0.50218\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9868)  (0.5, 2619, 1966)  (1.0, 9869, 9631)\n",
      "Average loss:  0.34603  Accuracy:  0.98205\n",
      "Average loss:  0.01338  Accuracy:  0.91680  Smallest:  0.00000  Largest:  1.00000  Average:  0.46552\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 829)  (0.5, 226, 104)  (1.0, 856, 819)\n",
      "Average loss:  0.34656  Accuracy:  0.98012\n",
      "epoch: 107\n",
      "Average loss:  0.00605  Accuracy:  0.96516  Smallest:  0.00000  Largest:  1.00000  Average:  0.49606\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9886)  (0.5, 2619, 2086)  (1.0, 9869, 9639)\n",
      "Average loss:  0.34614  Accuracy:  0.98097\n",
      "Average loss:  0.01924  Accuracy:  0.87389  Smallest:  0.00000  Largest:  1.00000  Average:  0.55667\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 774)  (0.5, 226, 79)  (1.0, 856, 817)\n",
      "Average loss:  0.34681  Accuracy:  0.97959\n",
      "epoch: 108\n",
      "Average loss:  0.00665  Accuracy:  0.95632  Smallest:  0.00000  Largest:  1.00000  Average:  0.49931\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9875)  (0.5, 2619, 1970)  (1.0, 9869, 9568)\n",
      "Average loss:  0.34532  Accuracy:  0.98254\n",
      "Average loss:  0.00525  Accuracy:  0.96494  Smallest:  0.00000  Largest:  1.00000  Average:  0.51082\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 828)  (0.5, 226, 189)  (1.0, 856, 827)\n",
      "Average loss:  0.34379  Accuracy:  0.98378\n",
      "epoch: 109\n",
      "Average loss:  0.00661  Accuracy:  0.95601  Smallest:  0.00000  Largest:  1.00000  Average:  0.49944\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9871)  (0.5, 2619, 1955)  (1.0, 9869, 9580)\n",
      "Average loss:  0.34559  Accuracy:  0.98151\n",
      "Average loss:  0.00942  Accuracy:  0.93459  Smallest:  0.00000  Largest:  1.00000  Average:  0.47964\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 829)  (0.5, 226, 132)  (1.0, 856, 825)\n",
      "Average loss:  0.34492  Accuracy:  0.98430\n",
      "epoch: 110\n",
      "Average loss:  0.00576  Accuracy:  0.96583  Smallest:  0.00000  Largest:  1.00000  Average:  0.49657\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9885)  (0.5, 2619, 2122)  (1.0, 9869, 9619)\n",
      "Average loss:  0.34486  Accuracy:  0.98294\n",
      "Average loss:  0.00695  Accuracy:  0.94349  Smallest:  0.00000  Largest:  1.00000  Average:  0.52373\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 823)  (0.5, 226, 157)  (1.0, 856, 823)\n",
      "Average loss:  0.34261  Accuracy:  0.98587\n",
      "epoch: 111\n",
      "Average loss:  0.00606  Accuracy:  0.95833  Smallest:  0.00000  Largest:  1.00000  Average:  0.50150\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9873)  (0.5, 2619, 2055)  (1.0, 9869, 9530)\n",
      "Average loss:  0.34454  Accuracy:  0.98352\n",
      "Average loss:  0.00601  Accuracy:  0.95971  Smallest:  0.00000  Largest:  1.00000  Average:  0.50761\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 826)  (0.5, 226, 178)  (1.0, 856, 830)\n",
      "Average loss:  0.34476  Accuracy:  0.98587\n",
      "epoch: 112\n",
      "Average loss:  0.00596  Accuracy:  0.96146  Smallest:  0.00000  Largest:  1.00000  Average:  0.49630\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9877)  (0.5, 2619, 2092)  (1.0, 9869, 9559)\n",
      "Average loss:  0.34441  Accuracy:  0.98312\n",
      "Average loss:  0.00742  Accuracy:  0.94192  Smallest:  0.00000  Largest:  1.00000  Average:  0.48788\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 829)  (0.5, 226, 161)  (1.0, 856, 810)\n",
      "Average loss:  0.34941  Accuracy:  0.98116\n",
      "epoch: 113\n",
      "Average loss:  0.00699  Accuracy:  0.94909  Smallest:  0.00000  Largest:  1.00000  Average:  0.50194\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9871)  (0.5, 2619, 1928)  (1.0, 9869, 9452)\n",
      "Average loss:  0.34418  Accuracy:  0.98379\n",
      "Average loss:  0.00617  Accuracy:  0.95866  Smallest:  0.00000  Largest:  1.00000  Average:  0.49367\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 827)  (0.5, 226, 178)  (1.0, 856, 827)\n",
      "Average loss:  0.34197  Accuracy:  0.98849\n",
      "epoch: 114\n",
      "Average loss:  0.00586  Accuracy:  0.95713  Smallest:  0.00000  Largest:  1.00000  Average:  0.49563\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9885)  (0.5, 2619, 2090)  (1.0, 9869, 9456)\n",
      "Average loss:  0.34386  Accuracy:  0.98325\n",
      "Average loss:  0.00920  Accuracy:  0.93354  Smallest:  0.00000  Largest:  1.00000  Average:  0.53051\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 818)  (0.5, 226, 152)  (1.0, 856, 814)\n",
      "Average loss:  0.34424  Accuracy:  0.98796\n",
      "epoch: 115\n",
      "Average loss:  0.00533  Accuracy:  0.96115  Smallest:  0.00000  Largest:  1.00000  Average:  0.49923\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9884)  (0.5, 2619, 2167)  (1.0, 9869, 9470)\n",
      "Average loss:  0.34322  Accuracy:  0.98432\n",
      "Average loss:  0.00631  Accuracy:  0.94349  Smallest:  0.00000  Largest:  1.00000  Average:  0.49078\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 828)  (0.5, 226, 168)  (1.0, 856, 807)\n",
      "Average loss:  0.34181  Accuracy:  0.98639\n",
      "epoch: 116\n",
      "Average loss:  0.00513  Accuracy:  0.96132  Smallest:  0.00000  Largest:  1.00000  Average:  0.49727\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9889)  (0.5, 2619, 2211)  (1.0, 9869, 9425)\n",
      "Average loss:  0.34246  Accuracy:  0.98687\n",
      "Average loss:  0.00583  Accuracy:  0.94767  Smallest:  0.00000  Largest:  1.00000  Average:  0.49066\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 829)  (0.5, 226, 174)  (1.0, 856, 808)\n",
      "Average loss:  0.34241  Accuracy:  0.98482\n",
      "epoch: 117\n",
      "Average loss:  0.00551  Accuracy:  0.95529  Smallest:  0.00000  Largest:  1.00000  Average:  0.49910\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9878)  (0.5, 2619, 2139)  (1.0, 9869, 9373)\n",
      "Average loss:  0.34171  Accuracy:  0.98745\n",
      "Average loss:  0.01114  Accuracy:  0.91680  Smallest:  0.00000  Largest:  1.00000  Average:  0.47270\n",
      "Category, # Members, # Correct Predictions:  (0.0, 829, 828)  (0.5, 226, 117)  (1.0, 856, 807)\n",
      "Average loss:  0.34444  Accuracy:  0.98639\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "prior_loss_weight = 1\n",
    "\n",
    "viz = Visdom()\n",
    "value_plotter = LossAccPlotter(show_regressions=False, show_averages=False)\n",
    "prior_plotter = LossAccPlotter(show_regressions=False, show_averages=False)\n",
    "\n",
    "n = len(train_gen)\n",
    "for epoch in range(n_epocs):\n",
    "    net = net.train()\n",
    "    \n",
    "    train_stats = CombinedStats()\n",
    "    \n",
    "    for board, value, prior in train_gen:\n",
    "        board, value, prior = board.to(device), value.to(device), prior.to(device)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        value_output, prior_output = net(board)\n",
    "        assert value_output.shape == value.shape\n",
    "        assert prior_output.shape == prior.shape\n",
    "            \n",
    "        value_loss = value_criterion(value_output, value)\n",
    "        prior_loss = prior_criterion(prior_output, prior)\n",
    "        loss = value_loss + prior_loss * prior_loss_weight\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_stats.update(value_output.cpu().detach().numpy(),\n",
    "                           value.cpu().numpy(),\n",
    "                           value_loss,\n",
    "                           prior_output.cpu().detach().numpy(),\n",
    "                           prior.cpu().numpy(),\n",
    "                           prior_loss)\n",
    "    \n",
    "    net.eval()\n",
    "    test_stats = evaluate(test_gen, net, device, value_criterion, prior_criterion)\n",
    "    print(\"epoch: {}\\n{}\\n{}\".format(epoch, train_stats, test_stats))\n",
    "    value_plotter.add_values(epoch,\n",
    "                             loss_train=train_stats.value_stats.loss, acc_train=train_stats.value_stats.accuracy,\n",
    "                             loss_val=test_stats.value_stats.loss, acc_val=test_stats.value_stats.accuracy)\n",
    "    prior_plotter.add_values(epoch,\n",
    "                         loss_train=train_stats.prior_stats.loss, acc_train=train_stats.prior_stats.accuracy,\n",
    "                         loss_val=test_stats.prior_stats.loss, acc_val=test_stats.prior_stats.accuracy)\n",
    "    if epoch == 0:\n",
    "        value_win = viz.matplot(value_plotter.fig)\n",
    "        prior_win = viz.matplot(prior_plotter.fig)\n",
    "    else:\n",
    "        viz.matplot(value_plotter.fig, win=value_win)\n",
    "        viz.matplot(prior_plotter.fig, win=prior_win)\n",
    "            \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
