{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# https://discuss.pytorch.org/t/output-of-resnet34-network-depends-on-the-batch-size/21647\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.manual_seed(999)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epocs = 10000\n",
    "epochs_per_stats = 1\n",
    "batch_size = 4096\n",
    "test_size = 0.2\n",
    "learning_rate = 0.002 * (batch_size / 1024.0)\n",
    "momentum = 0.0\n",
    "\n",
    "WORKING_DIR = '/home/richard/Downloads/nn/PSU_back/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/richard/data/connect4/7ply_boards.pkl', 'rb') as f:\n",
    "    boards = pickle.load(f)\n",
    "with open ('/home/richard/data/connect4/7ply_values.pkl', 'rb') as f:\n",
    "    values = pickle.load(f)\n",
    "\n",
    "board_train, board_test, value_train, value_test = train_test_split(boards, values, test_size=test_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset with 22391 positions\n",
      "Creating dataset with 5598 positions\n"
     ]
    }
   ],
   "source": [
    "from connect4.neural.nn_pytorch import Connect4Dataset\n",
    "\n",
    "train = Connect4Dataset(board_train, value_train, to_move_channel=False)\n",
    "test = Connect4Dataset(board_test, value_test, to_move_channel=False)\n",
    "\n",
    "train_gen = data.DataLoader(train, batch_size, shuffle=True)\n",
    "test_gen = data.DataLoader(test, 4096, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Conv2d(2, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): ResidualLayer(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (batch_norm2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (1): ResidualLayer(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (batch_norm2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (2): ResidualLayer(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (batch_norm2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "  )\n",
       "  (2): ValueHead(\n",
       "    (conv1): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (batch_norm): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): LeakyReLU(negative_slope=0.01)\n",
       "    (fcN): Sequential(\n",
       "      (0): Linear(in_features=42, out_features=42, bias=True)\n",
       "      (1): Linear(in_features=42, out_features=42, bias=True)\n",
       "      (2): Linear(in_features=42, out_features=42, bias=True)\n",
       "      (3): Linear(in_features=42, out_features=42, bias=True)\n",
       "    )\n",
       "    (fc1): Linear(in_features=42, out_features=1, bias=True)\n",
       "    (tanh): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from connect4.neural.nn_pytorch import build_value_net\n",
    "\n",
    "# net = build_value_net(64, value_head_fc_layers=16)\n",
    "net = build_value_net()\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "# criterion = nn.L1Loss(reduction='none')\n",
    "\n",
    "# optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=momentum)\n",
    "optimizer = optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# option to load previous progress\n",
    "# file_path = WORKING_DIR + '../nn9.pth'\n",
    "# file_path = '/home/richard/Downloads/nn/8-1.pth'\n",
    "file_path = None\n",
    "if file_path is not None:\n",
    "    checkpoint = torch.load(file_path)\n",
    "    net.load_state_dict(checkpoint['net_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Test Stats:\n",
      " Average loss:  0.22359  Accuracy:  0.11933  Smallest:  0.45189  Largest:  0.45337  Average:  0.45273\n",
      "Category, # Members, # Correct Predictions:  (0.0, 2398, 0)  (0.5, 668, 668)  (1.0, 2532, 0)\n"
     ]
    }
   ],
   "source": [
    "from connect4.neural.stats import Stats\n",
    "\n",
    "# Get an idea of how the initialisation is\n",
    "def evaluate_fit(net, test_gen, device, output_stats=False):\n",
    "    test_stats = Stats() if output_stats else None\n",
    "    with torch.set_grad_enabled(False):\n",
    "        net = net.eval()\n",
    "        net.train(False)\n",
    "        for board, value in test_gen:\n",
    "            board, value = board.to(device), value.to(device)\n",
    "\n",
    "            output = net(board)\n",
    "#             output = output.view(-1)\n",
    "            assert output.shape == value.shape\n",
    "            \n",
    "            loss = criterion(output, value)\n",
    "#             print(output.shape, value.shape)\n",
    "#             print(output, value, loss)\n",
    "\n",
    "            if output_stats:\n",
    "                output = output.cpu().numpy().flatten()\n",
    "                value = value.cpu().numpy().flatten()\n",
    "                test_stats.update(output, value, loss)\n",
    "    return test_stats\n",
    "\n",
    "test_stats = evaluate_fit(net, test_gen, device, True)\n",
    "print(\"Initial Test Stats:\\n\", test_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 \n",
      "Train:\n",
      " Average loss:  0.21351  Accuracy:  0.11697  Smallest:  0.43786  Largest:  0.61889  Average:  0.48066\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 0)  (0.5, 2619, 2619)  (1.0, 9869, 0) \n",
      "Test:\n",
      " Average loss:  0.22105  Accuracy:  0.11933  Smallest:  0.47924  Largest:  0.48075  Average:  0.47976\n",
      "Category, # Members, # Correct Predictions:  (0.0, 2398, 0)  (0.5, 668, 668)  (1.0, 2532, 0)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1728x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   1 \n",
      "Train:\n",
      " Average loss:  0.18141  Accuracy:  0.17851  Smallest:  0.36680  Largest:  0.83726  Average:  0.51837\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 0)  (0.5, 2619, 2613)  (1.0, 9869, 1384) \n",
      "Test:\n",
      " Average loss:  0.22140  Accuracy:  0.11933  Smallest:  0.47469  Largest:  0.47532  Average:  0.47478\n",
      "Category, # Members, # Correct Predictions:  (0.0, 2398, 0)  (0.5, 668, 668)  (1.0, 2532, 0)\n",
      "Epoch:   2 \n",
      "Train:\n",
      " Average loss:  0.14024  Accuracy:  0.37680  Smallest:  0.23443  Largest:  0.94827  Average:  0.53961\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 630)  (0.5, 2619, 2319)  (1.0, 9869, 5488) \n",
      "Test:\n",
      " Average loss:  0.22234  Accuracy:  0.11933  Smallest:  0.46332  Largest:  0.46582  Average:  0.46357\n",
      "Category, # Members, # Correct Predictions:  (0.0, 2398, 0)  (0.5, 668, 668)  (1.0, 2532, 0)\n",
      "Epoch:   3 \n",
      "Train:\n",
      " Average loss:  0.10018  Accuracy:  0.69148  Smallest:  0.03789  Largest:  0.98053  Average:  0.52778\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 6776)  (0.5, 2619, 1400)  (1.0, 9869, 7307) \n",
      "Test:\n",
      " Average loss:  0.22265  Accuracy:  0.11933  Smallest:  0.45778  Largest:  0.47750  Average:  0.45862\n",
      "Category, # Members, # Correct Predictions:  (0.0, 2398, 0)  (0.5, 668, 668)  (1.0, 2532, 0)\n",
      "Epoch:   4 \n",
      "Train:\n",
      " Average loss:  0.07560  Accuracy:  0.77772  Smallest:  0.00239  Largest:  0.99515  Average:  0.50081\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 8422)  (0.5, 2619, 816)  (1.0, 9869, 8176) \n",
      "Test:\n",
      " Average loss:  0.21242  Accuracy:  0.11933  Smallest:  0.41745  Largest:  0.63623  Average:  0.46884\n",
      "Category, # Members, # Correct Predictions:  (0.0, 2398, 0)  (0.5, 668, 668)  (1.0, 2532, 0)\n",
      "Epoch:   5 \n",
      "Train:\n",
      " Average loss:  0.06655  Accuracy:  0.80081  Smallest:  0.00030  Largest:  0.99916  Average:  0.49923\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 8698)  (0.5, 2619, 712)  (1.0, 9869, 8521) \n",
      "Test:\n",
      " Average loss:  0.14572  Accuracy:  0.34066  Smallest:  0.18647  Largest:  0.88937  Average:  0.53311\n",
      "Category, # Members, # Correct Predictions:  (0.0, 2398, 198)  (0.5, 668, 662)  (1.0, 2532, 1047)\n",
      "Epoch:   6 \n",
      "Train:\n",
      " Average loss:  0.06390  Accuracy:  0.80403  Smallest:  0.00016  Largest:  0.99967  Average:  0.49745\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 8728)  (0.5, 2619, 701)  (1.0, 9869, 8574) \n",
      "Test:\n",
      " Average loss:  0.08773  Accuracy:  0.70489  Smallest:  0.02245  Largest:  0.98472  Average:  0.57058\n",
      "Category, # Members, # Correct Predictions:  (0.0, 2398, 1372)  (0.5, 668, 455)  (1.0, 2532, 2119)\n",
      "Epoch:   7 \n",
      "Train:\n",
      " Average loss:  0.05926  Accuracy:  0.81341  Smallest:  0.00009  Largest:  0.99985  Average:  0.50721\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 8647)  (0.5, 2619, 764)  (1.0, 9869, 8802) \n",
      "Test:\n",
      " Average loss:  0.07157  Accuracy:  0.76545  Smallest:  0.00325  Largest:  0.99415  Average:  0.47505\n",
      "Category, # Members, # Correct Predictions:  (0.0, 2398, 2066)  (0.5, 668, 376)  (1.0, 2532, 1843)\n",
      "Epoch:   8 \n",
      "Train:\n",
      " Average loss:  0.05339  Accuracy:  0.82573  Smallest:  0.00011  Largest:  0.99981  Average:  0.49467\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 8907)  (0.5, 2619, 855)  (1.0, 9869, 8727) \n",
      "Test:\n",
      " Average loss:  0.06447  Accuracy:  0.79153  Smallest:  0.00225  Largest:  0.99735  Average:  0.51476\n",
      "Category, # Members, # Correct Predictions:  (0.0, 2398, 1984)  (0.5, 668, 358)  (1.0, 2532, 2089)\n",
      "Epoch:   9 \n",
      "Train:\n",
      " Average loss:  0.04955  Accuracy:  0.83560  Smallest:  0.00025  Largest:  0.99985  Average:  0.50043\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 8962)  (0.5, 2619, 890)  (1.0, 9869, 8858) \n",
      "Test:\n",
      " Average loss:  0.06062  Accuracy:  0.80529  Smallest:  0.00183  Largest:  0.99928  Average:  0.54762\n",
      "Category, # Members, # Correct Predictions:  (0.0, 2398, 1927)  (0.5, 668, 317)  (1.0, 2532, 2264)\n",
      "Epoch:   10 \n",
      "Train:\n",
      " Average loss:  0.04667  Accuracy:  0.84315  Smallest:  0.00013  Largest:  0.99986  Average:  0.49862\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9056)  (0.5, 2619, 877)  (1.0, 9869, 8946) \n",
      "Test:\n",
      " Average loss:  0.05928  Accuracy:  0.81011  Smallest:  0.00061  Largest:  0.99962  Average:  0.54912\n",
      "Category, # Members, # Correct Predictions:  (0.0, 2398, 1965)  (0.5, 668, 255)  (1.0, 2532, 2315)\n",
      "Epoch:   11 \n",
      "Train:\n",
      " Average loss:  0.04507  Accuracy:  0.84445  Smallest:  0.00012  Largest:  0.99991  Average:  0.50086\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9068)  (0.5, 2619, 810)  (1.0, 9869, 9030) \n",
      "Test:\n",
      " Average loss:  0.06979  Accuracy:  0.78492  Smallest:  0.00066  Largest:  0.99978  Average:  0.59262\n",
      "Category, # Members, # Correct Predictions:  (0.0, 2398, 1793)  (0.5, 668, 210)  (1.0, 2532, 2391)\n",
      "Epoch:   12 \n",
      "Train:\n",
      " Average loss:  0.04166  Accuracy:  0.85208  Smallest:  0.00009  Largest:  0.99995  Average:  0.50282\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9128)  (0.5, 2619, 817)  (1.0, 9869, 9134) \n",
      "Test:\n",
      " Average loss:  0.05521  Accuracy:  0.82065  Smallest:  0.00045  Largest:  0.99961  Average:  0.51099\n",
      "Category, # Members, # Correct Predictions:  (0.0, 2398, 2110)  (0.5, 668, 258)  (1.0, 2532, 2226)\n",
      "Epoch:   13 \n",
      "Train:\n",
      " Average loss:  0.04120  Accuracy:  0.85414  Smallest:  0.00005  Largest:  0.99996  Average:  0.49664\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9220)  (0.5, 2619, 783)  (1.0, 9869, 9122) \n",
      "Test:\n",
      " Average loss:  0.05567  Accuracy:  0.81815  Smallest:  0.00014  Largest:  0.99985  Average:  0.49543\n",
      "Category, # Members, # Correct Predictions:  (0.0, 2398, 2162)  (0.5, 668, 208)  (1.0, 2532, 2210)\n",
      "Epoch:   14 \n",
      "Train:\n",
      " Average loss:  0.03828  Accuracy:  0.85950  Smallest:  0.00005  Largest:  0.99997  Average:  0.50311\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9178)  (0.5, 2619, 836)  (1.0, 9869, 9231) \n",
      "Test:\n",
      " Average loss:  0.05554  Accuracy:  0.81958  Smallest:  0.00005  Largest:  0.99983  Average:  0.48630\n",
      "Category, # Members, # Correct Predictions:  (0.0, 2398, 2203)  (0.5, 668, 191)  (1.0, 2532, 2194)\n",
      "Epoch:   15 \n",
      "Train:\n",
      " Average loss:  0.03647  Accuracy:  0.86459  Smallest:  0.00002  Largest:  0.99998  Average:  0.49749\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9296)  (0.5, 2619, 834)  (1.0, 9869, 9229) \n",
      "Test:\n",
      " Average loss:  0.05448  Accuracy:  0.82637  Smallest:  0.00004  Largest:  0.99993  Average:  0.51742\n",
      "Category, # Members, # Correct Predictions:  (0.0, 2398, 2128)  (0.5, 668, 211)  (1.0, 2532, 2287)\n",
      "Epoch:   16 \n",
      "Train:\n",
      " Average loss:  0.03474  Accuracy:  0.86999  Smallest:  0.00001  Largest:  0.99998  Average:  0.49989\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9324)  (0.5, 2619, 834)  (1.0, 9869, 9322) \n",
      "Test:\n",
      " Average loss:  0.06563  Accuracy:  0.79600  Smallest:  0.00002  Largest:  0.99990  Average:  0.44215\n",
      "Category, # Members, # Correct Predictions:  (0.0, 2398, 2270)  (0.5, 668, 144)  (1.0, 2532, 2042)\n",
      "Epoch:   17 \n",
      "Train:\n",
      " Average loss:  0.03687  Accuracy:  0.86048  Smallest:  0.00000  Largest:  0.99999  Average:  0.49569\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9303)  (0.5, 2619, 742)  (1.0, 9869, 9222) \n",
      "Test:\n",
      " Average loss:  0.06968  Accuracy:  0.79475  Smallest:  0.00000  Largest:  0.99991  Average:  0.43019\n",
      "Category, # Members, # Correct Predictions:  (0.0, 2398, 2302)  (0.5, 668, 128)  (1.0, 2532, 2019)\n",
      "Epoch:   18 \n",
      "Train:\n",
      " Average loss:  0.03581  Accuracy:  0.86303  Smallest:  0.00000  Largest:  0.99998  Average:  0.48660\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9405)  (0.5, 2619, 736)  (1.0, 9869, 9183) \n",
      "Test:\n",
      " Average loss:  0.05602  Accuracy:  0.82422  Smallest:  0.00001  Largest:  0.99997  Average:  0.53881\n",
      "Category, # Members, # Correct Predictions:  (0.0, 2398, 2070)  (0.5, 668, 186)  (1.0, 2532, 2358)\n",
      "Epoch:   19 \n",
      "Train:\n",
      " Average loss:  0.03131  Accuracy:  0.88098  Smallest:  0.00000  Largest:  0.99999  Average:  0.50439\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9381)  (0.5, 2619, 877)  (1.0, 9869, 9468) \n",
      "Test:\n",
      " Average loss:  0.06658  Accuracy:  0.80297  Smallest:  0.00000  Largest:  0.99996  Average:  0.43812\n",
      "Category, # Members, # Correct Predictions:  (0.0, 2398, 2296)  (0.5, 668, 136)  (1.0, 2532, 2063)\n",
      "Epoch:   20 \n",
      "Train:\n",
      " Average loss:  0.02944  Accuracy:  0.88536  Smallest:  0.00000  Largest:  0.99999  Average:  0.49790\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9483)  (0.5, 2619, 895)  (1.0, 9869, 9446) \n",
      "Test:\n",
      " Average loss:  0.06916  Accuracy:  0.79868  Smallest:  0.00004  Largest:  0.99998  Average:  0.59235\n",
      "Category, # Members, # Correct Predictions:  (0.0, 2398, 1867)  (0.5, 668, 164)  (1.0, 2532, 2440)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   21 \n",
      "Train:\n",
      " Average loss:  0.02795  Accuracy:  0.89072  Smallest:  0.00000  Largest:  0.99999  Average:  0.50012\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9514)  (0.5, 2619, 908)  (1.0, 9869, 9522) \n",
      "Test:\n",
      " Average loss:  0.05518  Accuracy:  0.81994  Smallest:  0.00000  Largest:  0.99998  Average:  0.49421\n",
      "Category, # Members, # Correct Predictions:  (0.0, 2398, 2180)  (0.5, 668, 181)  (1.0, 2532, 2229)\n",
      "Epoch:   22 \n",
      "Train:\n",
      " Average loss:  0.02937  Accuracy:  0.88245  Smallest:  0.00000  Largest:  1.00000  Average:  0.49979\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9498)  (0.5, 2619, 793)  (1.0, 9869, 9468) \n",
      "Test:\n",
      " Average loss:  0.05688  Accuracy:  0.81743  Smallest:  0.00001  Largest:  0.99998  Average:  0.54202\n",
      "Category, # Members, # Correct Predictions:  (0.0, 2398, 2041)  (0.5, 668, 183)  (1.0, 2532, 2352)\n",
      "Epoch:   23 \n",
      "Train:\n",
      " Average loss:  0.02807  Accuracy:  0.88710  Smallest:  0.00000  Largest:  1.00000  Average:  0.49353\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9582)  (0.5, 2619, 827)  (1.0, 9869, 9454) \n",
      "Test:\n",
      " Average loss:  0.08822  Accuracy:  0.77099  Smallest:  0.00002  Largest:  0.99999  Average:  0.63034\n",
      "Category, # Members, # Correct Predictions:  (0.0, 2398, 1718)  (0.5, 668, 120)  (1.0, 2532, 2478)\n",
      "Epoch:   24 \n",
      "Train:\n",
      " Average loss:  0.02684  Accuracy:  0.89098  Smallest:  0.00000  Largest:  1.00000  Average:  0.50000\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9526)  (0.5, 2619, 874)  (1.0, 9869, 9550) \n",
      "Test:\n",
      " Average loss:  0.05427  Accuracy:  0.82655  Smallest:  0.00000  Largest:  0.99998  Average:  0.51250\n",
      "Category, # Members, # Correct Predictions:  (0.0, 2398, 2143)  (0.5, 668, 168)  (1.0, 2532, 2316)\n",
      "Epoch:   25 \n",
      "Train:\n",
      " Average loss:  0.02420  Accuracy:  0.90112  Smallest:  0.00000  Largest:  1.00000  Average:  0.49948\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9648)  (0.5, 2619, 917)  (1.0, 9869, 9612) \n",
      "Test:\n",
      " Average loss:  0.05410  Accuracy:  0.82762  Smallest:  0.00000  Largest:  0.99999  Average:  0.51888\n",
      "Category, # Members, # Correct Predictions:  (0.0, 2398, 2151)  (0.5, 668, 158)  (1.0, 2532, 2324)\n",
      "Epoch:   26 \n",
      "Train:\n",
      " Average loss:  0.02288  Accuracy:  0.90371  Smallest:  0.00000  Largest:  1.00000  Average:  0.49805\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9679)  (0.5, 2619, 923)  (1.0, 9869, 9633) \n",
      "Test:\n",
      " Average loss:  0.06417  Accuracy:  0.81458  Smallest:  0.00000  Largest:  0.99999  Average:  0.57201\n",
      "Category, # Members, # Correct Predictions:  (0.0, 2398, 1984)  (0.5, 668, 149)  (1.0, 2532, 2427)\n",
      "Epoch:   27 \n",
      "Train:\n",
      " Average loss:  0.02223  Accuracy:  0.90581  Smallest:  0.00000  Largest:  1.00000  Average:  0.50084\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9666)  (0.5, 2619, 945)  (1.0, 9869, 9671) \n",
      "Test:\n",
      " Average loss:  0.06147  Accuracy:  0.81547  Smallest:  0.00000  Largest:  1.00000  Average:  0.56566\n",
      "Category, # Members, # Correct Predictions:  (0.0, 2398, 2004)  (0.5, 668, 142)  (1.0, 2532, 2419)\n",
      "Epoch:   28 \n",
      "Train:\n",
      " Average loss:  0.02250  Accuracy:  0.90492  Smallest:  0.00000  Largest:  1.00000  Average:  0.50277\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9664)  (0.5, 2619, 947)  (1.0, 9869, 9651) \n",
      "Test:\n",
      " Average loss:  0.05430  Accuracy:  0.82940  Smallest:  0.00000  Largest:  1.00000  Average:  0.49838\n",
      "Category, # Members, # Correct Predictions:  (0.0, 2398, 2199)  (0.5, 668, 151)  (1.0, 2532, 2293)\n",
      "Epoch:   29 \n",
      "Train:\n",
      " Average loss:  0.02051  Accuracy:  0.91282  Smallest:  0.00000  Largest:  1.00000  Average:  0.50011\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9714)  (0.5, 2619, 1024)  (1.0, 9869, 9701) \n",
      "Test:\n",
      " Average loss:  0.06705  Accuracy:  0.80386  Smallest:  0.00000  Largest:  0.99998  Average:  0.44009\n",
      "Category, # Members, # Correct Predictions:  (0.0, 2398, 2290)  (0.5, 668, 119)  (1.0, 2532, 2091)\n",
      "Epoch:   30 \n",
      "Train:\n",
      " Average loss:  0.02428  Accuracy:  0.89473  Smallest:  0.00000  Largest:  1.00000  Average:  0.49614\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9634)  (0.5, 2619, 813)  (1.0, 9869, 9587) \n",
      "Test:\n",
      " Average loss:  0.09614  Accuracy:  0.76313  Smallest:  0.00000  Largest:  0.99998  Average:  0.38129\n",
      "Category, # Members, # Correct Predictions:  (0.0, 2398, 2343)  (0.5, 668, 67)  (1.0, 2532, 1862)\n",
      "Epoch:   31 \n",
      "Train:\n",
      " Average loss:  0.02532  Accuracy:  0.89371  Smallest:  0.00000  Largest:  1.00000  Average:  0.48812\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9661)  (0.5, 2619, 838)  (1.0, 9869, 9512) \n",
      "Test:\n",
      " Average loss:  0.05652  Accuracy:  0.82905  Smallest:  0.00000  Largest:  1.00000  Average:  0.52240\n",
      "Category, # Members, # Correct Predictions:  (0.0, 2398, 2134)  (0.5, 668, 149)  (1.0, 2532, 2358)\n",
      "Epoch:   32 \n",
      "Train:\n",
      " Average loss:  0.02168  Accuracy:  0.90492  Smallest:  0.00000  Largest:  1.00000  Average:  0.50291\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9638)  (0.5, 2619, 936)  (1.0, 9869, 9688) \n",
      "Test:\n",
      " Average loss:  0.05459  Accuracy:  0.82887  Smallest:  0.00000  Largest:  1.00000  Average:  0.51163\n",
      "Category, # Members, # Correct Predictions:  (0.0, 2398, 2168)  (0.5, 668, 162)  (1.0, 2532, 2310)\n",
      "Epoch:   33 \n",
      "Train:\n",
      " Average loss:  0.01928  Accuracy:  0.91675  Smallest:  0.00000  Largest:  1.00000  Average:  0.49753\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9738)  (0.5, 2619, 1079)  (1.0, 9869, 9710) \n",
      "Test:\n",
      " Average loss:  0.05703  Accuracy:  0.82690  Smallest:  0.00000  Largest:  1.00000  Average:  0.54282\n",
      "Category, # Members, # Correct Predictions:  (0.0, 2398, 2086)  (0.5, 668, 157)  (1.0, 2532, 2386)\n",
      "Epoch:   34 \n",
      "Train:\n",
      " Average loss:  0.01937  Accuracy:  0.91291  Smallest:  0.00000  Largest:  1.00000  Average:  0.50383\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9704)  (0.5, 2619, 1006)  (1.0, 9869, 9731) \n",
      "Test:\n",
      " Average loss:  0.05764  Accuracy:  0.82404  Smallest:  0.00000  Largest:  0.99999  Average:  0.47504\n",
      "Category, # Members, # Correct Predictions:  (0.0, 2398, 2243)  (0.5, 668, 149)  (1.0, 2532, 2221)\n",
      "Epoch:   35 \n",
      "Train:\n",
      " Average loss:  0.02134  Accuracy:  0.90313  Smallest:  0.00000  Largest:  1.00000  Average:  0.49514\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9694)  (0.5, 2619, 895)  (1.0, 9869, 9633) \n",
      "Test:\n",
      " Average loss:  0.05854  Accuracy:  0.82512  Smallest:  0.00000  Largest:  1.00000  Average:  0.54202\n",
      "Category, # Members, # Correct Predictions:  (0.0, 2398, 2087)  (0.5, 668, 148)  (1.0, 2532, 2384)\n",
      "Epoch:   36 \n",
      "Train:\n",
      " Average loss:  0.02235  Accuracy:  0.89902  Smallest:  0.00000  Largest:  1.00000  Average:  0.49940\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9661)  (0.5, 2619, 846)  (1.0, 9869, 9623) \n",
      "Test:\n",
      " Average loss:  0.05439  Accuracy:  0.83155  Smallest:  0.00000  Largest:  1.00000  Average:  0.51523\n",
      "Category, # Members, # Correct Predictions:  (0.0, 2398, 2156)  (0.5, 668, 171)  (1.0, 2532, 2328)\n",
      "Epoch:   37 \n",
      "Train:\n",
      " Average loss:  0.01878  Accuracy:  0.91492  Smallest:  0.00000  Largest:  1.00000  Average:  0.49977\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9751)  (0.5, 2619, 1005)  (1.0, 9869, 9730) \n",
      "Test:\n",
      " Average loss:  0.05877  Accuracy:  0.82136  Smallest:  0.00000  Largest:  1.00000  Average:  0.54942\n",
      "Category, # Members, # Correct Predictions:  (0.0, 2398, 2060)  (0.5, 668, 139)  (1.0, 2532, 2399)\n",
      "Epoch:   38 \n",
      "Train:\n",
      " Average loss:  0.01905  Accuracy:  0.91354  Smallest:  0.00000  Largest:  1.00000  Average:  0.50246\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9710)  (0.5, 2619, 1016)  (1.0, 9869, 9729) \n",
      "Test:\n",
      " Average loss:  0.05389  Accuracy:  0.82922  Smallest:  0.00000  Largest:  0.99999  Average:  0.49452\n",
      "Category, # Members, # Correct Predictions:  (0.0, 2398, 2211)  (0.5, 668, 158)  (1.0, 2532, 2273)\n",
      "Epoch:   39 \n",
      "Train:\n",
      " Average loss:  0.01689  Accuracy:  0.92644  Smallest:  0.00000  Largest:  1.00000  Average:  0.49669\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9789)  (0.5, 2619, 1212)  (1.0, 9869, 9743) \n",
      "Test:\n",
      " Average loss:  0.06474  Accuracy:  0.81100  Smallest:  0.00000  Largest:  1.00000  Average:  0.57384\n",
      "Category, # Members, # Correct Predictions:  (0.0, 2398, 1974)  (0.5, 668, 125)  (1.0, 2532, 2441)\n",
      "Epoch:   40 \n",
      "Train:\n",
      " Average loss:  0.01630  Accuracy:  0.92711  Smallest:  0.00000  Largest:  1.00000  Average:  0.50218\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9782)  (0.5, 2619, 1216)  (1.0, 9869, 9761) \n",
      "Test:\n",
      " Average loss:  0.05943  Accuracy:  0.81726  Smallest:  0.00000  Largest:  1.00000  Average:  0.55032\n",
      "Category, # Members, # Correct Predictions:  (0.0, 2398, 2043)  (0.5, 668, 142)  (1.0, 2532, 2390)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   41 \n",
      "Train:\n",
      " Average loss:  0.01561  Accuracy:  0.92997  Smallest:  0.00000  Largest:  1.00000  Average:  0.49584\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9808)  (0.5, 2619, 1241)  (1.0, 9869, 9774) \n",
      "Test:\n",
      " Average loss:  0.05490  Accuracy:  0.82440  Smallest:  0.00000  Largest:  1.00000  Average:  0.52414\n",
      "Category, # Members, # Correct Predictions:  (0.0, 2398, 2137)  (0.5, 668, 135)  (1.0, 2532, 2343)\n",
      "Epoch:   42 \n",
      "Train:\n",
      " Average loss:  0.01519  Accuracy:  0.93189  Smallest:  0.00000  Largest:  1.00000  Average:  0.50205\n",
      "Category, # Members, # Correct Predictions:  (0.0, 9903, 9807)  (0.5, 2619, 1269)  (1.0, 9869, 9790) \n",
      "Test:\n",
      " Average loss:  0.05469  Accuracy:  0.83065  Smallest:  0.00000  Largest:  1.00000  Average:  0.50339\n",
      "Category, # Members, # Correct Predictions:  (0.0, 2398, 2183)  (0.5, 668, 157)  (1.0, 2532, 2310)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \"\"\"\n\u001b[0;32m--> 219\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_with_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_with_file_like\u001b[0;34m(f, mode, body)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_fd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \"\"\"\n\u001b[0;32m--> 219\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_with_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0mpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0mpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m     \u001b[0mpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0mserialized_storage_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialized_storages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__reduce_ex__\u001b[0;34m(self, proto)\u001b[0m\n\u001b[1;32m     36\u001b[0m         args = (self.storage(),\n\u001b[1;32m     37\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage_offset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                 \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from laplotter import LossAccPlotter\n",
    "from visdom import Visdom\n",
    "\n",
    "viz = Visdom()\n",
    "plotter = LossAccPlotter(show_regressions=False, show_averages=False)\n",
    "\n",
    "for epoch in range(n_epocs):\n",
    "    \n",
    "    net = net.train()\n",
    "    train_stats = Stats()\n",
    "    \n",
    "    for board, value in train_gen:\n",
    "        board, value = board.to(device), value.to(device)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        output = net(board)\n",
    "#         output = output.view(-1)\n",
    "        assert output.shape == value.shape\n",
    "            \n",
    "        loss = criterion(output, value)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch % epochs_per_stats == 0:\n",
    "            output = output.cpu().view(-1).detach().numpy()\n",
    "            value = value.cpu().view(-1).numpy()\n",
    "            train_stats.update(output, value, loss)\n",
    "\n",
    "    # validate\n",
    "    test_stats = evaluate_fit(net, test_gen, device, epoch % epochs_per_stats == 0)\n",
    "                \n",
    "    if test_stats is not None:            \n",
    "        print(\"Epoch:  \", epoch, \"\\nTrain:\\n\", train_stats, \"\\nTest:\\n\", test_stats)\n",
    "        plotter.add_values(epoch,\n",
    "                           loss_train=train_stats.loss, acc_train=train_stats.accuracy,\n",
    "                           loss_val=test_stats.loss, acc_val=test_stats.accuracy)\n",
    "        if epoch == 0:\n",
    "            win = viz.matplot(plotter.fig)\n",
    "        else:\n",
    "            viz.matplot(plotter.fig, win=win)\n",
    "        \n",
    "    torch.save({\n",
    "        'net_state_dict': net.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict()},\n",
    "        WORKING_DIR + str(epoch) + '-' + str(batch_size) + '.pth')\n",
    "            \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plotter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-e76209a9e63b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplotter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'plotter' is not defined"
     ]
    }
   ],
   "source": [
    "plotter.fig"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
