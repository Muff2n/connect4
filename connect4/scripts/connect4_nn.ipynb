{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# https://discuss.pytorch.org/t/output-of-resnet34-network-depends-on-the-batch-size/21647\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.manual_seed(999)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epocs = 10000\n",
    "epochs_per_stats = 1\n",
    "batch_size = 4096\n",
    "test_size = 0.2\n",
    "learning_rate = 0.002 * (batch_size / 1024.0)\n",
    "momentum = 0.0\n",
    "\n",
    "WORKING_DIR = '/home/richard/Downloads/nn/PSU_back/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "boards = torch.load('/home/richard/Downloads/connect4_boards.pth').numpy()\n",
    "values = torch.load('/home/richard/Downloads/connect4_values.pth').numpy()\n",
    "\n",
    "# Here we don't want to have the player to move channel\n",
    "boards = boards[:, 1:]\n",
    "\n",
    "board_train, board_test, value_train, value_test = train_test_split(boards, values, test_size=test_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from connect4.neural.nn_pytorch import Connect4Dataset\n",
    "\n",
    "train = Connect4Dataset(board_train, value_train)\n",
    "test = Connect4Dataset(board_test, value_test)\n",
    "\n",
    "train_gen = data.DataLoader(train, batch_size, shuffle=True)\n",
    "test_gen = data.DataLoader(test, 4096, shuffle=False)\n",
    "# test_gen = data.DataLoader(test, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): ResidualLayer(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (batch_norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (1): ResidualLayer(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (batch_norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (2): ResidualLayer(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (batch_norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "  )\n",
       "  (2): ValueHead(\n",
       "    (conv1): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (batch_norm): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): LeakyReLU(negative_slope=0.01)\n",
       "    (fcN): Sequential(\n",
       "      (0): Linear(in_features=42, out_features=42, bias=True)\n",
       "      (1): Linear(in_features=42, out_features=42, bias=True)\n",
       "      (2): Linear(in_features=42, out_features=42, bias=True)\n",
       "      (3): Linear(in_features=42, out_features=42, bias=True)\n",
       "      (4): Linear(in_features=42, out_features=42, bias=True)\n",
       "      (5): Linear(in_features=42, out_features=42, bias=True)\n",
       "      (6): Linear(in_features=42, out_features=42, bias=True)\n",
       "      (7): Linear(in_features=42, out_features=42, bias=True)\n",
       "      (8): Linear(in_features=42, out_features=42, bias=True)\n",
       "      (9): Linear(in_features=42, out_features=42, bias=True)\n",
       "      (10): Linear(in_features=42, out_features=42, bias=True)\n",
       "      (11): Linear(in_features=42, out_features=42, bias=True)\n",
       "      (12): Linear(in_features=42, out_features=42, bias=True)\n",
       "      (13): Linear(in_features=42, out_features=42, bias=True)\n",
       "      (14): Linear(in_features=42, out_features=42, bias=True)\n",
       "      (15): Linear(in_features=42, out_features=42, bias=True)\n",
       "    )\n",
       "    (fc1): Linear(in_features=42, out_features=1, bias=True)\n",
       "    (tanh): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from connect4.neural.nn_pytorch import build_value_net\n",
    "\n",
    "net = build_value_net(64, value_head_fc_layers=16)\n",
    "\n",
    "def init_normal(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.normal_(m.weight, std=0.0000001)\n",
    "    elif type(m) == nn.Conv2d:\n",
    "        nn.init.normal_(m.weight, std=0.0000001)\n",
    "    elif type(m) == nn.BatchNorm2d:\n",
    "        nn.init.normal_(m.weight, std=0.0000001)\n",
    "#         nn.init.constant_(m.bias, 0)\n",
    "\n",
    "# net.apply(init_normal)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "# criterion = nn.L1Loss(reduction='none')\n",
    "\n",
    "# optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=momentum)\n",
    "optimizer = optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# option to load previous progress\n",
    "# file_path = WORKING_DIR + '../nn9.pth'\n",
    "# file_path = '/home/richard/Downloads/nn/8-1.pth'\n",
    "file_path = None\n",
    "if file_path is not None:\n",
    "    checkpoint = torch.load(file_path)\n",
    "    net.load_state_dict(checkpoint['net_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Test Stats:\n",
      " Average loss:  0.24114  Accuracy:  0.09458  Smallest:  0.46713  Largest:  0.46713  Average:  0.46713\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 0)  (0.5, 1278, 1278)  (1.0, 8934, 0)\n"
     ]
    }
   ],
   "source": [
    "from connect4.neural.stats import Stats\n",
    "\n",
    "# Get an idea of how the initialisation is\n",
    "def evaluate_fit(net, test_gen, device, output_stats=False):\n",
    "    test_stats = Stats() if output_stats else None\n",
    "    with torch.set_grad_enabled(False):\n",
    "        net = net.eval()\n",
    "        net.train(False)\n",
    "        for board, value in test_gen:\n",
    "            board, value = board.to(device), value.to(device)\n",
    "\n",
    "            output = net(board)\n",
    "            output = output.view(-1)\n",
    "            assert output.shape == value.shape\n",
    "            \n",
    "            loss = criterion(output, value)\n",
    "#             print(output.shape, value.shape)\n",
    "#             print(output, value, loss)\n",
    "\n",
    "            if output_stats:\n",
    "                output = output.cpu().numpy().flatten()\n",
    "                value = value.cpu().numpy().flatten()\n",
    "                test_stats.update(output, value, loss)\n",
    "    return test_stats\n",
    "\n",
    "test_stats = evaluate_fit(net, test_gen, device, True)\n",
    "print(\"Initial Test Stats:\\n\", test_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 \n",
      "Train:\n",
      " Average loss:  0.21300  Accuracy:  0.09581  Smallest:  0.46712  Largest:  0.67049  Average:  0.54264\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 0)  (0.5, 5171, 5171)  (1.0, 35539, 7) \n",
      "Test:\n",
      " Average loss:  0.18376  Accuracy:  0.66119  Smallest:  0.67833  Largest:  0.67918  Average:  0.67867\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 0)  (0.5, 1278, 0)  (1.0, 8934, 8934)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1728x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   1 \n",
      "Train:\n",
      " Average loss:  0.17103  Accuracy:  0.65758  Smallest:  0.67775  Largest:  0.93207  Average:  0.76127\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 0)  (0.5, 5171, 0)  (1.0, 35539, 35539) \n",
      "Test:\n",
      " Average loss:  0.18271  Accuracy:  0.66119  Smallest:  0.67716  Largest:  0.71101  Average:  0.67927\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 0)  (0.5, 1278, 0)  (1.0, 8934, 8934)\n",
      "Epoch:   2 \n",
      "Train:\n",
      " Average loss:  0.12314  Accuracy:  0.64169  Smallest:  0.50258  Largest:  0.99958  Average:  0.78839\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 0)  (0.5, 5171, 2381)  (1.0, 35539, 32299) \n",
      "Test:\n",
      " Average loss:  0.16578  Accuracy:  0.32201  Smallest:  0.49182  Largest:  0.99614  Average:  0.58696\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 0)  (0.5, 1278, 1271)  (1.0, 8934, 3080)\n",
      "Epoch:   3 \n",
      "Train:\n",
      " Average loss:  0.08078  Accuracy:  0.70671  Smallest:  0.05082  Largest:  1.00000  Average:  0.74609\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 5250)  (0.5, 5171, 2279)  (1.0, 35539, 30665) \n",
      "Test:\n",
      " Average loss:  0.07318  Accuracy:  0.77664  Smallest:  0.05184  Largest:  1.00000  Average:  0.77580\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 1627)  (0.5, 1278, 432)  (1.0, 8934, 8435)\n",
      "Epoch:   4 \n",
      "Train:\n",
      " Average loss:  0.05998  Accuracy:  0.80625  Smallest:  0.01599  Largest:  1.00000  Average:  0.70588\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 9629)  (0.5, 5171, 1787)  (1.0, 35539, 32158) \n",
      "Test:\n",
      " Average loss:  0.10317  Accuracy:  0.73572  Smallest:  0.03744  Largest:  1.00000  Average:  0.56440\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 3138)  (0.5, 1278, 290)  (1.0, 8934, 6513)\n",
      "Epoch:   5 \n",
      "Train:\n",
      " Average loss:  0.05303  Accuracy:  0.82837  Smallest:  0.03386  Largest:  1.00000  Average:  0.70454\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 10519)  (0.5, 5171, 1794)  (1.0, 35539, 32456) \n",
      "Test:\n",
      " Average loss:  0.05897  Accuracy:  0.80943  Smallest:  0.04110  Largest:  1.00000  Average:  0.68749\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2602)  (0.5, 1278, 464)  (1.0, 8934, 7871)\n",
      "Epoch:   6 \n",
      "Train:\n",
      " Average loss:  0.04826  Accuracy:  0.83850  Smallest:  0.01383  Largest:  1.00000  Average:  0.70744\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 10522)  (0.5, 5171, 1836)  (1.0, 35539, 32959) \n",
      "Test:\n",
      " Average loss:  0.07942  Accuracy:  0.78012  Smallest:  0.01426  Largest:  1.00000  Average:  0.60302\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 3031)  (0.5, 1278, 354)  (1.0, 8934, 7156)\n",
      "Epoch:   7 \n",
      "Train:\n",
      " Average loss:  0.04319  Accuracy:  0.84914  Smallest:  0.01351  Largest:  1.00000  Average:  0.70546\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 10999)  (0.5, 5171, 1758)  (1.0, 35539, 33135) \n",
      "Test:\n",
      " Average loss:  0.06072  Accuracy:  0.81202  Smallest:  0.01300  Largest:  1.00000  Average:  0.65956\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2873)  (0.5, 1278, 385)  (1.0, 8934, 7714)\n",
      "Epoch:   8 \n",
      "Train:\n",
      " Average loss:  0.03988  Accuracy:  0.85392  Smallest:  0.00972  Largest:  1.00000  Average:  0.70909\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 11166)  (0.5, 5171, 1740)  (1.0, 35539, 33244) \n",
      "Test:\n",
      " Average loss:  0.05876  Accuracy:  0.81135  Smallest:  0.00801  Largest:  1.00000  Average:  0.66848\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2909)  (0.5, 1278, 362)  (1.0, 8934, 7692)\n",
      "Epoch:   9 \n",
      "Train:\n",
      " Average loss:  0.03805  Accuracy:  0.85297  Smallest:  0.00807  Largest:  1.00000  Average:  0.70607\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 11406)  (0.5, 5171, 1710)  (1.0, 35539, 32983) \n",
      "Test:\n",
      " Average loss:  0.05692  Accuracy:  0.81343  Smallest:  0.00987  Largest:  1.00000  Average:  0.75657\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2300)  (0.5, 1278, 332)  (1.0, 8934, 8359)\n",
      "Epoch:   10 \n",
      "Train:\n",
      " Average loss:  0.03467  Accuracy:  0.85049  Smallest:  0.00403  Largest:  1.00000  Average:  0.70773\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 11536)  (0.5, 5171, 1748)  (1.0, 35539, 32681) \n",
      "Test:\n",
      " Average loss:  0.05394  Accuracy:  0.82208  Smallest:  0.00540  Largest:  1.00000  Average:  0.66894\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2931)  (0.5, 1278, 375)  (1.0, 8934, 7802)\n",
      "Epoch:   11 \n",
      "Train:\n",
      " Average loss:  0.03136  Accuracy:  0.84666  Smallest:  0.00357  Largest:  1.00000  Average:  0.70740\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 11844)  (0.5, 5171, 1732)  (1.0, 35539, 32182) \n",
      "Test:\n",
      " Average loss:  0.05050  Accuracy:  0.82541  Smallest:  0.00487  Largest:  1.00000  Average:  0.69626\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2777)  (0.5, 1278, 406)  (1.0, 8934, 7970)\n",
      "Epoch:   12 \n",
      "Train:\n",
      " Average loss:  0.03085  Accuracy:  0.83962  Smallest:  0.00301  Largest:  1.00000  Average:  0.70915\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 11839)  (0.5, 5171, 1688)  (1.0, 35539, 31850) \n",
      "Test:\n",
      " Average loss:  0.04887  Accuracy:  0.79559  Smallest:  0.00430  Largest:  1.00000  Average:  0.72859\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2641)  (0.5, 1278, 335)  (1.0, 8934, 7774)\n",
      "Epoch:   13 \n",
      "Train:\n",
      " Average loss:  0.02880  Accuracy:  0.83497  Smallest:  0.00235  Largest:  1.00000  Average:  0.70725\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 12075)  (0.5, 5171, 1670)  (1.0, 35539, 31381) \n",
      "Test:\n",
      " Average loss:  0.08169  Accuracy:  0.77879  Smallest:  0.00373  Largest:  1.00000  Average:  0.59890\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 3147)  (0.5, 1278, 291)  (1.0, 8934, 7085)\n",
      "Epoch:   14 \n",
      "Train:\n",
      " Average loss:  0.02841  Accuracy:  0.85205  Smallest:  0.00214  Largest:  1.00000  Average:  0.70709\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 12044)  (0.5, 5171, 1698)  (1.0, 35539, 32307) \n",
      "Test:\n",
      " Average loss:  0.05175  Accuracy:  0.81557  Smallest:  0.00443  Largest:  1.00000  Average:  0.67859\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2934)  (0.5, 1278, 344)  (1.0, 8934, 7742)\n",
      "Epoch:   15 \n",
      "Train:\n",
      " Average loss:  0.02458  Accuracy:  0.84504  Smallest:  0.00131  Largest:  1.00000  Average:  0.70667\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 12329)  (0.5, 5171, 1661)  (1.0, 35539, 31680) \n",
      "Test:\n",
      " Average loss:  0.04876  Accuracy:  0.79448  Smallest:  0.00242  Largest:  1.00000  Average:  0.70628\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2806)  (0.5, 1278, 348)  (1.0, 8934, 7581)\n",
      "Epoch:   16 \n",
      "Train:\n",
      " Average loss:  0.02423  Accuracy:  0.83155  Smallest:  0.00097  Largest:  1.00000  Average:  0.70752\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 12384)  (0.5, 5171, 1611)  (1.0, 35539, 30946) \n",
      "Test:\n",
      " Average loss:  0.05000  Accuracy:  0.82652  Smallest:  0.00616  Largest:  1.00000  Average:  0.69741\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2818)  (0.5, 1278, 374)  (1.0, 8934, 7976)\n",
      "Epoch:   17 \n",
      "Train:\n",
      " Average loss:  0.02271  Accuracy:  0.82418  Smallest:  0.00099  Largest:  1.00000  Average:  0.70844\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 12460)  (0.5, 5171, 1604)  (1.0, 35539, 30479) \n",
      "Test:\n",
      " Average loss:  0.05353  Accuracy:  0.80699  Smallest:  0.00329  Largest:  1.00000  Average:  0.67100\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2945)  (0.5, 1278, 325)  (1.0, 8934, 7634)\n",
      "Epoch:   18 \n",
      "Train:\n",
      " Average loss:  0.01977  Accuracy:  0.82041  Smallest:  0.00058  Largest:  1.00000  Average:  0.70937\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 12617)  (0.5, 5171, 1792)  (1.0, 35539, 29930) \n",
      "Test:\n",
      " Average loss:  0.06738  Accuracy:  0.78538  Smallest:  0.00132  Largest:  1.00000  Average:  0.62944\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 3101)  (0.5, 1278, 307)  (1.0, 8934, 7204)\n",
      "Epoch:   19 \n",
      "Train:\n",
      " Average loss:  0.01914  Accuracy:  0.82763  Smallest:  0.00050  Largest:  1.00000  Average:  0.70658\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 12698)  (0.5, 5171, 1780)  (1.0, 35539, 30251) \n",
      "Test:\n",
      " Average loss:  0.05186  Accuracy:  0.72417  Smallest:  0.00106  Largest:  1.00000  Average:  0.72593\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2668)  (0.5, 1278, 294)  (1.0, 8934, 6823)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   20 \n",
      "Train:\n",
      " Average loss:  0.01894  Accuracy:  0.82026  Smallest:  0.00054  Largest:  1.00000  Average:  0.70716\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 12711)  (0.5, 5171, 1749)  (1.0, 35539, 29871) \n",
      "Test:\n",
      " Average loss:  0.05106  Accuracy:  0.78427  Smallest:  0.00075  Largest:  1.00000  Average:  0.69823\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2846)  (0.5, 1278, 324)  (1.0, 8934, 7427)\n",
      "Epoch:   21 \n",
      "Train:\n",
      " Average loss:  0.01690  Accuracy:  0.82685  Smallest:  0.00035  Largest:  1.00000  Average:  0.70793\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 12782)  (0.5, 5171, 1865)  (1.0, 35539, 30040) \n",
      "Test:\n",
      " Average loss:  0.06407  Accuracy:  0.79766  Smallest:  0.00058  Largest:  1.00000  Average:  0.64053\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 3041)  (0.5, 1278, 311)  (1.0, 8934, 7426)\n",
      "Epoch:   22 \n",
      "Train:\n",
      " Average loss:  0.01869  Accuracy:  0.83231  Smallest:  0.00046  Largest:  1.00000  Average:  0.70726\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 12653)  (0.5, 5171, 1809)  (1.0, 35539, 30520) \n",
      "Test:\n",
      " Average loss:  0.05283  Accuracy:  0.80129  Smallest:  0.00184  Largest:  1.00000  Average:  0.73761\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2563)  (0.5, 1278, 321)  (1.0, 8934, 7943)\n",
      "Epoch:   23 \n",
      "Train:\n",
      " Average loss:  0.02038  Accuracy:  0.85216  Smallest:  0.00141  Largest:  1.00000  Average:  0.71086\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 12484)  (0.5, 5171, 1856)  (1.0, 35539, 31715) \n",
      "Test:\n",
      " Average loss:  0.07889  Accuracy:  0.76976  Smallest:  0.00101  Largest:  1.00000  Average:  0.60801\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 3169)  (0.5, 1278, 254)  (1.0, 8934, 6978)\n",
      "Epoch:   24 \n",
      "Train:\n",
      " Average loss:  0.01673  Accuracy:  0.83059  Smallest:  0.00056  Largest:  1.00000  Average:  0.70608\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 12806)  (0.5, 5171, 1875)  (1.0, 35539, 30208) \n",
      "Test:\n",
      " Average loss:  0.06087  Accuracy:  0.78767  Smallest:  0.00074  Largest:  1.00000  Average:  0.65483\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 3009)  (0.5, 1278, 316)  (1.0, 8934, 7318)\n",
      "Epoch:   25 \n",
      "Train:\n",
      " Average loss:  0.01427  Accuracy:  0.82224  Smallest:  0.00030  Largest:  1.00000  Average:  0.70840\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 12912)  (0.5, 5171, 2067)  (1.0, 35539, 29459) \n",
      "Test:\n",
      " Average loss:  0.05303  Accuracy:  0.73172  Smallest:  0.00039  Largest:  1.00000  Average:  0.69793\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2882)  (0.5, 1278, 273)  (1.0, 8934, 6732)\n",
      "Epoch:   26 \n",
      "Train:\n",
      " Average loss:  0.01420  Accuracy:  0.82764  Smallest:  0.00035  Largest:  1.00000  Average:  0.70531\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 12940)  (0.5, 5171, 2025)  (1.0, 35539, 29765) \n",
      "Test:\n",
      " Average loss:  0.05542  Accuracy:  0.79056  Smallest:  0.00034  Largest:  1.00000  Average:  0.67040\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2932)  (0.5, 1278, 347)  (1.0, 8934, 7403)\n",
      "Epoch:   27 \n",
      "Train:\n",
      " Average loss:  0.01283  Accuracy:  0.82676  Smallest:  0.00021  Largest:  1.00000  Average:  0.70773\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 12989)  (0.5, 5171, 2168)  (1.0, 35539, 29525) \n",
      "Test:\n",
      " Average loss:  0.04961  Accuracy:  0.69953  Smallest:  0.00016  Largest:  1.00000  Average:  0.70991\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2844)  (0.5, 1278, 283)  (1.0, 8934, 6325)\n",
      "Epoch:   28 \n",
      "Train:\n",
      " Average loss:  0.01144  Accuracy:  0.81671  Smallest:  0.00012  Largest:  1.00000  Average:  0.70664\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13076)  (0.5, 5171, 2279)  (1.0, 35539, 28784) \n",
      "Test:\n",
      " Average loss:  0.05643  Accuracy:  0.74763  Smallest:  0.00012  Largest:  1.00000  Average:  0.67601\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2933)  (0.5, 1278, 309)  (1.0, 8934, 6860)\n",
      "Epoch:   29 \n",
      "Train:\n",
      " Average loss:  0.01065  Accuracy:  0.81447  Smallest:  0.00010  Largest:  1.00000  Average:  0.70766\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13084)  (0.5, 5171, 2411)  (1.0, 35539, 28523) \n",
      "Test:\n",
      " Average loss:  0.04937  Accuracy:  0.70708  Smallest:  0.00011  Largest:  1.00000  Average:  0.71340\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2792)  (0.5, 1278, 336)  (1.0, 8934, 6426)\n",
      "Epoch:   30 \n",
      "Train:\n",
      " Average loss:  0.01051  Accuracy:  0.83232  Smallest:  0.00010  Largest:  1.00000  Average:  0.70556\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13120)  (0.5, 5171, 2362)  (1.0, 35539, 29501) \n",
      "Test:\n",
      " Average loss:  0.04850  Accuracy:  0.73409  Smallest:  0.00015  Largest:  1.00000  Average:  0.70962\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2815)  (0.5, 1278, 320)  (1.0, 8934, 6784)\n",
      "Epoch:   31 \n",
      "Train:\n",
      " Average loss:  0.00857  Accuracy:  0.82818  Smallest:  0.00007  Largest:  1.00000  Average:  0.70652\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13195)  (0.5, 5171, 2805)  (1.0, 35539, 28759) \n",
      "Test:\n",
      " Average loss:  0.05181  Accuracy:  0.73327  Smallest:  0.00004  Largest:  1.00000  Average:  0.69129\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2882)  (0.5, 1278, 335)  (1.0, 8934, 6691)\n",
      "Epoch:   32 \n",
      "Train:\n",
      " Average loss:  0.00876  Accuracy:  0.82859  Smallest:  0.00003  Largest:  1.00000  Average:  0.70685\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13158)  (0.5, 5171, 2759)  (1.0, 35539, 28864) \n",
      "Test:\n",
      " Average loss:  0.05513  Accuracy:  0.74415  Smallest:  0.00007  Largest:  1.00000  Average:  0.67729\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2926)  (0.5, 1278, 328)  (1.0, 8934, 6801)\n",
      "Epoch:   33 \n",
      "Train:\n",
      " Average loss:  0.01037  Accuracy:  0.81769  Smallest:  0.00005  Largest:  1.00000  Average:  0.70797\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13038)  (0.5, 5171, 2559)  (1.0, 35539, 28595) \n",
      "Test:\n",
      " Average loss:  0.05432  Accuracy:  0.69420  Smallest:  0.00008  Largest:  1.00000  Average:  0.74514\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2538)  (0.5, 1278, 312)  (1.0, 8934, 6530)\n",
      "Epoch:   34 \n",
      "Train:\n",
      " Average loss:  0.00877  Accuracy:  0.82454  Smallest:  0.00004  Largest:  1.00000  Average:  0.70549\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13152)  (0.5, 5171, 2766)  (1.0, 35539, 28644) \n",
      "Test:\n",
      " Average loss:  0.04969  Accuracy:  0.74445  Smallest:  0.00008  Largest:  1.00000  Average:  0.71316\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2738)  (0.5, 1278, 381)  (1.0, 8934, 6940)\n",
      "Epoch:   35 \n",
      "Train:\n",
      " Average loss:  0.00834  Accuracy:  0.82274  Smallest:  0.00004  Largest:  1.00000  Average:  0.70666\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13148)  (0.5, 5171, 2973)  (1.0, 35539, 28344) \n",
      "Test:\n",
      " Average loss:  0.05931  Accuracy:  0.62626  Smallest:  0.00004  Largest:  1.00000  Average:  0.77056\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2348)  (0.5, 1278, 270)  (1.0, 8934, 5844)\n",
      "Epoch:   36 \n",
      "Train:\n",
      " Average loss:  0.00832  Accuracy:  0.81691  Smallest:  0.00003  Largest:  1.00000  Average:  0.70482\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13179)  (0.5, 5171, 2877)  (1.0, 35539, 28094) \n",
      "Test:\n",
      " Average loss:  0.05058  Accuracy:  0.69753  Smallest:  0.00005  Largest:  1.00000  Average:  0.73823\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2588)  (0.5, 1278, 347)  (1.0, 8934, 6490)\n",
      "Epoch:   37 \n",
      "Train:\n",
      " Average loss:  0.00702  Accuracy:  0.81319  Smallest:  0.00003  Largest:  1.00000  Average:  0.70516\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13210)  (0.5, 5171, 3216)  (1.0, 35539, 27523) \n",
      "Test:\n",
      " Average loss:  0.05009  Accuracy:  0.69472  Smallest:  0.00003  Largest:  1.00000  Average:  0.70081\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2842)  (0.5, 1278, 362)  (1.0, 8934, 6183)\n",
      "Epoch:   38 \n",
      "Train:\n",
      " Average loss:  0.00741  Accuracy:  0.81417  Smallest:  0.00002  Largest:  1.00000  Average:  0.70582\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13177)  (0.5, 5171, 3149)  (1.0, 35539, 27676) \n",
      "Test:\n",
      " Average loss:  0.05118  Accuracy:  0.68643  Smallest:  0.00002  Largest:  1.00000  Average:  0.73122\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2626)  (0.5, 1278, 344)  (1.0, 8934, 6305)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   39 \n",
      "Train:\n",
      " Average loss:  0.00829  Accuracy:  0.80709  Smallest:  0.00001  Largest:  1.00000  Average:  0.70585\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13133)  (0.5, 5171, 3033)  (1.0, 35539, 27453) \n",
      "Test:\n",
      " Average loss:  0.05526  Accuracy:  0.59384  Smallest:  0.00001  Largest:  1.00000  Average:  0.74754\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2563)  (0.5, 1278, 268)  (1.0, 8934, 5193)\n",
      "Epoch:   40 \n",
      "Train:\n",
      " Average loss:  0.00819  Accuracy:  0.78177  Smallest:  0.00001  Largest:  1.00000  Average:  0.70473\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13156)  (0.5, 5171, 3089)  (1.0, 35539, 26006) \n",
      "Test:\n",
      " Average loss:  0.05253  Accuracy:  0.67192  Smallest:  0.00002  Largest:  1.00000  Average:  0.70455\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2785)  (0.5, 1278, 353)  (1.0, 8934, 5941)\n",
      "Epoch:   41 \n",
      "Train:\n",
      " Average loss:  0.00861  Accuracy:  0.77874  Smallest:  0.00002  Largest:  1.00000  Average:  0.70610\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13093)  (0.5, 5171, 3053)  (1.0, 35539, 25941) \n",
      "Test:\n",
      " Average loss:  0.05150  Accuracy:  0.68761  Smallest:  0.00002  Largest:  1.00000  Average:  0.69056\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2850)  (0.5, 1278, 392)  (1.0, 8934, 6049)\n",
      "Epoch:   42 \n",
      "Train:\n",
      " Average loss:  0.00851  Accuracy:  0.77147  Smallest:  0.00002  Largest:  1.00000  Average:  0.70616\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13062)  (0.5, 5171, 3140)  (1.0, 35539, 25492) \n",
      "Test:\n",
      " Average loss:  0.04981  Accuracy:  0.63196  Smallest:  0.00002  Largest:  1.00000  Average:  0.71783\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2716)  (0.5, 1278, 398)  (1.0, 8934, 5425)\n",
      "Epoch:   43 \n",
      "Train:\n",
      " Average loss:  0.00818  Accuracy:  0.77228  Smallest:  0.00001  Largest:  1.00000  Average:  0.70536\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13101)  (0.5, 5171, 3162)  (1.0, 35539, 25475) \n",
      "Test:\n",
      " Average loss:  0.07801  Accuracy:  0.72010  Smallest:  0.00002  Largest:  1.00000  Average:  0.61201\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 3085)  (0.5, 1278, 378)  (1.0, 8934, 6267)\n",
      "Epoch:   44 \n",
      "Train:\n",
      " Average loss:  0.00846  Accuracy:  0.76843  Smallest:  0.00000  Largest:  1.00000  Average:  0.70587\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13056)  (0.5, 5171, 3222)  (1.0, 35539, 25252) \n",
      "Test:\n",
      " Average loss:  0.05304  Accuracy:  0.65956  Smallest:  0.00001  Largest:  1.00000  Average:  0.69390\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2829)  (0.5, 1278, 391)  (1.0, 8934, 5692)\n",
      "Epoch:   45 \n",
      "Train:\n",
      " Average loss:  0.00796  Accuracy:  0.76903  Smallest:  0.00000  Largest:  1.00000  Average:  0.70535\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13108)  (0.5, 5171, 3274)  (1.0, 35539, 25180) \n",
      "Test:\n",
      " Average loss:  0.05403  Accuracy:  0.59925  Smallest:  0.00001  Largest:  1.00000  Average:  0.72542\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2628)  (0.5, 1278, 381)  (1.0, 8934, 5088)\n",
      "Epoch:   46 \n",
      "Train:\n",
      " Average loss:  0.00780  Accuracy:  0.74588  Smallest:  0.00000  Largest:  1.00000  Average:  0.70725\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13084)  (0.5, 5171, 3263)  (1.0, 35539, 23964) \n",
      "Test:\n",
      " Average loss:  0.05339  Accuracy:  0.62019  Smallest:  0.00000  Largest:  1.00000  Average:  0.69450\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2830)  (0.5, 1278, 386)  (1.0, 8934, 5164)\n",
      "Epoch:   47 \n",
      "Train:\n",
      " Average loss:  0.00777  Accuracy:  0.74501  Smallest:  0.00000  Largest:  1.00000  Average:  0.70597\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13096)  (0.5, 5171, 3314)  (1.0, 35539, 23854) \n",
      "Test:\n",
      " Average loss:  0.05451  Accuracy:  0.54411  Smallest:  0.00000  Largest:  1.00000  Average:  0.75038\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2502)  (0.5, 1278, 335)  (1.0, 8934, 4515)\n",
      "Epoch:   48 \n",
      "Train:\n",
      " Average loss:  0.00746  Accuracy:  0.74225  Smallest:  0.00000  Largest:  1.00000  Average:  0.70608\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13090)  (0.5, 5171, 3383)  (1.0, 35539, 23642) \n",
      "Test:\n",
      " Average loss:  0.05695  Accuracy:  0.65068  Smallest:  0.00001  Largest:  1.00000  Average:  0.67342\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2874)  (0.5, 1278, 406)  (1.0, 8934, 5512)\n",
      "Epoch:   49 \n",
      "Train:\n",
      " Average loss:  0.00696  Accuracy:  0.72908  Smallest:  0.00000  Largest:  1.00000  Average:  0.70479\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13146)  (0.5, 5171, 3535)  (1.0, 35539, 22722) \n",
      "Test:\n",
      " Average loss:  0.05320  Accuracy:  0.61308  Smallest:  0.00001  Largest:  1.00000  Average:  0.71275\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2695)  (0.5, 1278, 418)  (1.0, 8934, 5171)\n",
      "Epoch:   50 \n",
      "Train:\n",
      " Average loss:  0.00820  Accuracy:  0.72860  Smallest:  0.00000  Largest:  1.00000  Average:  0.70676\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13025)  (0.5, 5171, 3421)  (1.0, 35539, 22931) \n",
      "Test:\n",
      " Average loss:  0.07325  Accuracy:  0.65305  Smallest:  0.00000  Largest:  1.00000  Average:  0.62572\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 3091)  (0.5, 1278, 393)  (1.0, 8934, 5340)\n",
      "Epoch:   51 \n",
      "Train:\n",
      " Average loss:  0.00774  Accuracy:  0.72673  Smallest:  0.00000  Largest:  1.00000  Average:  0.70520\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13101)  (0.5, 5171, 3483)  (1.0, 35539, 22692) \n",
      "Test:\n",
      " Average loss:  0.05169  Accuracy:  0.62130  Smallest:  0.00001  Largest:  1.00000  Average:  0.69363\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2797)  (0.5, 1278, 466)  (1.0, 8934, 5132)\n",
      "Epoch:   52 \n",
      "Train:\n",
      " Average loss:  0.00776  Accuracy:  0.70974  Smallest:  0.00000  Largest:  1.00000  Average:  0.70824\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13037)  (0.5, 5171, 3471)  (1.0, 35539, 21850) \n",
      "Test:\n",
      " Average loss:  0.05088  Accuracy:  0.58119  Smallest:  0.00000  Largest:  1.00000  Average:  0.72786\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2594)  (0.5, 1278, 431)  (1.0, 8934, 4828)\n",
      "Epoch:   53 \n",
      "Train:\n",
      " Average loss:  0.00736  Accuracy:  0.71703  Smallest:  0.00000  Largest:  1.00000  Average:  0.70745\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13085)  (0.5, 5171, 3517)  (1.0, 35539, 22150) \n",
      "Test:\n",
      " Average loss:  0.05320  Accuracy:  0.59858  Smallest:  0.00000  Largest:  1.00000  Average:  0.70593\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2728)  (0.5, 1278, 445)  (1.0, 8934, 4915)\n",
      "Epoch:   54 \n",
      "Train:\n",
      " Average loss:  0.00662  Accuracy:  0.71848  Smallest:  0.00000  Largest:  1.00000  Average:  0.70711\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13132)  (0.5, 5171, 3690)  (1.0, 35539, 22008) \n",
      "Test:\n",
      " Average loss:  0.07216  Accuracy:  0.43051  Smallest:  0.00000  Largest:  1.00000  Average:  0.79796\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2070)  (0.5, 1278, 277)  (1.0, 8934, 3470)\n",
      "Epoch:   55 \n",
      "Train:\n",
      " Average loss:  0.00654  Accuracy:  0.69327  Smallest:  0.00000  Largest:  1.00000  Average:  0.70737\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13131)  (0.5, 5171, 3651)  (1.0, 35539, 20686) \n",
      "Test:\n",
      " Average loss:  0.05452  Accuracy:  0.52457  Smallest:  0.00000  Largest:  1.00000  Average:  0.74395\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2488)  (0.5, 1278, 389)  (1.0, 8934, 4211)\n",
      "Epoch:   56 \n",
      "Train:\n",
      " Average loss:  0.00909  Accuracy:  0.69129  Smallest:  0.00000  Largest:  1.00000  Average:  0.70445\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 12994)  (0.5, 5171, 3329)  (1.0, 35539, 21038) \n",
      "Test:\n",
      " Average loss:  0.05831  Accuracy:  0.62655  Smallest:  0.00000  Largest:  1.00000  Average:  0.66565\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2907)  (0.5, 1278, 437)  (1.0, 8934, 5122)\n",
      "Epoch:   57 \n",
      "Train:\n",
      " Average loss:  0.00712  Accuracy:  0.72007  Smallest:  0.00000  Largest:  1.00000  Average:  0.70680\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13104)  (0.5, 5171, 3521)  (1.0, 35539, 22291) \n",
      "Test:\n",
      " Average loss:  0.05290  Accuracy:  0.55750  Smallest:  0.00000  Largest:  1.00000  Average:  0.74116\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2511)  (0.5, 1278, 428)  (1.0, 8934, 4594)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   58 \n",
      "Train:\n",
      " Average loss:  0.00552  Accuracy:  0.72268  Smallest:  0.00000  Largest:  1.00000  Average:  0.70570\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13192)  (0.5, 5171, 3871)  (1.0, 35539, 21994) \n",
      "Test:\n",
      " Average loss:  0.05040  Accuracy:  0.57083  Smallest:  0.00000  Largest:  1.00000  Average:  0.72029\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2640)  (0.5, 1278, 479)  (1.0, 8934, 4594)\n",
      "Epoch:   59 \n",
      "Train:\n",
      " Average loss:  0.00450  Accuracy:  0.69709  Smallest:  0.00000  Largest:  1.00000  Average:  0.70652\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13216)  (0.5, 5171, 4130)  (1.0, 35539, 20328) \n",
      "Test:\n",
      " Average loss:  0.05217  Accuracy:  0.55351  Smallest:  0.00000  Largest:  1.00000  Average:  0.69402\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2812)  (0.5, 1278, 456)  (1.0, 8934, 4211)\n",
      "Epoch:   60 \n",
      "Train:\n",
      " Average loss:  0.00443  Accuracy:  0.67771  Smallest:  0.00000  Largest:  1.00000  Average:  0.70567\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13240)  (0.5, 5171, 4139)  (1.0, 35539, 19248) \n",
      "Test:\n",
      " Average loss:  0.06757  Accuracy:  0.42074  Smallest:  0.00000  Largest:  1.00000  Average:  0.79124\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2071)  (0.5, 1278, 339)  (1.0, 8934, 3275)\n",
      "Epoch:   61 \n",
      "Train:\n",
      " Average loss:  0.00606  Accuracy:  0.64705  Smallest:  0.00000  Largest:  1.00000  Average:  0.70857\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13094)  (0.5, 5171, 3878)  (1.0, 35539, 17998) \n",
      "Test:\n",
      " Average loss:  0.07210  Accuracy:  0.60176  Smallest:  0.00000  Largest:  1.00000  Average:  0.62411\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 3067)  (0.5, 1278, 438)  (1.0, 8934, 4626)\n",
      "Epoch:   62 \n",
      "Train:\n",
      " Average loss:  0.00623  Accuracy:  0.67287  Smallest:  0.00000  Largest:  1.00000  Average:  0.70516\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13136)  (0.5, 5171, 3869)  (1.0, 35539, 19360) \n",
      "Test:\n",
      " Average loss:  0.05205  Accuracy:  0.55351  Smallest:  0.00000  Largest:  1.00000  Average:  0.70610\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2700)  (0.5, 1278, 477)  (1.0, 8934, 4302)\n",
      "Epoch:   63 \n",
      "Train:\n",
      " Average loss:  0.00570  Accuracy:  0.67076  Smallest:  0.00000  Largest:  1.00000  Average:  0.70600\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13153)  (0.5, 5171, 3964)  (1.0, 35539, 19134) \n",
      "Test:\n",
      " Average loss:  0.05232  Accuracy:  0.53538  Smallest:  0.00000  Largest:  1.00000  Average:  0.70524\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2716)  (0.5, 1278, 467)  (1.0, 8934, 4051)\n",
      "Epoch:   64 \n",
      "Train:\n",
      " Average loss:  0.00558  Accuracy:  0.66578  Smallest:  0.00000  Largest:  1.00000  Average:  0.70631\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13160)  (0.5, 5171, 3980)  (1.0, 35539, 18842) \n",
      "Test:\n",
      " Average loss:  0.05204  Accuracy:  0.54552  Smallest:  0.00000  Largest:  1.00000  Average:  0.68825\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2834)  (0.5, 1278, 475)  (1.0, 8934, 4062)\n",
      "Epoch:   65 \n",
      "Train:\n",
      " Average loss:  0.00534  Accuracy:  0.64833  Smallest:  0.00000  Largest:  1.00000  Average:  0.70671\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13169)  (0.5, 5171, 4046)  (1.0, 35539, 17824) \n",
      "Test:\n",
      " Average loss:  0.05906  Accuracy:  0.42666  Smallest:  0.00000  Largest:  1.00000  Average:  0.76886\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2260)  (0.5, 1278, 393)  (1.0, 8934, 3112)\n",
      "Epoch:   66 \n",
      "Train:\n",
      " Average loss:  0.00518  Accuracy:  0.64833  Smallest:  0.00000  Largest:  1.00000  Average:  0.70672\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13163)  (0.5, 5171, 4093)  (1.0, 35539, 17783) \n",
      "Test:\n",
      " Average loss:  0.05239  Accuracy:  0.49349  Smallest:  0.00000  Largest:  1.00000  Average:  0.71128\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2705)  (0.5, 1278, 431)  (1.0, 8934, 3532)\n",
      "Epoch:   67 \n",
      "Train:\n",
      " Average loss:  0.00635  Accuracy:  0.64082  Smallest:  0.00000  Largest:  1.00000  Average:  0.70577\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13111)  (0.5, 5171, 3883)  (1.0, 35539, 17639) \n",
      "Test:\n",
      " Average loss:  0.05186  Accuracy:  0.50318  Smallest:  0.00000  Largest:  1.00000  Average:  0.71616\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2667)  (0.5, 1278, 459)  (1.0, 8934, 3673)\n",
      "Epoch:   68 \n",
      "Train:\n",
      " Average loss:  0.00580  Accuracy:  0.64988  Smallest:  0.00000  Largest:  1.00000  Average:  0.70742\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13095)  (0.5, 5171, 3998)  (1.0, 35539, 18030) \n",
      "Test:\n",
      " Average loss:  0.05196  Accuracy:  0.49852  Smallest:  0.00000  Largest:  1.00000  Average:  0.73257\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2555)  (0.5, 1278, 428)  (1.0, 8934, 3753)\n",
      "Epoch:   69 \n",
      "Train:\n",
      " Average loss:  0.00554  Accuracy:  0.65240  Smallest:  0.00000  Largest:  1.00000  Average:  0.70494\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13152)  (0.5, 5171, 4022)  (1.0, 35539, 18085) \n",
      "Test:\n",
      " Average loss:  0.05112  Accuracy:  0.51273  Smallest:  0.00000  Largest:  1.00000  Average:  0.71650\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2627)  (0.5, 1278, 471)  (1.0, 8934, 3830)\n",
      "Epoch:   70 \n",
      "Train:\n",
      " Average loss:  0.00496  Accuracy:  0.65099  Smallest:  0.00000  Largest:  1.00000  Average:  0.70702\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13170)  (0.5, 5171, 4140)  (1.0, 35539, 17873) \n",
      "Test:\n",
      " Average loss:  0.05315  Accuracy:  0.54433  Smallest:  0.00000  Largest:  1.00000  Average:  0.69105\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2761)  (0.5, 1278, 508)  (1.0, 8934, 4086)\n",
      "Epoch:   71 \n",
      "Train:\n",
      " Average loss:  0.00495  Accuracy:  0.63989  Smallest:  0.00000  Largest:  1.00000  Average:  0.70653\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13199)  (0.5, 5171, 4126)  (1.0, 35539, 17258) \n",
      "Test:\n",
      " Average loss:  0.05073  Accuracy:  0.53567  Smallest:  0.00000  Largest:  1.00000  Average:  0.70291\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2705)  (0.5, 1278, 549)  (1.0, 8934, 3984)\n",
      "Epoch:   72 \n",
      "Train:\n",
      " Average loss:  0.00459  Accuracy:  0.65181  Smallest:  0.00000  Largest:  1.00000  Average:  0.70623\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13201)  (0.5, 5171, 4214)  (1.0, 35539, 17812) \n",
      "Test:\n",
      " Average loss:  0.05230  Accuracy:  0.49697  Smallest:  0.00000  Largest:  1.00000  Average:  0.70359\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2741)  (0.5, 1278, 509)  (1.0, 8934, 3465)\n",
      "Epoch:   73 \n",
      "Train:\n",
      " Average loss:  0.00500  Accuracy:  0.62028  Smallest:  0.00000  Largest:  1.00000  Average:  0.70697\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13172)  (0.5, 5171, 4162)  (1.0, 35539, 16189) \n",
      "Test:\n",
      " Average loss:  0.05975  Accuracy:  0.39742  Smallest:  0.00000  Largest:  1.00000  Average:  0.77434\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2218)  (0.5, 1278, 395)  (1.0, 8934, 2757)\n",
      "Epoch:   74 \n",
      "Train:\n",
      " Average loss:  0.00613  Accuracy:  0.60564  Smallest:  0.00000  Largest:  1.00000  Average:  0.70849\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13053)  (0.5, 5171, 4009)  (1.0, 35539, 15670) \n",
      "Test:\n",
      " Average loss:  0.05442  Accuracy:  0.50326  Smallest:  0.00000  Largest:  1.00000  Average:  0.68218\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2839)  (0.5, 1278, 516)  (1.0, 8934, 3445)\n",
      "Epoch:   75 \n",
      "Train:\n",
      " Average loss:  0.00547  Accuracy:  0.62256  Smallest:  0.00000  Largest:  1.00000  Average:  0.70628\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13139)  (0.5, 5171, 4082)  (1.0, 35539, 16425) \n",
      "Test:\n",
      " Average loss:  0.05920  Accuracy:  0.55380  Smallest:  0.00000  Largest:  1.00000  Average:  0.66673\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2877)  (0.5, 1278, 493)  (1.0, 8934, 4113)\n",
      "Epoch:   76 \n",
      "Train:\n",
      " Average loss:  0.00473  Accuracy:  0.64696  Smallest:  0.00000  Largest:  1.00000  Average:  0.70619\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13174)  (0.5, 5171, 4234)  (1.0, 35539, 17557) \n",
      "Test:\n",
      " Average loss:  0.05181  Accuracy:  0.52731  Smallest:  0.00000  Largest:  1.00000  Average:  0.70031\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2746)  (0.5, 1278, 537)  (1.0, 8934, 3842)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   77 \n",
      "Train:\n",
      " Average loss:  0.00433  Accuracy:  0.64089  Smallest:  0.00000  Largest:  1.00000  Average:  0.70643\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13188)  (0.5, 5171, 4294)  (1.0, 35539, 17155) \n",
      "Test:\n",
      " Average loss:  0.05518  Accuracy:  0.43643  Smallest:  0.00000  Largest:  1.00000  Average:  0.75326\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2368)  (0.5, 1278, 450)  (1.0, 8934, 3079)\n",
      "Epoch:   78 \n",
      "Train:\n",
      " Average loss:  0.00428  Accuracy:  0.62137  Smallest:  0.00000  Largest:  1.00000  Average:  0.70732\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13198)  (0.5, 5171, 4252)  (1.0, 35539, 16132) \n",
      "Test:\n",
      " Average loss:  0.05342  Accuracy:  0.52738  Smallest:  0.00000  Largest:  1.00000  Average:  0.68139\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2812)  (0.5, 1278, 567)  (1.0, 8934, 3747)\n",
      "Epoch:   79 \n",
      "Train:\n",
      " Average loss:  0.00512  Accuracy:  0.61676  Smallest:  0.00000  Largest:  1.00000  Average:  0.70599\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13140)  (0.5, 5171, 4194)  (1.0, 35539, 15999) \n",
      "Test:\n",
      " Average loss:  0.05295  Accuracy:  0.43909  Smallest:  0.00000  Largest:  1.00000  Average:  0.72755\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2540)  (0.5, 1278, 481)  (1.0, 8934, 2912)\n",
      "Epoch:   80 \n",
      "Train:\n",
      " Average loss:  0.00588  Accuracy:  0.59347  Smallest:  0.00000  Largest:  1.00000  Average:  0.70757\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13108)  (0.5, 5171, 4003)  (1.0, 35539, 14963) \n",
      "Test:\n",
      " Average loss:  0.05332  Accuracy:  0.46559  Smallest:  0.00000  Largest:  1.00000  Average:  0.70774\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2691)  (0.5, 1278, 479)  (1.0, 8934, 3121)\n",
      "Epoch:   81 \n",
      "Train:\n",
      " Average loss:  0.00614  Accuracy:  0.61016  Smallest:  0.00000  Largest:  1.00000  Average:  0.70656\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13105)  (0.5, 5171, 3978)  (1.0, 35539, 15893) \n",
      "Test:\n",
      " Average loss:  0.05547  Accuracy:  0.46218  Smallest:  0.00000  Largest:  1.00000  Average:  0.76117\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2267)  (0.5, 1278, 463)  (1.0, 8934, 3515)\n",
      "Epoch:   82 \n",
      "Train:\n",
      " Average loss:  0.00524  Accuracy:  0.63862  Smallest:  0.00000  Largest:  1.00000  Average:  0.70774\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13115)  (0.5, 5171, 4145)  (1.0, 35539, 17254) \n",
      "Test:\n",
      " Average loss:  0.05875  Accuracy:  0.54944  Smallest:  0.00000  Largest:  1.00000  Average:  0.65935\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2936)  (0.5, 1278, 504)  (1.0, 8934, 3984)\n",
      "Epoch:   83 \n",
      "Train:\n",
      " Average loss:  0.00466  Accuracy:  0.62727  Smallest:  0.00000  Largest:  1.00000  Average:  0.70587\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13190)  (0.5, 5171, 4229)  (1.0, 35539, 16482) \n",
      "Test:\n",
      " Average loss:  0.05104  Accuracy:  0.53323  Smallest:  0.00000  Largest:  1.00000  Average:  0.69301\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2766)  (0.5, 1278, 523)  (1.0, 8934, 3916)\n",
      "Epoch:   84 \n",
      "Train:\n",
      " Average loss:  0.00436  Accuracy:  0.64515  Smallest:  0.00000  Largest:  1.00000  Average:  0.70628\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13193)  (0.5, 5171, 4302)  (1.0, 35539, 17372) \n",
      "Test:\n",
      " Average loss:  0.05394  Accuracy:  0.44168  Smallest:  0.00000  Largest:  1.00000  Average:  0.74029\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2518)  (0.5, 1278, 437)  (1.0, 8934, 3013)\n",
      "Epoch:   85 \n",
      "Train:\n",
      " Average loss:  0.00372  Accuracy:  0.62796  Smallest:  0.00000  Largest:  1.00000  Average:  0.70594\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13227)  (0.5, 5171, 4366)  (1.0, 35539, 16345) \n",
      "Test:\n",
      " Average loss:  0.05499  Accuracy:  0.42163  Smallest:  0.00000  Largest:  1.00000  Average:  0.75550\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2372)  (0.5, 1278, 483)  (1.0, 8934, 2842)\n",
      "Epoch:   86 \n",
      "Train:\n",
      " Average loss:  0.00374  Accuracy:  0.61728  Smallest:  0.00000  Largest:  1.00000  Average:  0.70719\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13219)  (0.5, 5171, 4386)  (1.0, 35539, 15756) \n",
      "Test:\n",
      " Average loss:  0.05051  Accuracy:  0.48942  Smallest:  0.00000  Largest:  1.00000  Average:  0.71558\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2640)  (0.5, 1278, 530)  (1.0, 8934, 3443)\n",
      "Epoch:   87 \n",
      "Train:\n",
      " Average loss:  0.00371  Accuracy:  0.63340  Smallest:  0.00000  Largest:  1.00000  Average:  0.70632\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13214)  (0.5, 5171, 4451)  (1.0, 35539, 16567) \n",
      "Test:\n",
      " Average loss:  0.06058  Accuracy:  0.55595  Smallest:  0.00000  Largest:  1.00000  Average:  0.65410\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2893)  (0.5, 1278, 580)  (1.0, 8934, 4039)\n",
      "Epoch:   88 \n",
      "Train:\n",
      " Average loss:  0.00375  Accuracy:  0.61837  Smallest:  0.00000  Largest:  1.00000  Average:  0.70633\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13212)  (0.5, 5171, 4436)  (1.0, 35539, 15772) \n",
      "Test:\n",
      " Average loss:  0.05261  Accuracy:  0.45730  Smallest:  0.00000  Largest:  1.00000  Average:  0.71141\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2667)  (0.5, 1278, 505)  (1.0, 8934, 3007)\n",
      "Epoch:   89 \n",
      "Train:\n",
      " Average loss:  0.00468  Accuracy:  0.59434  Smallest:  0.00000  Largest:  1.00000  Average:  0.70571\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13170)  (0.5, 5171, 4266)  (1.0, 35539, 14685) \n",
      "Test:\n",
      " Average loss:  0.06009  Accuracy:  0.51184  Smallest:  0.00000  Largest:  1.00000  Average:  0.65558\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2928)  (0.5, 1278, 556)  (1.0, 8934, 3432)\n",
      "Epoch:   90 \n",
      "Train:\n",
      " Average loss:  0.00445  Accuracy:  0.59304  Smallest:  0.00000  Largest:  1.00000  Average:  0.70675\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13189)  (0.5, 5171, 4317)  (1.0, 35539, 14545) \n",
      "Test:\n",
      " Average loss:  0.05085  Accuracy:  0.43806  Smallest:  0.00000  Largest:  1.00000  Average:  0.73782\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2492)  (0.5, 1278, 516)  (1.0, 8934, 2911)\n",
      "Epoch:   91 \n",
      "Train:\n",
      " Average loss:  0.00404  Accuracy:  0.59948  Smallest:  0.00000  Largest:  1.00000  Average:  0.70667\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13190)  (0.5, 5171, 4401)  (1.0, 35539, 14808) \n",
      "Test:\n",
      " Average loss:  0.05195  Accuracy:  0.41459  Smallest:  0.00000  Largest:  1.00000  Average:  0.74445\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2456)  (0.5, 1278, 493)  (1.0, 8934, 2653)\n",
      "Epoch:   92 \n",
      "Train:\n",
      " Average loss:  0.00443  Accuracy:  0.58808  Smallest:  0.00000  Largest:  1.00000  Average:  0.70733\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13157)  (0.5, 5171, 4317)  (1.0, 35539, 14309) \n",
      "Test:\n",
      " Average loss:  0.05201  Accuracy:  0.44213  Smallest:  0.00000  Largest:  1.00000  Average:  0.70998\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2661)  (0.5, 1278, 516)  (1.0, 8934, 2797)\n",
      "Epoch:   93 \n",
      "Train:\n",
      " Average loss:  0.00482  Accuracy:  0.57028  Smallest:  0.00000  Largest:  1.00000  Average:  0.70748\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13145)  (0.5, 5171, 4217)  (1.0, 35539, 13459) \n",
      "Test:\n",
      " Average loss:  0.05840  Accuracy:  0.52487  Smallest:  0.00000  Largest:  1.00000  Average:  0.66035\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2912)  (0.5, 1278, 564)  (1.0, 8934, 3616)\n",
      "Epoch:   94 \n",
      "Train:\n",
      " Average loss:  0.00533  Accuracy:  0.58982  Smallest:  0.00000  Largest:  1.00000  Average:  0.70492\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13140)  (0.5, 5171, 4167)  (1.0, 35539, 14570) \n",
      "Test:\n",
      " Average loss:  0.05215  Accuracy:  0.44782  Smallest:  0.00000  Largest:  1.00000  Average:  0.72318\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2591)  (0.5, 1278, 500)  (1.0, 8934, 2960)\n",
      "Epoch:   95 \n",
      "Train:\n",
      " Average loss:  0.00626  Accuracy:  0.58720  Smallest:  0.00000  Largest:  1.00000  Average:  0.70756\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13059)  (0.5, 5171, 3919)  (1.0, 35539, 14757) \n",
      "Test:\n",
      " Average loss:  0.05060  Accuracy:  0.50710  Smallest:  0.00000  Largest:  1.00000  Average:  0.71732\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2598)  (0.5, 1278, 538)  (1.0, 8934, 3716)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   96 \n",
      "Train:\n",
      " Average loss:  0.00476  Accuracy:  0.63286  Smallest:  0.00000  Largest:  1.00000  Average:  0.70641\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13153)  (0.5, 5171, 4209)  (1.0, 35539, 16841) \n",
      "Test:\n",
      " Average loss:  0.04970  Accuracy:  0.48949  Smallest:  0.00000  Largest:  1.00000  Average:  0.71238\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2676)  (0.5, 1278, 520)  (1.0, 8934, 3418)\n",
      "Epoch:   97 \n",
      "Train:\n",
      " Average loss:  0.00360  Accuracy:  0.62796  Smallest:  0.00000  Largest:  1.00000  Average:  0.70644\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13233)  (0.5, 5171, 4395)  (1.0, 35539, 16310) \n",
      "Test:\n",
      " Average loss:  0.04946  Accuracy:  0.48912  Smallest:  0.00000  Largest:  1.00000  Average:  0.72327\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2576)  (0.5, 1278, 551)  (1.0, 8934, 3482)\n",
      "Epoch:   98 \n",
      "Train:\n",
      " Average loss:  0.00338  Accuracy:  0.62485  Smallest:  0.00000  Largest:  1.00000  Average:  0.70726\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13221)  (0.5, 5171, 4490)  (1.0, 35539, 16059) \n",
      "Test:\n",
      " Average loss:  0.05548  Accuracy:  0.42977  Smallest:  0.00000  Largest:  1.00000  Average:  0.75955\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2269)  (0.5, 1278, 492)  (1.0, 8934, 3046)\n",
      "Epoch:   99 \n",
      "Train:\n",
      " Average loss:  0.00318  Accuracy:  0.62285  Smallest:  0.00000  Largest:  1.00000  Average:  0.70655\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13221)  (0.5, 5171, 4543)  (1.0, 35539, 15898) \n",
      "Test:\n",
      " Average loss:  0.05083  Accuracy:  0.50207  Smallest:  0.00000  Largest:  1.00000  Average:  0.69136\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2779)  (0.5, 1278, 593)  (1.0, 8934, 3412)\n",
      "Epoch:   100 \n",
      "Train:\n",
      " Average loss:  0.00336  Accuracy:  0.60733  Smallest:  0.00000  Largest:  1.00000  Average:  0.70645\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13229)  (0.5, 5171, 4516)  (1.0, 35539, 15078) \n",
      "Test:\n",
      " Average loss:  0.05942  Accuracy:  0.52109  Smallest:  0.00000  Largest:  1.00000  Average:  0.65299\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2943)  (0.5, 1278, 551)  (1.0, 8934, 3547)\n",
      "Epoch:   101 \n",
      "Train:\n",
      " Average loss:  0.00331  Accuracy:  0.60131  Smallest:  0.00000  Largest:  1.00000  Average:  0.70629\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13231)  (0.5, 5171, 4521)  (1.0, 35539, 14746) \n",
      "Test:\n",
      " Average loss:  0.04997  Accuracy:  0.45870  Smallest:  0.00000  Largest:  1.00000  Average:  0.72172\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2544)  (0.5, 1278, 581)  (1.0, 8934, 3073)\n",
      "Epoch:   102 \n",
      "Train:\n",
      " Average loss:  0.00371  Accuracy:  0.58361  Smallest:  0.00000  Largest:  1.00000  Average:  0.70666\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13194)  (0.5, 5171, 4464)  (1.0, 35539, 13883) \n",
      "Test:\n",
      " Average loss:  0.05852  Accuracy:  0.35494  Smallest:  0.00000  Largest:  1.00000  Average:  0.76346\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2315)  (0.5, 1278, 438)  (1.0, 8934, 2043)\n",
      "Epoch:   103 \n",
      "Train:\n",
      " Average loss:  0.00401  Accuracy:  0.58605  Smallest:  0.00000  Largest:  1.00000  Average:  0.70686\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13184)  (0.5, 5171, 4405)  (1.0, 35539, 14084) \n",
      "Test:\n",
      " Average loss:  0.05515  Accuracy:  0.51354  Smallest:  0.00000  Largest:  1.00000  Average:  0.67220\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2866)  (0.5, 1278, 564)  (1.0, 8934, 3509)\n",
      "Epoch:   104 \n",
      "Train:\n",
      " Average loss:  0.00500  Accuracy:  0.57924  Smallest:  0.00000  Largest:  1.00000  Average:  0.70533\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13168)  (0.5, 5171, 4187)  (1.0, 35539, 13950) \n",
      "Test:\n",
      " Average loss:  0.05278  Accuracy:  0.40594  Smallest:  0.00000  Largest:  1.00000  Average:  0.72485\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2586)  (0.5, 1278, 508)  (1.0, 8934, 2391)\n",
      "Epoch:   105 \n",
      "Train:\n",
      " Average loss:  0.00453  Accuracy:  0.56599  Smallest:  0.00000  Largest:  1.00000  Average:  0.70743\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13163)  (0.5, 5171, 4263)  (1.0, 35539, 13163) \n",
      "Test:\n",
      " Average loss:  0.05322  Accuracy:  0.50481  Smallest:  0.00000  Largest:  1.00000  Average:  0.68230\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2792)  (0.5, 1278, 576)  (1.0, 8934, 3453)\n",
      "Epoch:   106 \n",
      "Train:\n",
      " Average loss:  0.00350  Accuracy:  0.59776  Smallest:  0.00000  Largest:  1.00000  Average:  0.70672\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13220)  (0.5, 5171, 4488)  (1.0, 35539, 14598) \n",
      "Test:\n",
      " Average loss:  0.05138  Accuracy:  0.47565  Smallest:  0.00000  Largest:  1.00000  Average:  0.69541\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2731)  (0.5, 1278, 571)  (1.0, 8934, 3125)\n",
      "Epoch:   107 \n",
      "Train:\n",
      " Average loss:  0.00289  Accuracy:  0.58551  Smallest:  0.00000  Largest:  1.00000  Average:  0.70628\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13258)  (0.5, 5171, 4615)  (1.0, 35539, 13771) \n",
      "Test:\n",
      " Average loss:  0.05121  Accuracy:  0.41163  Smallest:  0.00000  Largest:  1.00000  Average:  0.74220\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2416)  (0.5, 1278, 558)  (1.0, 8934, 2588)\n",
      "Epoch:   108 \n",
      "Train:\n",
      " Average loss:  0.00302  Accuracy:  0.58418  Smallest:  0.00000  Largest:  1.00000  Average:  0.70666\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13253)  (0.5, 5171, 4569)  (1.0, 35539, 13750) \n",
      "Test:\n",
      " Average loss:  0.05616  Accuracy:  0.49660  Smallest:  0.00000  Largest:  1.00000  Average:  0.66913\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2869)  (0.5, 1278, 580)  (1.0, 8934, 3261)\n",
      "Epoch:   109 \n",
      "Train:\n",
      " Average loss:  0.00359  Accuracy:  0.58089  Smallest:  0.00000  Largest:  1.00000  Average:  0.70652\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13214)  (0.5, 5171, 4503)  (1.0, 35539, 13677) \n",
      "Test:\n",
      " Average loss:  0.05351  Accuracy:  0.40298  Smallest:  0.00000  Largest:  1.00000  Average:  0.73985\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2465)  (0.5, 1278, 495)  (1.0, 8934, 2485)\n",
      "Epoch:   110 \n",
      "Train:\n",
      " Average loss:  0.00400  Accuracy:  0.57532  Smallest:  0.00000  Largest:  1.00000  Average:  0.70646\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13169)  (0.5, 5171, 4410)  (1.0, 35539, 13514) \n",
      "Test:\n",
      " Average loss:  0.06010  Accuracy:  0.34495  Smallest:  0.00000  Largest:  1.00000  Average:  0.76674\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2312)  (0.5, 1278, 389)  (1.0, 8934, 1960)\n",
      "Epoch:   111 \n",
      "Train:\n",
      " Average loss:  0.00525  Accuracy:  0.56901  Smallest:  0.00000  Largest:  1.00000  Average:  0.70666\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13080)  (0.5, 5171, 4246)  (1.0, 35539, 13426) \n",
      "Test:\n",
      " Average loss:  0.05918  Accuracy:  0.49349  Smallest:  0.00000  Largest:  1.00000  Average:  0.65925\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2918)  (0.5, 1278, 549)  (1.0, 8934, 3201)\n",
      "Epoch:   112 \n",
      "Train:\n",
      " Average loss:  0.00491  Accuracy:  0.58942  Smallest:  0.00000  Largest:  1.00000  Average:  0.70657\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13139)  (0.5, 5171, 4286)  (1.0, 35539, 14430) \n",
      "Test:\n",
      " Average loss:  0.05264  Accuracy:  0.47654  Smallest:  0.00000  Largest:  1.00000  Average:  0.69543\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2747)  (0.5, 1278, 548)  (1.0, 8934, 3144)\n",
      "Epoch:   113 \n",
      "Train:\n",
      " Average loss:  0.00467  Accuracy:  0.58786  Smallest:  0.00000  Largest:  1.00000  Average:  0.70671\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13163)  (0.5, 5171, 4279)  (1.0, 35539, 14329) \n",
      "Test:\n",
      " Average loss:  0.05265  Accuracy:  0.49652  Smallest:  0.00000  Largest:  1.00000  Average:  0.69145\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2754)  (0.5, 1278, 581)  (1.0, 8934, 3374)\n",
      "Epoch:   114 \n",
      "Train:\n",
      " Average loss:  0.00378  Accuracy:  0.59563  Smallest:  0.00000  Largest:  1.00000  Average:  0.70673\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13216)  (0.5, 5171, 4400)  (1.0, 35539, 14575) \n",
      "Test:\n",
      " Average loss:  0.04895  Accuracy:  0.47262  Smallest:  0.00000  Largest:  1.00000  Average:  0.72144\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2579)  (0.5, 1278, 584)  (1.0, 8934, 3223)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   115 \n",
      "Train:\n",
      " Average loss:  0.00339  Accuracy:  0.59621  Smallest:  0.00000  Largest:  1.00000  Average:  0.70612\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13228)  (0.5, 5171, 4528)  (1.0, 35539, 14466) \n",
      "Test:\n",
      " Average loss:  0.04994  Accuracy:  0.45752  Smallest:  0.00000  Largest:  1.00000  Average:  0.69985\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2787)  (0.5, 1278, 540)  (1.0, 8934, 2855)\n",
      "Epoch:   116 \n",
      "Train:\n",
      " Average loss:  0.00312  Accuracy:  0.60067  Smallest:  0.00000  Largest:  1.00000  Average:  0.70616\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13261)  (0.5, 5171, 4512)  (1.0, 35539, 14690) \n",
      "Test:\n",
      " Average loss:  0.05390  Accuracy:  0.41881  Smallest:  0.00000  Largest:  1.00000  Average:  0.75083\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2355)  (0.5, 1278, 519)  (1.0, 8934, 2785)\n",
      "Epoch:   117 \n",
      "Train:\n",
      " Average loss:  0.00347  Accuracy:  0.59935  Smallest:  0.00000  Largest:  1.00000  Average:  0.70649\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13209)  (0.5, 5171, 4545)  (1.0, 35539, 14638) \n",
      "Test:\n",
      " Average loss:  0.05157  Accuracy:  0.45811  Smallest:  0.00000  Largest:  1.00000  Average:  0.71004\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2651)  (0.5, 1278, 579)  (1.0, 8934, 2960)\n",
      "Epoch:   118 \n",
      "Train:\n",
      " Average loss:  0.00338  Accuracy:  0.56843  Smallest:  0.00000  Largest:  1.00000  Average:  0.70731\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13198)  (0.5, 5171, 4510)  (1.0, 35539, 13013) \n",
      "Test:\n",
      " Average loss:  0.05115  Accuracy:  0.42962  Smallest:  0.00000  Largest:  1.00000  Average:  0.72599\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2576)  (0.5, 1278, 558)  (1.0, 8934, 2671)\n",
      "Epoch:   119 \n",
      "Train:\n",
      " Average loss:  0.00315  Accuracy:  0.58066  Smallest:  0.00000  Largest:  1.00000  Average:  0.70617\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13253)  (0.5, 5171, 4540)  (1.0, 35539, 13589) \n",
      "Test:\n",
      " Average loss:  0.06681  Accuracy:  0.49401  Smallest:  0.00000  Largest:  1.00000  Average:  0.63850\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 3018)  (0.5, 1278, 523)  (1.0, 8934, 3134)\n",
      "Epoch:   120 \n",
      "Train:\n",
      " Average loss:  0.00404  Accuracy:  0.57101  Smallest:  0.00000  Largest:  1.00000  Average:  0.70614\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13198)  (0.5, 5171, 4432)  (1.0, 35539, 13230) \n",
      "Test:\n",
      " Average loss:  0.04909  Accuracy:  0.44309  Smallest:  0.00000  Largest:  1.00000  Average:  0.71151\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2672)  (0.5, 1278, 549)  (1.0, 8934, 2766)\n",
      "Epoch:   121 \n",
      "Train:\n",
      " Average loss:  0.00386  Accuracy:  0.58694  Smallest:  0.00000  Largest:  1.00000  Average:  0.70522\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13219)  (0.5, 5171, 4380)  (1.0, 35539, 14122) \n",
      "Test:\n",
      " Average loss:  0.06206  Accuracy:  0.50414  Smallest:  0.00000  Largest:  1.00000  Average:  0.64987\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2956)  (0.5, 1278, 574)  (1.0, 8934, 3282)\n",
      "Epoch:   122 \n",
      "Train:\n",
      " Average loss:  0.00337  Accuracy:  0.59090  Smallest:  0.00000  Largest:  1.00000  Average:  0.70637\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13234)  (0.5, 5171, 4512)  (1.0, 35539, 14189) \n",
      "Test:\n",
      " Average loss:  0.06225  Accuracy:  0.36908  Smallest:  0.00000  Largest:  1.00000  Average:  0.78172\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2045)  (0.5, 1278, 483)  (1.0, 8934, 2459)\n",
      "Epoch:   123 \n",
      "Train:\n",
      " Average loss:  0.00329  Accuracy:  0.59045  Smallest:  0.00000  Largest:  1.00000  Average:  0.70694\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13218)  (0.5, 5171, 4528)  (1.0, 35539, 14165) \n",
      "Test:\n",
      " Average loss:  0.05024  Accuracy:  0.44982  Smallest:  0.00000  Largest:  1.00000  Average:  0.72652\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2509)  (0.5, 1278, 594)  (1.0, 8934, 2975)\n",
      "Epoch:   124 \n",
      "Train:\n",
      " Average loss:  0.00326  Accuracy:  0.58623  Smallest:  0.00000  Largest:  1.00000  Average:  0.70659\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13216)  (0.5, 5171, 4552)  (1.0, 35539, 13915) \n",
      "Test:\n",
      " Average loss:  0.05097  Accuracy:  0.47165  Smallest:  0.00000  Largest:  1.00000  Average:  0.69705\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2722)  (0.5, 1278, 594)  (1.0, 8934, 3057)\n",
      "Epoch:   125 \n",
      "Train:\n",
      " Average loss:  0.00322  Accuracy:  0.58955  Smallest:  0.00000  Largest:  1.00000  Average:  0.70542\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13240)  (0.5, 5171, 4567)  (1.0, 35539, 14055) \n",
      "Test:\n",
      " Average loss:  0.05222  Accuracy:  0.39668  Smallest:  0.00000  Largest:  1.00000  Average:  0.73175\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2518)  (0.5, 1278, 518)  (1.0, 8934, 2324)\n",
      "Epoch:   126 \n",
      "Train:\n",
      " Average loss:  0.00337  Accuracy:  0.56856  Smallest:  0.00000  Largest:  1.00000  Average:  0.70684\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13229)  (0.5, 5171, 4465)  (1.0, 35539, 13034) \n",
      "Test:\n",
      " Average loss:  0.04877  Accuracy:  0.46603  Smallest:  0.00000  Largest:  1.00000  Average:  0.70667\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2684)  (0.5, 1278, 574)  (1.0, 8934, 3039)\n",
      "Epoch:   127 \n",
      "Train:\n",
      " Average loss:  0.00435  Accuracy:  0.57299  Smallest:  0.00000  Largest:  1.00000  Average:  0.70614\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13176)  (0.5, 5171, 4361)  (1.0, 35539, 13430) \n",
      "Test:\n",
      " Average loss:  0.05588  Accuracy:  0.48742  Smallest:  0.00000  Largest:  1.00000  Average:  0.66416\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2936)  (0.5, 1278, 524)  (1.0, 8934, 3126)\n",
      "Epoch:   128 \n",
      "Train:\n",
      " Average loss:  0.00358  Accuracy:  0.57898  Smallest:  0.00000  Largest:  1.00000  Average:  0.70643\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13238)  (0.5, 5171, 4424)  (1.0, 35539, 13629) \n",
      "Test:\n",
      " Average loss:  0.05080  Accuracy:  0.45138  Smallest:  0.00000  Largest:  1.00000  Average:  0.69767\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2782)  (0.5, 1278, 520)  (1.0, 8934, 2797)\n",
      "Epoch:   129 \n",
      "Train:\n",
      " Average loss:  0.00377  Accuracy:  0.59204  Smallest:  0.00000  Largest:  1.00000  Average:  0.70619\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13198)  (0.5, 5171, 4428)  (1.0, 35539, 14371) \n",
      "Test:\n",
      " Average loss:  0.04911  Accuracy:  0.50999  Smallest:  0.00000  Largest:  1.00000  Average:  0.70022\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2703)  (0.5, 1278, 599)  (1.0, 8934, 3589)\n",
      "Epoch:   130 \n",
      "Train:\n",
      " Average loss:  0.00340  Accuracy:  0.59782  Smallest:  0.00000  Largest:  1.00000  Average:  0.70589\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13230)  (0.5, 5171, 4510)  (1.0, 35539, 14569) \n",
      "Test:\n",
      " Average loss:  0.05153  Accuracy:  0.45152  Smallest:  0.00000  Largest:  1.00000  Average:  0.69764\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2753)  (0.5, 1278, 534)  (1.0, 8934, 2814)\n",
      "Epoch:   131 \n",
      "Train:\n",
      " Average loss:  0.00347  Accuracy:  0.58675  Smallest:  0.00000  Largest:  1.00000  Average:  0.70680\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13231)  (0.5, 5171, 4485)  (1.0, 35539, 13995) \n",
      "Test:\n",
      " Average loss:  0.05524  Accuracy:  0.49445  Smallest:  0.00000  Largest:  1.00000  Average:  0.67425\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2872)  (0.5, 1278, 545)  (1.0, 8934, 3264)\n",
      "Epoch:   132 \n",
      "Train:\n",
      " Average loss:  0.00372  Accuracy:  0.59214  Smallest:  0.00000  Largest:  1.00000  Average:  0.70581\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13220)  (0.5, 5171, 4452)  (1.0, 35539, 14330) \n",
      "Test:\n",
      " Average loss:  0.05456  Accuracy:  0.37544  Smallest:  0.00000  Largest:  1.00000  Average:  0.75258\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2382)  (0.5, 1278, 469)  (1.0, 8934, 2222)\n",
      "Epoch:   133 \n",
      "Train:\n",
      " Average loss:  0.00287  Accuracy:  0.60093  Smallest:  0.00000  Largest:  1.00000  Average:  0.70631\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13256)  (0.5, 5171, 4581)  (1.0, 35539, 14640) \n",
      "Test:\n",
      " Average loss:  0.05093  Accuracy:  0.48128  Smallest:  0.00000  Largest:  1.00000  Average:  0.70053\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2698)  (0.5, 1278, 592)  (1.0, 8934, 3213)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   134 \n",
      "Train:\n",
      " Average loss:  0.00286  Accuracy:  0.59809  Smallest:  0.00000  Largest:  1.00000  Average:  0.70604\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13262)  (0.5, 5171, 4612)  (1.0, 35539, 14450) \n",
      "Test:\n",
      " Average loss:  0.05283  Accuracy:  0.46544  Smallest:  0.00000  Largest:  1.00000  Average:  0.68737\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2798)  (0.5, 1278, 585)  (1.0, 8934, 2906)\n",
      "Epoch:   135 \n",
      "Train:\n",
      " Average loss:  0.00271  Accuracy:  0.60263  Smallest:  0.00000  Largest:  1.00000  Average:  0.70603\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13243)  (0.5, 5171, 4671)  (1.0, 35539, 14655) \n",
      "Test:\n",
      " Average loss:  0.05028  Accuracy:  0.47054  Smallest:  0.00000  Largest:  1.00000  Average:  0.70501\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2659)  (0.5, 1278, 601)  (1.0, 8934, 3098)\n",
      "Epoch:   136 \n",
      "Train:\n",
      " Average loss:  0.00258  Accuracy:  0.58605  Smallest:  0.00000  Largest:  1.00000  Average:  0.70632\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13261)  (0.5, 5171, 4683)  (1.0, 35539, 13729) \n",
      "Test:\n",
      " Average loss:  0.05022  Accuracy:  0.44079  Smallest:  0.00000  Largest:  1.00000  Average:  0.71711\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2603)  (0.5, 1278, 587)  (1.0, 8934, 2766)\n",
      "Epoch:   137 \n",
      "Train:\n",
      " Average loss:  0.00227  Accuracy:  0.57075  Smallest:  0.00000  Largest:  1.00000  Average:  0.70687\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13260)  (0.5, 5171, 4737)  (1.0, 35539, 12849) \n",
      "Test:\n",
      " Average loss:  0.05028  Accuracy:  0.41482  Smallest:  0.00000  Largest:  1.00000  Average:  0.71111\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2681)  (0.5, 1278, 537)  (1.0, 8934, 2387)\n",
      "Epoch:   138 \n",
      "Train:\n",
      " Average loss:  0.00279  Accuracy:  0.57184  Smallest:  0.00000  Largest:  1.00000  Average:  0.70568\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13247)  (0.5, 5171, 4636)  (1.0, 35539, 13022) \n",
      "Test:\n",
      " Average loss:  0.05161  Accuracy:  0.40964  Smallest:  0.00000  Largest:  1.00000  Average:  0.74252\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2380)  (0.5, 1278, 579)  (1.0, 8934, 2576)\n",
      "Epoch:   139 \n",
      "Train:\n",
      " Average loss:  0.00353  Accuracy:  0.56780  Smallest:  0.00000  Largest:  1.00000  Average:  0.70563\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13222)  (0.5, 5171, 4545)  (1.0, 35539, 12920) \n",
      "Test:\n",
      " Average loss:  0.05753  Accuracy:  0.35716  Smallest:  0.00000  Largest:  1.00000  Average:  0.76624\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2215)  (0.5, 1278, 478)  (1.0, 8934, 2133)\n",
      "Epoch:   140 \n",
      "Train:\n",
      " Average loss:  0.00392  Accuracy:  0.56331  Smallest:  0.00000  Largest:  1.00000  Average:  0.70669\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13184)  (0.5, 5171, 4436)  (1.0, 35539, 12824) \n",
      "Test:\n",
      " Average loss:  0.05054  Accuracy:  0.44087  Smallest:  0.00000  Largest:  1.00000  Average:  0.73301\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2430)  (0.5, 1278, 642)  (1.0, 8934, 2885)\n",
      "Epoch:   141 \n",
      "Train:\n",
      " Average loss:  0.00364  Accuracy:  0.57571  Smallest:  0.00000  Largest:  1.00000  Average:  0.70654\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13205)  (0.5, 5171, 4492)  (1.0, 35539, 13417) \n",
      "Test:\n",
      " Average loss:  0.06013  Accuracy:  0.34480  Smallest:  0.00000  Largest:  1.00000  Average:  0.77233\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2197)  (0.5, 1278, 451)  (1.0, 8934, 2011)\n",
      "Epoch:   142 \n",
      "Train:\n",
      " Average loss:  0.00268  Accuracy:  0.58028  Smallest:  0.00000  Largest:  1.00000  Average:  0.70627\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13273)  (0.5, 5171, 4640)  (1.0, 35539, 13448) \n",
      "Test:\n",
      " Average loss:  0.05050  Accuracy:  0.42466  Smallest:  0.00000  Largest:  1.00000  Average:  0.71705\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2591)  (0.5, 1278, 591)  (1.0, 8934, 2556)\n",
      "Epoch:   143 \n",
      "Train:\n",
      " Average loss:  0.00261  Accuracy:  0.56851  Smallest:  0.00000  Largest:  1.00000  Average:  0.70635\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13270)  (0.5, 5171, 4665)  (1.0, 35539, 12790) \n",
      "Test:\n",
      " Average loss:  0.05000  Accuracy:  0.43954  Smallest:  0.00000  Largest:  1.00000  Average:  0.70532\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2672)  (0.5, 1278, 587)  (1.0, 8934, 2680)\n",
      "Epoch:   144 \n",
      "Train:\n",
      " Average loss:  0.00228  Accuracy:  0.56793  Smallest:  0.00000  Largest:  1.00000  Average:  0.70707\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13262)  (0.5, 5171, 4738)  (1.0, 35539, 12694) \n",
      "Test:\n",
      " Average loss:  0.05062  Accuracy:  0.39824  Smallest:  0.00000  Largest:  1.00000  Average:  0.72833\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2553)  (0.5, 1278, 547)  (1.0, 8934, 2281)\n",
      "Epoch:   145 \n",
      "Train:\n",
      " Average loss:  0.00272  Accuracy:  0.55143  Smallest:  0.00000  Largest:  1.00000  Average:  0.70647\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13258)  (0.5, 5171, 4668)  (1.0, 35539, 11876) \n",
      "Test:\n",
      " Average loss:  0.06454  Accuracy:  0.46137  Smallest:  0.00000  Largest:  1.00000  Average:  0.64621\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2980)  (0.5, 1278, 560)  (1.0, 8934, 2694)\n",
      "Epoch:   146 \n",
      "Train:\n",
      " Average loss:  0.00280  Accuracy:  0.55639  Smallest:  0.00000  Largest:  1.00000  Average:  0.70649\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13237)  (0.5, 5171, 4651)  (1.0, 35539, 12182) \n",
      "Test:\n",
      " Average loss:  0.05091  Accuracy:  0.43176  Smallest:  0.00000  Largest:  1.00000  Average:  0.70327\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2679)  (0.5, 1278, 636)  (1.0, 8934, 2519)\n",
      "Epoch:   147 \n",
      "Train:\n",
      " Average loss:  0.00289  Accuracy:  0.55391  Smallest:  0.00000  Largest:  1.00000  Average:  0.70628\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13243)  (0.5, 5171, 4620)  (1.0, 35539, 12073) \n",
      "Test:\n",
      " Average loss:  0.05251  Accuracy:  0.38595  Smallest:  0.00000  Largest:  1.00000  Average:  0.74373\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2373)  (0.5, 1278, 596)  (1.0, 8934, 2246)\n",
      "Epoch:   148 \n",
      "Train:\n",
      " Average loss:  0.00284  Accuracy:  0.55467  Smallest:  0.00000  Largest:  1.00000  Average:  0.70597\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13254)  (0.5, 5171, 4627)  (1.0, 35539, 12096) \n",
      "Test:\n",
      " Average loss:  0.05127  Accuracy:  0.39565  Smallest:  0.00000  Largest:  1.00000  Average:  0.73189\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2457)  (0.5, 1278, 590)  (1.0, 8934, 2299)\n",
      "Epoch:   149 \n",
      "Train:\n",
      " Average loss:  0.00368  Accuracy:  0.54323  Smallest:  0.00000  Largest:  1.00000  Average:  0.70645\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13211)  (0.5, 5171, 4504)  (1.0, 35539, 11644) \n",
      "Test:\n",
      " Average loss:  0.05223  Accuracy:  0.41948  Smallest:  0.00000  Largest:  1.00000  Average:  0.73117\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2467)  (0.5, 1278, 577)  (1.0, 8934, 2624)\n",
      "Epoch:   150 \n",
      "Train:\n",
      " Average loss:  0.00380  Accuracy:  0.56673  Smallest:  0.00000  Largest:  1.00000  Average:  0.70716\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13165)  (0.5, 5171, 4519)  (1.0, 35539, 12945) \n",
      "Test:\n",
      " Average loss:  0.05578  Accuracy:  0.46485  Smallest:  0.00000  Largest:  1.00000  Average:  0.67408\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2858)  (0.5, 1278, 566)  (1.0, 8934, 2857)\n",
      "Epoch:   151 \n",
      "Train:\n",
      " Average loss:  0.00328  Accuracy:  0.55705  Smallest:  0.00000  Largest:  1.00000  Average:  0.70629\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13227)  (0.5, 5171, 4508)  (1.0, 35539, 12371) \n",
      "Test:\n",
      " Average loss:  0.05347  Accuracy:  0.39550  Smallest:  0.00000  Largest:  1.00000  Average:  0.74722\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2359)  (0.5, 1278, 553)  (1.0, 8934, 2432)\n",
      "Epoch:   152 \n",
      "Train:\n",
      " Average loss:  0.00290  Accuracy:  0.57719  Smallest:  0.00000  Largest:  1.00000  Average:  0.70686\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13225)  (0.5, 5171, 4650)  (1.0, 35539, 13319) \n",
      "Test:\n",
      " Average loss:  0.05069  Accuracy:  0.45160  Smallest:  0.00000  Largest:  1.00000  Average:  0.69715\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2722)  (0.5, 1278, 597)  (1.0, 8934, 2783)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   153 \n",
      "Train:\n",
      " Average loss:  0.00314  Accuracy:  0.56031  Smallest:  0.00000  Largest:  1.00000  Average:  0.70618\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13254)  (0.5, 5171, 4547)  (1.0, 35539, 12481) \n",
      "Test:\n",
      " Average loss:  0.05624  Accuracy:  0.46048  Smallest:  0.00000  Largest:  1.00000  Average:  0.66835\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2903)  (0.5, 1278, 595)  (1.0, 8934, 2724)\n",
      "Epoch:   154 \n",
      "Train:\n",
      " Average loss:  0.00292  Accuracy:  0.56240  Smallest:  0.00000  Largest:  1.00000  Average:  0.70640\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13241)  (0.5, 5171, 4611)  (1.0, 35539, 12543) \n",
      "Test:\n",
      " Average loss:  0.05416  Accuracy:  0.34954  Smallest:  0.00000  Largest:  1.00000  Average:  0.74793\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2428)  (0.5, 1278, 485)  (1.0, 8934, 1810)\n",
      "Epoch:   155 \n",
      "Train:\n",
      " Average loss:  0.00283  Accuracy:  0.55937  Smallest:  0.00000  Largest:  1.00000  Average:  0.70645\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13239)  (0.5, 5171, 4637)  (1.0, 35539, 12355) \n",
      "Test:\n",
      " Average loss:  0.05153  Accuracy:  0.41052  Smallest:  0.00000  Largest:  1.00000  Average:  0.71241\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2648)  (0.5, 1278, 560)  (1.0, 8934, 2339)\n",
      "Epoch:   156 \n",
      "Train:\n",
      " Average loss:  0.00271  Accuracy:  0.55818  Smallest:  0.00000  Largest:  1.00000  Average:  0.70587\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13244)  (0.5, 5171, 4677)  (1.0, 35539, 12246) \n",
      "Test:\n",
      " Average loss:  0.05209  Accuracy:  0.44079  Smallest:  0.00000  Largest:  1.00000  Average:  0.70984\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2604)  (0.5, 1278, 597)  (1.0, 8934, 2755)\n",
      "Epoch:   157 \n",
      "Train:\n",
      " Average loss:  0.00287  Accuracy:  0.56671  Smallest:  0.00000  Largest:  1.00000  Average:  0.70587\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13231)  (0.5, 5171, 4660)  (1.0, 35539, 12737) \n",
      "Test:\n",
      " Average loss:  0.05019  Accuracy:  0.39668  Smallest:  0.00000  Largest:  1.00000  Average:  0.72631\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2556)  (0.5, 1278, 590)  (1.0, 8934, 2214)\n",
      "Epoch:   158 \n",
      "Train:\n",
      " Average loss:  0.00304  Accuracy:  0.54723  Smallest:  0.00000  Largest:  1.00000  Average:  0.70628\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13241)  (0.5, 5171, 4621)  (1.0, 35539, 11713) \n",
      "Test:\n",
      " Average loss:  0.05420  Accuracy:  0.36397  Smallest:  0.00000  Largest:  1.00000  Average:  0.74695\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2389)  (0.5, 1278, 526)  (1.0, 8934, 2003)\n",
      "Epoch:   159 \n",
      "Train:\n",
      " Average loss:  0.00344  Accuracy:  0.55532  Smallest:  0.00000  Largest:  1.00000  Average:  0.70634\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13221)  (0.5, 5171, 4563)  (1.0, 35539, 12228) \n",
      "Test:\n",
      " Average loss:  0.05104  Accuracy:  0.40764  Smallest:  0.00000  Largest:  1.00000  Average:  0.72129\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2587)  (0.5, 1278, 582)  (1.0, 8934, 2339)\n",
      "Epoch:   160 \n",
      "Train:\n",
      " Average loss:  0.00352  Accuracy:  0.55624  Smallest:  0.00000  Largest:  1.00000  Average:  0.70594\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13217)  (0.5, 5171, 4519)  (1.0, 35539, 12326) \n",
      "Test:\n",
      " Average loss:  0.05102  Accuracy:  0.42984  Smallest:  0.00000  Largest:  1.00000  Average:  0.70515\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2685)  (0.5, 1278, 585)  (1.0, 8934, 2538)\n",
      "Epoch:   161 \n",
      "Train:\n",
      " Average loss:  0.00315  Accuracy:  0.55541  Smallest:  0.00000  Largest:  1.00000  Average:  0.70650\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13232)  (0.5, 5171, 4588)  (1.0, 35539, 12197) \n",
      "Test:\n",
      " Average loss:  0.05196  Accuracy:  0.45397  Smallest:  0.00000  Largest:  1.00000  Average:  0.69108\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2762)  (0.5, 1278, 585)  (1.0, 8934, 2787)\n",
      "Epoch:   162 \n",
      "Train:\n",
      " Average loss:  0.00339  Accuracy:  0.56279  Smallest:  0.00000  Largest:  1.00000  Average:  0.70557\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13221)  (0.5, 5171, 4567)  (1.0, 35539, 12628) \n",
      "Test:\n",
      " Average loss:  0.05221  Accuracy:  0.38847  Smallest:  0.00000  Largest:  1.00000  Average:  0.73708\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2470)  (0.5, 1278, 528)  (1.0, 8934, 2251)\n",
      "Epoch:   163 \n",
      "Train:\n",
      " Average loss:  0.00338  Accuracy:  0.55424  Smallest:  0.00000  Largest:  1.00000  Average:  0.70665\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13223)  (0.5, 5171, 4523)  (1.0, 35539, 12208) \n",
      "Test:\n",
      " Average loss:  0.05066  Accuracy:  0.43228  Smallest:  0.00000  Largest:  1.00000  Average:  0.70849\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2666)  (0.5, 1278, 582)  (1.0, 8934, 2593)\n",
      "Epoch:   164 \n",
      "Train:\n",
      " Average loss:  0.00297  Accuracy:  0.56011  Smallest:  0.00000  Largest:  1.00000  Average:  0.70675\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13236)  (0.5, 5171, 4601)  (1.0, 35539, 12434) \n",
      "Test:\n",
      " Average loss:  0.05093  Accuracy:  0.38336  Smallest:  0.00000  Largest:  1.00000  Average:  0.74072\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2456)  (0.5, 1278, 553)  (1.0, 8934, 2171)\n",
      "Epoch:   165 \n",
      "Train:\n",
      " Average loss:  0.00266  Accuracy:  0.56063  Smallest:  0.00000  Largest:  1.00000  Average:  0.70609\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13248)  (0.5, 5171, 4665)  (1.0, 35539, 12386) \n",
      "Test:\n",
      " Average loss:  0.05343  Accuracy:  0.44109  Smallest:  0.00000  Largest:  1.00000  Average:  0.68125\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2826)  (0.5, 1278, 590)  (1.0, 8934, 2544)\n",
      "Epoch:   166 \n",
      "Train:\n",
      " Average loss:  0.00212  Accuracy:  0.55163  Smallest:  0.00000  Largest:  1.00000  Average:  0.70689\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13281)  (0.5, 5171, 4760)  (1.0, 35539, 11772) \n",
      "Test:\n",
      " Average loss:  0.04946  Accuracy:  0.40571  Smallest:  0.00000  Largest:  1.00000  Average:  0.71371\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2642)  (0.5, 1278, 580)  (1.0, 8934, 2260)\n",
      "Epoch:   167 \n",
      "Train:\n",
      " Average loss:  0.00224  Accuracy:  0.54636  Smallest:  0.00000  Largest:  1.00000  Average:  0.70620\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13274)  (0.5, 5171, 4756)  (1.0, 35539, 11498) \n",
      "Test:\n",
      " Average loss:  0.05126  Accuracy:  0.42081  Smallest:  0.00000  Largest:  1.00000  Average:  0.69513\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2738)  (0.5, 1278, 597)  (1.0, 8934, 2351)\n",
      "Epoch:   168 \n",
      "Train:\n",
      " Average loss:  0.00299  Accuracy:  0.54910  Smallest:  0.00000  Largest:  1.00000  Average:  0.70597\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13242)  (0.5, 5171, 4590)  (1.0, 35539, 11844) \n",
      "Test:\n",
      " Average loss:  0.05610  Accuracy:  0.36368  Smallest:  0.00000  Largest:  1.00000  Average:  0.75749\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2278)  (0.5, 1278, 503)  (1.0, 8934, 2133)\n",
      "Epoch:   169 \n",
      "Train:\n",
      " Average loss:  0.00358  Accuracy:  0.55345  Smallest:  0.00000  Largest:  1.00000  Average:  0.70592\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13208)  (0.5, 5171, 4545)  (1.0, 35539, 12158) \n",
      "Test:\n",
      " Average loss:  0.05048  Accuracy:  0.40253  Smallest:  0.00000  Largest:  1.00000  Average:  0.72499\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2551)  (0.5, 1278, 577)  (1.0, 8934, 2311)\n",
      "Epoch:   170 \n",
      "Train:\n",
      " Average loss:  0.00314  Accuracy:  0.55713  Smallest:  0.00000  Largest:  1.00000  Average:  0.70680\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13224)  (0.5, 5171, 4588)  (1.0, 35539, 12298) \n",
      "Test:\n",
      " Average loss:  0.05044  Accuracy:  0.42644  Smallest:  0.00000  Largest:  1.00000  Average:  0.70825\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2653)  (0.5, 1278, 590)  (1.0, 8934, 2519)\n",
      "Epoch:   171 \n",
      "Train:\n",
      " Average loss:  0.00246  Accuracy:  0.55604  Smallest:  0.00000  Largest:  1.00000  Average:  0.70622\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13282)  (0.5, 5171, 4704)  (1.0, 35539, 12065) \n",
      "Test:\n",
      " Average loss:  0.05171  Accuracy:  0.43517  Smallest:  0.00000  Largest:  1.00000  Average:  0.69537\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2769)  (0.5, 1278, 562)  (1.0, 8934, 2549)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   172 \n",
      "Train:\n",
      " Average loss:  0.00260  Accuracy:  0.54741  Smallest:  0.00000  Largest:  1.00000  Average:  0.70672\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13262)  (0.5, 5171, 4638)  (1.0, 35539, 11685) \n",
      "Test:\n",
      " Average loss:  0.05555  Accuracy:  0.35028  Smallest:  0.00000  Largest:  1.00000  Average:  0.75776\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2287)  (0.5, 1278, 509)  (1.0, 8934, 1937)\n",
      "Epoch:   173 \n",
      "Train:\n",
      " Average loss:  0.00256  Accuracy:  0.55095  Smallest:  0.00000  Largest:  1.00000  Average:  0.70620\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13263)  (0.5, 5171, 4717)  (1.0, 35539, 11796) \n",
      "Test:\n",
      " Average loss:  0.05055  Accuracy:  0.37789  Smallest:  0.00000  Largest:  1.00000  Average:  0.73845\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2464)  (0.5, 1278, 562)  (1.0, 8934, 2080)\n",
      "Epoch:   174 \n",
      "Train:\n",
      " Average loss:  0.00263  Accuracy:  0.54255  Smallest:  0.00000  Largest:  1.00000  Average:  0.70668\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13251)  (0.5, 5171, 4681)  (1.0, 35539, 11390) \n",
      "Test:\n",
      " Average loss:  0.05356  Accuracy:  0.46285  Smallest:  0.00000  Largest:  1.00000  Average:  0.67885\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2805)  (0.5, 1278, 642)  (1.0, 8934, 2807)\n",
      "Epoch:   175 \n",
      "Train:\n",
      " Average loss:  0.00280  Accuracy:  0.55032  Smallest:  0.00000  Largest:  1.00000  Average:  0.70656\n",
      "Category, # Members, # Correct Predictions:  (0.0, 13335, 13245)  (0.5, 5171, 4656)  (1.0, 35539, 11841) \n",
      "Test:\n",
      " Average loss:  0.05056  Accuracy:  0.42429  Smallest:  0.00000  Largest:  1.00000  Average:  0.71025\n",
      "Category, # Members, # Correct Predictions:  (0.0, 3300, 2599)  (0.5, 1278, 629)  (1.0, 8934, 2505)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2154\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2155\u001b[0m         \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2156\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2157\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from laplotter import LossAccPlotter\n",
    "from visdom import Visdom\n",
    "\n",
    "viz = Visdom()\n",
    "plotter = LossAccPlotter()\n",
    "\n",
    "for epoch in range(n_epocs):\n",
    "    \n",
    "    net = net.train()\n",
    "    train_stats = Stats()\n",
    "    \n",
    "    for board, value in train_gen:\n",
    "        board, value = board.to(device), value.to(device)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        output = net(board)\n",
    "        output = output.view(-1)\n",
    "        assert output.shape == value.shape\n",
    "            \n",
    "        loss = criterion(output, value)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch % epochs_per_stats == 0:\n",
    "            output = output.cpu().view(-1).detach().numpy()\n",
    "            value = value.cpu().view(-1).numpy()\n",
    "            train_stats.update(output, value, loss)\n",
    "\n",
    "    # validate\n",
    "    test_stats = evaluate_fit(net, test_gen, device, epoch % epochs_per_stats == 0)\n",
    "                \n",
    "    if test_stats is not None:            \n",
    "        print(\"Epoch:  \", epoch, \"\\nTrain:\\n\", train_stats, \"\\nTest:\\n\", test_stats)\n",
    "        plotter.add_values(epoch,\n",
    "                           loss_train=train_stats.loss, acc_train=train_stats.accuracy,\n",
    "                           loss_val=test_stats.loss, acc_val=test_stats.accuracy)\n",
    "        if epoch == 0:\n",
    "            win = viz.matplot(plotter.fig)\n",
    "        else:\n",
    "            viz.matplot(plotter.fig, win=win)\n",
    "        \n",
    "    torch.save({\n",
    "        'net_state_dict': net.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict()},\n",
    "        WORKING_DIR + str(epoch) + '-' + str(batch_size) + '.pth')\n",
    "            \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plotter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-e76209a9e63b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplotter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'plotter' is not defined"
     ]
    }
   ],
   "source": [
    "plotter.fig"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
